> 本文由 [https://github.com/huiyeruzhou/arxiv_crawler](https://github.com/huiyeruzhou/arxiv_crawler) 自动生成
>
> 领域白名单：cs.AI,cs.CL,cs.LG,cs.CV
> 关键词： LLM, GPT, AI, language+model, deep+learning, transformer, neural+network, machine+learning

# 论文全览：2025-02-06

共有270篇相关领域论文, 另有40篇其他

## 宇宙学和非银河系天体物理学(astro-ph.CO:Cosmology and Nongalactic Astrophysics)

### Fast Sampling of Cosmological Initial Conditions with Gaussian Neural Posterior Estimation 
[[arxiv](https://arxiv.org/abs/2502.03139)] [[cool](https://papers.cool/arxiv/2502.03139)] [[pdf](https://arxiv.org/pdf/2502.03139)]
> **Authors**: Oleg Savchenko,Guillermo Franco Abellán,Florian List,Noemi Anau Montel,Christoph Weniger
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 9 + 2 pages, 7 figures, 1 table. Comments welcome!
- **标题**: None
- **领域**: 宇宙学和非银河系天体物理学,天体物理学仪器和方法,机器学习
- **Abstract**: Knowledge of the primordial matter density field from which the large-scale structure of the Universe emerged over cosmic time is of fundamental importance for cosmology. However, reconstructing these cosmological initial conditions from late-time observations is a notoriously difficult task, which requires advanced cosmological simulators and sophisticated statistical methods to explore a multi-million-dimensional parameter space. We show how simulation-based inference (SBI) can be used to tackle this problem and to obtain data-constrained realisations of the primordial dark matter density field in a simulation-efficient way with general non-differentiable simulators. Our method is applicable to full high-resolution dark matter $N$-body simulations and is based on modelling the posterior distribution of the constrained initial conditions to be Gaussian with a diagonal covariance matrix in Fourier space. As a result, we can generate thousands of posterior samples within seconds on a single GPU, orders of magnitude faster than existing methods, paving the way for sequential SBI for cosmological fields. Furthermore, we perform an analytical fit of the estimated dependence of the covariance on the wavenumber, effectively transforming any point-estimator of initial conditions into a fast sampler. We test the validity of our obtained samples by comparing them to the true values with summary statistics and performing a Bayesian consistency test.

## 无序系统和神经网络(cond-mat.dis-nn:Disordered Systems and Neural Networks)

### From Kernels to Features: A Multi-Scale Adaptive Theory of Feature Learning 
[[arxiv](https://arxiv.org/abs/2502.03210)] [[cool](https://papers.cool/arxiv/2502.03210)] [[pdf](https://arxiv.org/pdf/2502.03210)]
> **Authors**: Noa Rubin,Kirsten Fischer,Javed Lindner,David Dahmen,Inbar Seroussi,Zohar Ringel,Michael Krämer,Moritz Helias
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 24 pages, 6 figures
- **标题**: None
- **领域**: 无序系统和神经网络,机器学习,机器学习
- **Abstract**: Theoretically describing feature learning in neural networks is crucial for understanding their expressive power and inductive biases, motivating various approaches. Some approaches describe network behavior after training through a simple change in kernel scale from initialization, resulting in a generalization power comparable to a Gaussian process. Conversely, in other approaches training results in the adaptation of the kernel to the data, involving complex directional changes to the kernel. While these approaches capture different facets of network behavior, their relationship and respective strengths across scaling regimes remains an open question. This work presents a theoretical framework of multi-scale adaptive feature learning bridging these approaches. Using methods from statistical mechanics, we derive analytical expressions for network output statistics which are valid across scaling regimes and in the continuum between them. A systematic expansion of the network's probability distribution reveals that mean-field scaling requires only a saddle-point approximation, while standard scaling necessitates additional correction terms. Remarkably, we find across regimes that kernel adaptation can be reduced to an effective kernel rescaling when predicting the mean network output of a linear network. However, even in this case, the multi-scale adaptive approach captures directional feature learning effects, providing richer insights than what could be recovered from a rescaling of the kernel alone.

## 材料科学(cond-mat.mtrl-sci:Materials Science)

### Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials 
[[arxiv](https://arxiv.org/abs/2502.03660)] [[cool](https://papers.cool/arxiv/2502.03660)] [[pdf](https://arxiv.org/pdf/2502.03660)]
> **Authors**: Santiago Miret,Kin Long Kelvin Lee,Carmelo Gonzales,Sajid Mannan,N. M. Anoop Krishnan
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 材料科学,人工智能,机器学习
- **Abstract**: Universal Machine Learning Interactomic Potentials (MLIPs) enable accelerated simulations for materials discovery. However, current research efforts fail to impactfully utilize MLIPs due to: 1. Overreliance on Density Functional Theory (DFT) for MLIP training data creation; 2. MLIPs' inability to reliably and accurately perform large-scale molecular dynamics (MD) simulations for diverse materials; 3. Limited understanding of MLIPs' underlying capabilities. To address these shortcomings, we aargue that MLIP research efforts should prioritize: 1. Employing more accurate simulation methods for large-scale MLIP training data creation (e.g. Coupled Cluster Theory) that cover a wide range of materials design spaces; 2. Creating MLIP metrology tools that leverage large-scale benchmarking, visualization, and interpretability analyses to provide a deeper understanding of MLIPs' inner workings; 3. Developing computationally efficient MLIPs to execute MD simulations that accurately model a broad set of materials properties. Together, these interdisciplinary research directions can help further the real-world application of MLIPs to accurately model complex materials at device scale.

### SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models 
[[arxiv](https://arxiv.org/abs/2502.03638)] [[cool](https://papers.cool/arxiv/2502.03638)] [[pdf](https://arxiv.org/pdf/2502.03638)]
> **Authors**: Daniel Levy,Siba Smarak Panigrahi,Sékou-Oumar Kaba,Qiang Zhu,Kin Long Kelvin Lee,Mikhail Galkin,Santiago Miret,Siamak Ravanbakhsh
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 材料科学,机器学习
- **Abstract**: Generating novel crystalline materials has potential to lead to advancements in fields such as electronics, energy storage, and catalysis. The defining characteristic of crystals is their symmetry, which plays a central role in determining their physical properties. However, existing crystal generation methods either fail to generate materials that display the symmetries of real-world crystals, or simply replicate the symmetry information from examples in a database. To address this limitation, we propose SymmCD, a novel diffusion-based generative model that explicitly incorporates crystallographic symmetry into the generative process. We decompose crystals into two components and learn their joint distribution through diffusion: 1) the asymmetric unit, the smallest subset of the crystal which can generate the whole crystal through symmetry transformations, and; 2) the symmetry transformations needed to be applied to each atom in the asymmetric unit. We also use a novel and interpretable representation for these transformations, enabling generalization across different crystallographic symmetry groups. We showcase the competitive performance of SymmCD on a subset of the Materials Project, obtaining diverse and valid crystals with realistic symmetries and predicted properties.

### AI-driven materials design: a mini-review 
[[arxiv](https://arxiv.org/abs/2502.02905)] [[cool](https://papers.cool/arxiv/2502.02905)] [[pdf](https://arxiv.org/pdf/2502.02905)]
> **Authors**: Mouyang Cheng,Chu-Liang Fu,Ryotaro Okabe,Abhijatmedhi Chotrattanapituk,Artittaya Boonkird,Nguyen Tuan Hung,Mingda Li
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 18 pages, 7 figures, 1 table; Review article
- **标题**: None
- **领域**: 材料科学,机器学习
- **Abstract**: Materials design is an important component of modern science and technology, yet traditional approaches rely heavily on trial-and-error and can be inefficient. Computational techniques, enhanced by modern artificial intelligence (AI), have greatly accelerated the design of new materials. Among these approaches, inverse design has shown great promise in designing materials that meet specific property requirements. In this mini-review, we summarize key computational advancements for materials design over the past few decades. We follow the evolution of relevant materials design techniques, from high-throughput forward machine learning (ML) methods and evolutionary algorithms, to advanced AI strategies like reinforcement learning (RL) and deep generative models. We highlight the paradigm shift from conventional screening approaches to inverse generation driven by deep generative models. Finally, we discuss current challenges and future perspectives of materials inverse design. This review may serve as a brief guide to the approaches, progress, and outlook of designing future functional materials with technological relevance.

## 人工智能(cs.AI:Artificial Intelligence)

### Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2 
[[arxiv](https://arxiv.org/abs/2502.03544)] [[cool](https://papers.cool/arxiv/2502.03544)] [[pdf](https://arxiv.org/pdf/2502.03544)]
> **Authors**: Yuri Chervonyi,Trieu H. Trinh,Miroslav Olšák,Xiaomeng Yang,Hoang Nguyen,Marcelo Menegali,Junehyuk Jung,Vikas Verma,Quoc V. Le,Thang Luong
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 28 pages, 16 figures
- **标题**: None
- **领域**: 人工智能,机器学习
- **Abstract**: We present AlphaGeometry2, a significantly improved version of AlphaGeometry introduced in Trinh et al. (2024), which has now surpassed an average gold medalist in solving Olympiad geometry problems. To achieve this, we first extend the original AlphaGeometry language to tackle harder problems involving movements of objects, and problems containing linear equations of angles, ratios, and distances. This, together with other additions, has markedly improved the coverage rate of the AlphaGeometry language on International Math Olympiads (IMO) 2000-2024 geometry problems from 66% to 88%. The search process of AlphaGeometry2 has also been greatly improved through the use of Gemini architecture for better language modeling, and a novel knowledge-sharing mechanism that combines multiple search trees. Together with further enhancements to the symbolic engine and synthetic data generation, we have significantly boosted the overall solving rate of AlphaGeometry2 to 84% for $\textit{all}$ geometry problems over the last 25 years, compared to 54% previously. AlphaGeometry2 was also part of the system that achieved silver-medal standard at IMO 2024 https://dpmd.ai/imo-silver. Last but not least, we report progress towards using AlphaGeometry2 as a part of a fully automated system that reliably solves geometry problems directly from natural language input.

### YINYANG-ALIGN: Benchmarking Contradictory Objectives and Proposing Multi-Objective Optimization based DPO for Text-to-Image Alignment 
[[arxiv](https://arxiv.org/abs/2502.03512)] [[cool](https://papers.cool/arxiv/2502.03512)] [[pdf](https://arxiv.org/pdf/2502.03512)]
> **Authors**: Amitava Das,Yaswanth Narsupalli,Gurpreet Singh,Vinija Jain,Vasu Sharma,Suranjana Trivedy,Aman Chadha,Amit Sheth
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能
- **Abstract**: Precise alignment in Text-to-Image (T2I) systems is crucial to ensure that generated visuals not only accurately encapsulate user intents but also conform to stringent ethical and aesthetic benchmarks. Incidents like the Google Gemini fiasco, where misaligned outputs triggered significant public backlash, underscore the critical need for robust alignment mechanisms. In contrast, Large Language Models (LLMs) have achieved notable success in alignment. Building on these advancements, researchers are eager to apply similar alignment techniques, such as Direct Preference Optimization (DPO), to T2I systems to enhance image generation fidelity and reliability. We present YinYangAlign, an advanced benchmarking framework that systematically quantifies the alignment fidelity of T2I systems, addressing six fundamental and inherently contradictory design objectives. Each pair represents fundamental tensions in image generation, such as balancing adherence to user prompts with creative modifications or maintaining diversity alongside visual coherence. YinYangAlign includes detailed axiom datasets featuring human prompts, aligned (chosen) responses, misaligned (rejected) AI-generated outputs, and explanations of the underlying contradictions.

### Examining Two Hop Reasoning Through Information Content Scaling 
[[arxiv](https://arxiv.org/abs/2502.03490)] [[cool](https://papers.cool/arxiv/2502.03490)] [[pdf](https://arxiv.org/pdf/2502.03490)]
> **Authors**: David Johnston,Nora Belrose
> **First submission**: 2025-02-04
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能,机器学习
- **Abstract**: Prior work has found that transformers have an inconsistent ability to learn to answer latent two-hop questions -- questions of the form "Who is Bob's mother's boss?" We study why this is the case by examining how transformers' capacity to learn datasets of two-hop questions and answers (two-hop QA) scales with their size, motivated by prior work on transformer knowledge capacity for simple factual memorization. We find that capacity scaling and generalization both support the hypothesis that latent two-hop QA requires transformers to learn each fact twice, while two-hop QA with chain of thought does not. We also show that with appropriate dataset parameters, it is possible to "trap" very small models in a regime where they memorize answers to two-hop questions independently, even though they would perform better if they could learn to answer them with function composition. Our findings show that measurement of capacity scaling can complement existing interpretability methods, though there are challenges in using it for this purpose.

### BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving 
[[arxiv](https://arxiv.org/abs/2502.03438)] [[cool](https://papers.cool/arxiv/2502.03438)] [[pdf](https://arxiv.org/pdf/2502.03438)]
> **Authors**: Ran Xin,Chenguang Xi,Jie Yang,Feng Chen,Hang Wu,Xia Xiao,Yifan Sun,Shen Zheng,Kai Shen
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能
- **Abstract**: Recent advancements in large language models (LLMs) have spurred growing interest in automatic theorem proving using Lean4, where effective tree search methods are crucial for navigating the underlying large proof search spaces. While the existing approaches primarily rely on value functions and/or Monte Carlo Tree Search (MCTS), the potential of simpler methods like Best-First Tree Search (BFS) remains underexplored. In this paper, we investigate whether BFS can achieve competitive performance in large-scale theorem proving tasks. We present BFS-Prover, a scalable expert iteration framework, featuring three key innovations. First, we implement strategic data filtering at each expert iteration round, excluding problems solvable via beam search node expansion to focus on harder cases. Second, we improve the sample efficiency of BFS through Direct Preference Optimization (DPO) applied to state-tactic pairs automatically annotated with compiler error feedback, refining the LLM's policy to prioritize productive expansions. Third, we employ length normalization in BFS to encourage exploration of deeper proof paths. BFS-Prover achieves a state-of-the-art score of $72.95\%$ on the MiniF2F test set and therefore challenges the perceived necessity of complex tree search methods, demonstrating that BFS can achieve competitive performance when properly scaled. To facilitate further research and development in this area, we have open-sourced our model at https://huggingface.co/bytedance-research/BFS-Prover.

### Learning from Active Human Involvement through Proxy Value Propagation 
[[arxiv](https://arxiv.org/abs/2502.03369)] [[cool](https://papers.cool/arxiv/2502.03369)] [[pdf](https://arxiv.org/pdf/2502.03369)]
> **Authors**: Zhenghao Peng,Wenjie Mo,Chenda Duan,Quanyi Li,Bolei Zhou
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: NeurIPS 2023 Spotlight. Project page: https://metadriverse.github.io/pvp
- **标题**: None
- **领域**: 人工智能,机器人技术
- **Abstract**: Learning from active human involvement enables the human subject to actively intervene and demonstrate to the AI agent during training. The interaction and corrective feedback from human brings safety and AI alignment to the learning process. In this work, we propose a new reward-free active human involvement method called Proxy Value Propagation for policy optimization. Our key insight is that a proxy value function can be designed to express human intents, wherein state-action pairs in the human demonstration are labeled with high values, while those agents' actions that are intervened receive low values. Through the TD-learning framework, labeled values of demonstrated state-action pairs are further propagated to other unlabeled data generated from agents' exploration. The proxy value function thus induces a policy that faithfully emulates human behaviors. Human-in-the-loop experiments show the generality and efficiency of our method. With minimal modification to existing reinforcement learning algorithms, our method can learn to solve continuous and discrete control tasks with various human control devices, including the challenging task of driving in Grand Theft Auto V. Demo video and code are available at: https://metadriverse.github.io/pvp

### PalimpChat: Declarative and Interactive AI analytics 
[[arxiv](https://arxiv.org/abs/2502.03368)] [[cool](https://papers.cool/arxiv/2502.03368)] [[pdf](https://arxiv.org/pdf/2502.03368)]
> **Authors**: Chunwei Liu,Gerardo Vitagliano,Brandon Rose,Matt Prinz,David Andrew Samson,Michael Cafarella
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能,数据库,信息检索
- **Abstract**: Thanks to the advances in generative architectures and large language models, data scientists can now code pipelines of machine-learning operations to process large collections of unstructured data. Recent progress has seen the rise of declarative AI frameworks (e.g., Palimpzest, Lotus, and DocETL) to build optimized and increasingly complex pipelines, but these systems often remain accessible only to expert programmers. In this demonstration, we present PalimpChat, a chat-based interface to Palimpzest that bridges this gap by letting users create and run sophisticated AI pipelines through natural language alone. By integrating Archytas, a ReAct-based reasoning agent, and Palimpzest's suite of relational and LLM-based operators, PalimpChat provides a practical illustration of how a chat interface can make declarative AI frameworks truly accessible to non-experts. Our demo system is publicly available online. At SIGMOD'25, participants can explore three real-world scenarios--scientific discovery, legal discovery, and real estate search--or apply PalimpChat to their own datasets. In this paper, we focus on how PalimpChat, supported by the Palimpzest optimizer, simplifies complex AI workflows such as extracting and analyzing biomedical data.

### SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs 
[[arxiv](https://arxiv.org/abs/2502.03283)] [[cool](https://papers.cool/arxiv/2502.03283)] [[pdf](https://arxiv.org/pdf/2502.03283)]
> **Authors**: Ben Liu,Jihai Zhang,Fangquan Lin,Cheng Yang,Min Peng,Wotao Yin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能,计算语言学,机器学习
- **Abstract**: Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates.

### A Scalable Approach to Probabilistic Neuro-Symbolic Verification 
[[arxiv](https://arxiv.org/abs/2502.03274)] [[cool](https://papers.cool/arxiv/2502.03274)] [[pdf](https://arxiv.org/pdf/2502.03274)]
> **Authors**: Vasileios Manginas,Nikolaos Manginas,Edward Stevinson,Sherwin Varghese,Nikos Katzouris,Georgios Paliouras,Alessio Lomuscio
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能
- **Abstract**: Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising direction for integrating neural learning with symbolic reasoning. In the probabilistic variant of such systems, a neural network first extracts a set of symbols from sub-symbolic input, which are then used by a symbolic component to reason in a probabilistic manner towards answering a query. In this work, we address the problem of formally verifying the robustness of such NeSy probabilistic reasoning systems, therefore paving the way for their safe deployment in critical domains. We analyze the complexity of solving this problem exactly, and show that it is $\mathrm{NP}^{\# \mathrm{P}}$-hard. To overcome this issue, we propose the first approach for approximate, relaxation-based verification of probabilistic NeSy systems. We demonstrate experimentally that the proposed method scales exponentially better than solver-based solutions and apply our technique to a real-world autonomous driving dataset, where we verify a safety property under large input dimensionalities and network sizes.

### CORTEX: A Cost-Sensitive Rule and Tree Extraction Method 
[[arxiv](https://arxiv.org/abs/2502.03200)] [[cool](https://papers.cool/arxiv/2502.03200)] [[pdf](https://arxiv.org/pdf/2502.03200)]
> **Authors**: Marija Kopanja,Miloš Savić,Luca Longo
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能,机器学习
- **Abstract**: Tree-based and rule-based machine learning models play pivotal roles in explainable artificial intelligence (XAI) due to their unique ability to provide explanations in the form of tree or rule sets that are easily understandable and interpretable, making them essential for applications in which trust in model decisions is necessary. These transparent models are typically used in surrogate modeling, a post-hoc XAI approach for explaining the logic of black-box models, enabling users to comprehend and trust complex predictive systems while maintaining competitive performance. This study proposes the Cost-Sensitive Rule and Tree Extraction (CORTEX) method, a novel rule-based XAI algorithm grounded in the multi-class cost-sensitive decision tree (CSDT) method. The original version of the CSDT is extended to classification problems with more than two classes by inducing the concept of an n-dimensional class-dependent cost matrix. The performance of CORTEX as a rule-extractor XAI method is compared to other post-hoc tree and rule extraction methods across several datasets with different numbers of classes. Several quantitative evaluation metrics are employed to assess the explainability of generated rule sets. Our findings demonstrate that CORTEX is competitive with other tree-based methods and can be superior to other rule-based methods across different datasets. The extracted rule sets suggest the advantages of using the CORTEX method over other methods by producing smaller rule sets with shorter rules on average across datasets with a diverse number of classes. Overall, the results underscore the potential of CORTEX as a powerful XAI tool for scenarios that require the generation of clear, human-understandable rules while maintaining good predictive performance.

### The Cake that is Intelligence and Who Gets to Bake it: An AI Analogy and its Implications for Participation 
[[arxiv](https://arxiv.org/abs/2502.03038)] [[cool](https://papers.cool/arxiv/2502.03038)] [[pdf](https://arxiv.org/pdf/2502.03038)]
> **Authors**: Martin Mundt,Anaelia Ovalle,Felix Friedrich,A Pranav,Subarnaduti Paul,Manuel Brack,Kristian Kersting,William Agnew
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能,计算机与社会,机器学习
- **Abstract**: In a widely popular analogy by Turing Award Laureate Yann LeCun, machine intelligence has been compared to cake - where unsupervised learning forms the base, supervised learning adds the icing, and reinforcement learning is the cherry on top. We expand this 'cake that is intelligence' analogy from a simple structural metaphor to the full life-cycle of AI systems, extending it to sourcing of ingredients (data), conception of recipes (instructions), the baking process (training), and the tasting and selling of the cake (evaluation and distribution). Leveraging our re-conceptualization, we describe each step's entailed social ramifications and how they are bounded by statistical assumptions within machine learning. Whereas these technical foundations and social impacts are deeply intertwined, they are often studied in isolation, creating barriers that restrict meaningful participation. Our re-conceptualization paves the way to bridge this gap by mapping where technical foundations interact with social outcomes, highlighting opportunities for cross-disciplinary dialogue. Finally, we conclude with actionable recommendations at each stage of the metaphorical AI cake's life-cycle, empowering prospective AI practitioners, users, and researchers, with increased awareness and ability to engage in broader AI discourse.

### (Neural-Symbolic) Machine Learning for Inconsistency Measurement 
[[arxiv](https://arxiv.org/abs/2502.02963)] [[cool](https://papers.cool/arxiv/2502.02963)] [[pdf](https://arxiv.org/pdf/2502.02963)]
> **Authors**: Sven Weinzierl,Carl Cora
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能
- **Abstract**: We present machine-learning-based approaches for determining the \emph{degree} of inconsistency -- which is a numerical value -- for propositional logic knowledge bases. Specifically, we present regression- and neural-based models that learn to predict the values that the inconsistency measures $\incmi$ and $\incat$ would assign to propositional logic knowledge bases. Our main motivation is that computing these values conventionally can be hard complexity-wise. As an important addition, we use specific postulates, that is, properties, of the underlying inconsistency measures to infer symbolic rules, which we combine with the learning-based models in the form of constraints. We perform various experiments and show that a) predicting the degree values is feasible in many situations, and b) including the symbolic constraints deduced from the rationality postulates increases the prediction quality.

## 计算语言学(cs.CL:Computation and Language)

### Hierarchical Contextual Manifold Alignment for Structuring Latent Representations in Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.03766)] [[cool](https://papers.cool/arxiv/2502.03766)] [[pdf](https://arxiv.org/pdf/2502.03766)]
> **Authors**: Meiquan Dong,Haoran Liu,Yan Huang,Zixuan Feng,Jianhong Tang,Ruoxi Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: The organization of latent token representations plays a crucial role in determining the stability, generalization, and contextual consistency of language models, yet conventional approaches to embedding refinement often rely on parameter modifications that introduce additional computational overhead. A hierarchical alignment method was introduced to restructure token embeddings without altering core model weights, ensuring that representational distributions maintained coherence across different linguistic contexts. Experimental evaluations demonstrated improvements in rare token retrieval, adversarial robustness, and long-range dependency tracking, highlighting the advantages of hierarchical structuring in mitigating inconsistencies in latent space organization. The comparative analysis against conventional fine-tuning and embedding perturbation methods revealed that hierarchical restructuring maintained computational efficiency while achieving measurable gains in representation quality. Structural refinements introduced through the alignment process resulted in improved contextual stability across varied linguistic tasks, reducing inconsistencies in token proximity relationships and enhancing interpretability in language generation. A detailed computational assessment confirmed that the realignment process introduced minimal inference overhead, ensuring that representational improvements did not compromise model efficiency. The findings reinforced the broader significance of structured representation learning, illustrating that hierarchical embedding modifications could serve as an effective strategy for refining latent space distributions while preserving pre-learned semantic associations.

### Rethinking the Residual Distribution of Locate-then-Editing Methods in Model Editing 
[[arxiv](https://arxiv.org/abs/2502.03748)] [[cool](https://papers.cool/arxiv/2502.03748)] [[pdf](https://arxiv.org/pdf/2502.03748)]
> **Authors**: Xiaopeng Li,Shanwen Wang,Shasha Li,Shezheng Song,Bin Ji,Jun Ma,Jie Yu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Preprint
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Model editing is a powerful technique for updating the knowledge of Large Language Models (LLMs). Locate-then-edit methods are a popular class of approaches that first identify the critical layers storing knowledge, then compute the residual of the last critical layer based on the edited knowledge, and finally perform multi-layer updates using a least-squares solution by evenly distributing the residual from the first critical layer to the last. Although these methods achieve promising results, they have been shown to degrade the original knowledge of LLMs. We argue that residual distribution leads to this issue. To explore this, we conduct a comprehensive analysis of residual distribution in locate-then-edit methods from both empirical and theoretical perspectives, revealing that residual distribution introduces editing errors, leading to inaccurate edits. To address this issue, we propose the Boundary Layer UpdatE (BLUE) strategy to enhance locate-then-edit methods. Sequential batch editing experiments on three LLMs and two datasets demonstrate that BLUE not only delivers an average performance improvement of 35.59\%, significantly advancing the state of the art in model editing, but also enhances the preservation of LLMs' general capabilities. Our code is available at https://github.com/xpq-tech/BLUE.

### MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers 
[[arxiv](https://arxiv.org/abs/2502.03711)] [[cool](https://papers.cool/arxiv/2502.03711)] [[pdf](https://arxiv.org/pdf/2502.03711)]
> **Authors**: Nicole Cho,William Watson
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: AAAI 2025 Workshop on Preventing and DetectingLLMMisinformation (PDLM) (Oral)
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: One critical challenge in the institutional adoption journey of Large Language Models (LLMs) stems from their propensity to hallucinate in generated responses. To address this, we propose MultiQ&A, a systematic approach for evaluating the robustness and consistency of LLM-generated answers. We demonstrate MultiQ&A's ability to crowdsource question perturbations and their respective answers through independent LLM agents at scale. Our experiments culminated in the examination of 1.9 million question perturbations and 2.3 million answers. Furthermore, MultiQ&A shows that ensembled LLMs, such as gpt-3.5-turbo, remain relatively robust and consistent under perturbations. MultiQ&A provides clarity in the response generation space, offering an effective method for inspecting disagreements and variability. Therefore, our system offers a potential framework for institutional LLM adoption with the ability to measure confidence, consistency, and the quantification of hallucinations.

### Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers 
[[arxiv](https://arxiv.org/abs/2502.03708)] [[cool](https://papers.cool/arxiv/2502.03708)] [[pdf](https://arxiv.org/pdf/2502.03708)]
> **Authors**: Daniel Beaglehole,Adityanarayanan Radhakrishnan,Enric Boix-Adserà,Mikhail Belkin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: A trained Large Language Model (LLM) contains much of human knowledge. Yet, it is difficult to gauge the extent or accuracy of that knowledge, as LLMs do not always ``know what they know'' and may even be actively misleading. In this work, we give a general method for detecting semantic concepts in the internal activations of LLMs. Furthermore, we show that our methodology can be easily adapted to steer LLMs toward desirable outputs. Our innovations are the following: (1) we use a nonlinear feature learning method to identify important linear directions for predicting concepts from each layer; (2) we aggregate features across layers to build powerful concept detectors and steering mechanisms. We showcase the power of our approach by attaining state-of-the-art results for detecting hallucinations, harmfulness, toxicity, and untruthful content on seven benchmarks. We highlight the generality of our approach by steering LLMs towards new concepts that, to the best of our knowledge, have not been previously considered in the literature, including: semantic disambiguation, human languages, programming languages, hallucinated responses, science subjects, poetic/Shakespearean English, and even multiple concepts simultaneously. Moreover, our method can steer concepts with numerical attributes such as product reviews. We provide our code (including a simple API for our methods) at https://github.com/dmbeaglehole/neural_controllers .

### LLM Alignment as Retriever Optimization: An Information Retrieval Perspective 
[[arxiv](https://arxiv.org/abs/2502.03699)] [[cool](https://papers.cool/arxiv/2502.03699)] [[pdf](https://arxiv.org/pdf/2502.03699)]
> **Authors**: Bowen Jin,Jinsung Yoon,Zhen Qin,Ziqi Wang,Wei Xiong,Yu Meng,Jiawei Han,Sercan O. Arik
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 26 pages
- **标题**: None
- **领域**: 计算语言学,人工智能,信息检索
- **Abstract**: Large Language Models (LLMs) have revolutionized artificial intelligence with capabilities in reasoning, coding, and communication, driving innovation across industries. Their true potential depends on effective alignment to ensure correct, trustworthy and ethical behavior, addressing challenges like misinformation, hallucinations, bias and misuse. While existing Reinforcement Learning (RL)-based alignment methods are notoriously complex, direct optimization approaches offer a simpler alternative. In this work, we introduce a novel direct optimization approach for LLM alignment by drawing on established Information Retrieval (IR) principles. We present a systematic framework that bridges LLM alignment and IR methodologies, mapping LLM generation and reward models to IR's retriever-reranker paradigm. Building on this foundation, we propose LLM Alignment as Retriever Preference Optimization (LarPO), a new alignment method that enhances overall alignment quality. Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 % averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work opens new avenues for advancing LLM alignment by integrating IR foundations, offering a promising direction for future research.

### A Comparison of DeepSeek and Other LLMs 
[[arxiv](https://arxiv.org/abs/2502.03688)] [[cool](https://papers.cool/arxiv/2502.03688)] [[pdf](https://arxiv.org/pdf/2502.03688)]
> **Authors**: Tianchen Gao,Jiashun Jin,Zheng Tracy Ke,Gabriel Moryoussef
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 21 pages, 5 figures, 6 tables
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Recently, DeepSeek has been the focus of attention in and beyond the AI community. An interesting problem is how DeepSeek compares to other large language models (LLMs). There are many tasks an LLM can do, and in this paper, we use the task of predicting an outcome using a short text for comparison. We consider two settings, an authorship classification setting and a citation classification setting. In the first one, the goal is to determine whether a short text is written by human or AI. In the second one, the goal is to classify a citation to one of four types using the textual content. For each experiment, we compare DeepSeek with $4$ popular LLMs: Claude, Gemini, GPT, and Llama. We find that, in terms of classification accuracy, DeepSeek outperforms Gemini, GPT, and Llama in most cases, but underperforms Claude. We also find that DeepSeek is comparably slower than others but with a low cost to use, while Claude is much more expensive than all the others. Finally, we find that in terms of similarity, the output of DeepSeek is most similar to those of Gemini and Claude (and among all $5$ LLMs, Claude and Gemini have the most similar outputs). In this paper, we also present a fully-labeled dataset collected by ourselves, and propose a recipe where we can use the LLMs and a recent data set, MADStat, to generate new data sets. The datasets in our paper can be used as benchmarks for future study on LLMs.

### Controlled LLM Decoding via Discrete Auto-regressive Biasing 
[[arxiv](https://arxiv.org/abs/2502.03685)] [[cool](https://papers.cool/arxiv/2502.03685)] [[pdf](https://arxiv.org/pdf/2502.03685)]
> **Authors**: Patrick Pynadath,Ruqi Zhang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,机器学习,机器学习
- **Abstract**: Controlled text generation allows for enforcing user-defined constraints on large language model outputs, an increasingly important field as LLMs become more prevalent in everyday life. One common approach uses energy-based decoding, which defines a target distribution through an energy function that combines multiple constraints into a weighted average. However, these methods often struggle to balance fluency with constraint satisfaction, even with extensive tuning of the energy function's coefficients. In this paper, we identify that this suboptimal balance arises from sampling in continuous space rather than the natural discrete space of text tokens. To address this, we propose Discrete Auto-regressive Biasing, a controlled decoding algorithm that leverages gradients while operating entirely in the discrete text domain. Specifically, we introduce a new formulation for controlled text generation by defining a joint distribution over the generated sequence and an auxiliary bias sequence. To efficiently sample from this joint distribution, we propose a Langevin-within-Gibbs sampling algorithm using gradient-based discrete MCMC. Our method significantly improves constraint satisfaction while maintaining comparable or better fluency, all with even lower computational costs. We demonstrate the advantages of our controlled decoding method on sentiment control, language detoxification, and keyword-guided generation.

### Reflection-Window Decoding: Text Generation with Selective Refinement 
[[arxiv](https://arxiv.org/abs/2502.03678)] [[cool](https://papers.cool/arxiv/2502.03678)] [[pdf](https://arxiv.org/pdf/2502.03678)]
> **Authors**: Zeyu Tang,Zhenhao Chen,Loka Li,Xiangchen Song,Yunlong Deng,Yifan Shen,Guangyi Chen,Peter Spirtes,Kun Zhang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: The autoregressive decoding for text generation in large language models (LLMs), while widely used, is inherently suboptimal due to the lack of a built-in mechanism to perform refinement and/or correction of the generated content. In this paper, we consider optimality in terms of the joint probability over the generated response, when jointly considering all tokens at the same time. We theoretically characterize the potential deviation of the autoregressively generated response from its globally optimal counterpart that is of the same length. Our analysis suggests that we need to be cautious when noticeable uncertainty arises during text generation, which may signal the sub-optimality of the generation history. To address the pitfall of autoregressive decoding for text generation, we propose an approach that incorporates a sliding reflection window and a pausing criterion, such that refinement and generation can be carried out interchangeably as the decoding proceeds. Our selective refinement framework strikes a balance between efficiency and optimality, and our extensive experimental results demonstrate the effectiveness of our approach.

### Advancing Reasoning in Large Language Models: Promising Methods and Approaches 
[[arxiv](https://arxiv.org/abs/2502.03671)] [[cool](https://papers.cool/arxiv/2502.03671)] [[pdf](https://arxiv.org/pdf/2502.03671)]
> **Authors**: Avinash Patil
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 9 Pages, 1 Figure, IEEE Format
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Large Language Models (LLMs) have succeeded remarkably in various natural language processing (NLP) tasks, yet their reasoning capabilities remain a fundamental challenge. While LLMs exhibit impressive fluency and factual recall, their ability to perform complex reasoning-spanning logical deduction, mathematical problem-solving, commonsense inference, and multi-step reasoning-often falls short of human expectations. This survey provides a comprehensive review of emerging techniques enhancing reasoning in LLMs. We categorize existing methods into key approaches, including prompting strategies (e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought reasoning), architectural innovations (e.g., retrieval-augmented models, modular reasoning networks, and neuro-symbolic integration), and learning paradigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement learning, and self-supervised reasoning objectives). Additionally, we explore evaluation frameworks used to assess reasoning in LLMs and highlight open challenges, such as hallucinations, robustness, and reasoning generalization across diverse tasks. By synthesizing recent advancements, this survey aims to provide insights into promising directions for future research and practical applications of reasoning-augmented LLMs.

### Looking for the Inner Music: Probing LLMs' Understanding of Literary Style 
[[arxiv](https://arxiv.org/abs/2502.03647)] [[cool](https://papers.cool/arxiv/2502.03647)] [[pdf](https://arxiv.org/pdf/2502.03647)]
> **Authors**: Rebecca M. M. Hicke,David Mimno
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,机器学习
- **Abstract**: Recent work has demonstrated that language models can be trained to identify the author of much shorter literary passages than has been thought feasible for traditional stylometry. We replicate these results for authorship and extend them to a new dataset measuring novel genre. We find that LLMs are able to distinguish authorship and genre, but they do so in different ways. Some models seem to rely more on memorization, while others benefit more from training to learn author/genre characteristics. We then use three methods to probe one high-performing LLM for features that define style. These include direct syntactic ablations to input text as well as two methods that look at model internals. We find that authorial style is easier to define than genre-level style and is more impacted by minor syntactic decisions and contextual word usage. However, some traits like pronoun usage and word order prove significant for defining both kinds of literary style.

### Context-Preserving Gradient Modulation for Large Language Models: A Novel Approach to Semantic Consistency in Long-Form Text Generation 
[[arxiv](https://arxiv.org/abs/2502.03643)] [[cool](https://papers.cool/arxiv/2502.03643)] [[pdf](https://arxiv.org/pdf/2502.03643)]
> **Authors**: Nirola Kobanov,Edmund Weatherstone,Zachary Vanderpoel,Orlando Wetherby
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Maintaining semantic consistency over extended text sequences remains a fundamental challenge in long-form text generation, where conventional training methodologies often struggle to prevent contextual drift and coherence degradation. A novel gradient modulation approach is introduced, designed to adjust parameter updates dynamically in response to contextual relevance, ensuring that generated text remains aligned with prior discourse. By integrating a modulation function that selectively amplifies or attenuates gradients based on learned contextual dependencies, the proposed method enhances the stability of model-generated narratives without imposing significant computational overhead. Comparative evaluations against baseline models reveal improvements in coherence, contextual retention, and long-range dependency tracking, demonstrating the effectiveness of modifying the learning process at the gradient level. The results indicate that sentence structure variability and lexical diversity benefit from this approach, mitigating repetitive phrasing and improving adaptability across diverse linguistic contexts. Statistical validation of coherence metrics further substantiates the observed enhancements, with a significant reduction in inconsistencies emerging as a direct consequence of the modulation mechanism. Computational efficiency assessments confirm that the framework achieves these gains without requiring substantial modifications to the underlying architecture, ensuring compatibility with existing optimization workflows.

### Sorting the Babble in Babel: Assessing the Performance of Language Detection Algorithms on the OpenAlex Database 
[[arxiv](https://arxiv.org/abs/2502.03627)] [[cool](https://papers.cool/arxiv/2502.03627)] [[pdf](https://arxiv.org/pdf/2502.03627)]
> **Authors**: Maxime Holmberg Sainte-Marie,Diego Kozlowski,Lucía Céspedes,Vincent Larivière
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 33 pages, 4 figures
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: This project aims to compare various language classification procedures, procedures combining various Python language detection algorithms and metadata-based corpora extracted from manually-annotated articles sampled from the OpenAlex database. Following an analysis of precision and recall performance for each algorithm, corpus, and language as well as of processing speeds recorded for each algorithm and corpus type, overall procedure performance at the database level was simulated using probabilistic confusion matrices for each algorithm, corpus, and language as well as a probabilistic model of relative article language frequencies for the whole OpenAlex database. Results show that procedure performance strongly depends on the importance given to each of the measures implemented: for contexts where precision is preferred, using the LangID algorithm on the greedy corpus gives the best results; however, for all cases where recall is considered at least slightly more important than precision or as soon as processing times are given any kind of consideration, the procedure combining the FastSpell algorithm and the Titles corpus outperforms all other alternatives. Given the lack of truly multilingual, large-scale bibliographic databases, it is hoped that these results help confirm and foster the unparalleled potential of the OpenAlex database for cross-linguistic, bibliometric-based research and analysis.

### On Fairness of Unified Multimodal Large Language Model for Image Generation 
[[arxiv](https://arxiv.org/abs/2502.03429)] [[cool](https://papers.cool/arxiv/2502.03429)] [[pdf](https://arxiv.org/pdf/2502.03429)]
> **Authors**: Ming Liu,Hao Chen,Jindong Wang,Liwen Wang,Bhiksha Raj Ramakrishnan,Wensheng Zhang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Unified multimodal large language models (U-MLLMs) have demonstrated impressive performance in visual understanding and generation in an end-to-end pipeline. Compared with generation-only models (e.g., Stable Diffusion), U-MLLMs may raise new questions about bias in their outputs, which can be affected by their unified capabilities. This gap is particularly concerning given the under-explored risk of propagating harmful stereotypes. In this paper, we benchmark the latest U-MLLMs and find that most exhibit significant demographic biases, such as gender and race bias. To better understand and mitigate this issue, we propose a locate-then-fix strategy, where we audit and show how the individual model component is affected by bias. Our analysis shows that bias originates primarily from the language model. More interestingly, we observe a "partial alignment" phenomenon in U-MLLMs, where understanding bias appears minimal, but generation bias remains substantial. Thus, we propose a novel balanced preference model to balance the demographic distribution with synthetic data. Experiments demonstrate that our approach reduces demographic bias while preserving semantic fidelity. We hope our findings underscore the need for more holistic interpretation and debiasing strategies of U-MLLMs in the future.

### Think or Step-by-Step? UnZIPping the Black Box in Zero-Shot Prompts 
[[arxiv](https://arxiv.org/abs/2502.03418)] [[cool](https://papers.cool/arxiv/2502.03418)] [[pdf](https://arxiv.org/pdf/2502.03418)]
> **Authors**: Nikta Gohari Sadr,Sangmitra Madhusudan,Ali Emami
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages (excluding references)
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Zero-shot prompting techniques have significantly improved the performance of Large Language Models (LLMs). However, we lack a clear understanding of why zero-shot prompts are so effective. For example, in the prompt "Let's think step-by-step," is "think" or "step-by-step" more crucial to its success? Existing interpretability methods, such as gradient-based and attention-based approaches, are computationally intensive and restricted to open-source models. We introduce the ZIP score (Zero-shot Importance of Perturbation score), a versatile metric applicable to both open and closed-source models, based on systematic input word perturbations. Our experiments across four recent LLMs, seven widely-used prompts, and several tasks, reveal interesting patterns in word importance. For instance, while both 'step-by-step' and 'think' show high ZIP scores, which one is more influential depends on the model and task. We validate our method using controlled experiments and compare our results with human judgments, finding that proprietary models align more closely with human intuition regarding word significance. These findings enhance our understanding of LLM behavior and contribute to developing more effective zero-shot prompts and improved model analysis.

### SPRI: Aligning Large Language Models with Context-Situated Principles 
[[arxiv](https://arxiv.org/abs/2502.03397)] [[cool](https://papers.cool/arxiv/2502.03397)] [[pdf](https://arxiv.org/pdf/2502.03397)]
> **Authors**: Hongli Zhan,Muneeza Azmat,Raya Horesh,Junyi Jessy Li,Mikhail Yurochkin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Aligning Large Language Models to integrate and reflect human values, especially for tasks that demand intricate human oversight, is arduous since it is resource-intensive and time-consuming to depend on human expertise for context-specific guidance. Prior work has utilized predefined sets of rules or principles to steer the behavior of models (Bai et al., 2022; Sun et al., 2023). However, these principles tend to be generic, making it challenging to adapt them to each individual input query or context. In this work, we present Situated-PRInciples (SPRI), a framework requiring minimal or no human effort that is designed to automatically generate guiding principles in real-time for each input query and utilize them to align each response. We evaluate SPRI on three tasks, and show that 1) SPRI can derive principles in a complex domain-specific task that leads to on-par performance as expert-crafted ones; 2) SPRI-generated principles lead to instance-specific rubrics that outperform prior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data leads to substantial improvement on truthfulness. We release our code and model generations at https://github.com/honglizhan/SPRI-public.

### LIMO: Less is More for Reasoning 
[[arxiv](https://arxiv.org/abs/2502.03387)] [[cool](https://papers.cool/arxiv/2502.03387)] [[pdf](https://arxiv.org/pdf/2502.03387)]
> **Authors**: Yixin Ye,Zhen Huang,Yang Xiao,Ethan Chern,Shijie Xia,Pengfei Liu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 17 pages
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (>100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from previous SFT-based models' 6.5% and 59.2% respectively, while only using 1% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model's encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as "cognitive templates" that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at https://github.com/GAIR-NLP/LIMO.

### High-Fidelity Simultaneous Speech-To-Speech Translation 
[[arxiv](https://arxiv.org/abs/2502.03382)] [[cool](https://papers.cool/arxiv/2502.03382)] [[pdf](https://arxiv.org/pdf/2502.03382)]
> **Authors**: Tom Labiausse,Laurent Mazaré,Edouard Grave,Patrick Pérez,Alexandre Défossez,Neil Zeghidour
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,声音,音频和语音处理
- **Abstract**: We introduce Hibiki, a decoder-only model for simultaneous speech translation. Hibiki leverages a multistream language model to synchronously process source and target speech, and jointly produces text and audio tokens to perform speech-to-text and speech-to-speech translation. We furthermore address the fundamental challenge of simultaneous interpretation, which unlike its consecutive counterpart, where one waits for the end of the source utterance to start translating, adapts its flow to accumulate just enough context to produce a correct translation in real-time, chunk by chunk. To do so, we introduce a weakly-supervised method that leverages the perplexity of an off-the-shelf text translation system to identify optimal delays on a per-word basis and create aligned synthetic data. After supervised training, Hibiki performs adaptive, simultaneous speech translation with vanilla temperature sampling. On a French-English simultaneous speech translation task, Hibiki demonstrates state-of-the-art performance in translation quality, speaker fidelity and naturalness. Moreover, the simplicity of its inference process makes it compatible with batched translation and even real-time on-device deployment. We provide examples as well as models and inference code.

### Demystifying Long Chain-of-Thought Reasoning in LLMs 
[[arxiv](https://arxiv.org/abs/2502.03373)] [[cool](https://papers.cool/arxiv/2502.03373)] [[pdf](https://arxiv.org/pdf/2502.03373)]
> **Authors**: Edward Yeo,Yuxuan Tong,Morry Niu,Graham Neubig,Xiang Yue
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Preprint, under review
- **标题**: None
- **领域**: 计算语言学,机器学习
- **Abstract**: Scaling inference compute enhances reasoning in large language models (LLMs), with long chains-of-thought (CoTs) enabling strategies like backtracking and error correction. Reinforcement learning (RL) has emerged as a crucial method for developing these capabilities, yet the conditions under which long CoTs emerge remain unclear, and RL training requires careful design choices. In this study, we systematically investigate the mechanics of long CoT reasoning, identifying the key factors that enable models to generate long CoT trajectories. Through extensive supervised fine-tuning (SFT) and RL experiments, we present four main findings: (1) While SFT is not strictly necessary, it simplifies training and improves efficiency; (2) Reasoning capabilities tend to emerge with increased training compute, but their development is not guaranteed, making reward shaping crucial for stabilizing CoT length growth; (3) Scaling verifiable reward signals is critical for RL. We find that leveraging noisy, web-extracted solutions with filtering mechanisms shows strong potential, particularly for out-of-distribution (OOD) tasks such as STEM reasoning; and (4) Core abilities like error correction are inherently present in base models, but incentivizing these skills effectively for complex tasks via RL demands significant compute, and measuring their emergence requires a nuanced approach. These insights provide practical guidance for optimizing training strategies to enhance long CoT reasoning in LLMs. Our code is available at: https://github.com/eddycmu/demystify-long-cot.

### Minerva: A Programmable Memory Test Benchmark for Language Models 
[[arxiv](https://arxiv.org/abs/2502.03358)] [[cool](https://papers.cool/arxiv/2502.03358)] [[pdf](https://arxiv.org/pdf/2502.03358)]
> **Authors**: Menglin Xia,Victor Ruehle,Saravan Rajmohan,Reza Shokri
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: How effectively can LLM-based AI assistants utilize their memory (context) to perform various tasks? Traditional data benchmarks, which are often manually crafted, suffer from several limitations: they are static, susceptible to overfitting, difficult to interpret, and lack actionable insights--failing to pinpoint the specific capabilities a model lacks when it does not pass a test. In this paper, we present a framework for automatically generating a comprehensive set of tests to evaluate models' abilities to use their memory effectively. Our framework extends the range of capability tests beyond the commonly explored (passkey, key-value, needle in the haystack) search, a dominant focus in the literature. Specifically, we evaluate models on atomic tasks such as searching, recalling, editing, matching, comparing information in context memory, and performing basic operations when inputs are structured into distinct blocks, simulating real-world data. Additionally, we design composite tests to investigate the models' ability to maintain state while operating on memory. Our benchmark enables an interpretable, detailed assessment of memory capabilities of LLMs.

### ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model 
[[arxiv](https://arxiv.org/abs/2502.03325)] [[cool](https://papers.cool/arxiv/2502.03325)] [[pdf](https://arxiv.org/pdf/2502.03325)]
> **Authors**: Qiguang Chen,Libo Qin,Jinhao Liu,Dengyun Peng,Jiaqi Wang,Mengkang Hu,Zhi Chen,Wanxiang Che,Ting Liu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Manuscript
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Recent advancements in large language models (LLMs) have led to significant successes across various applications, where the most noticeable is to a series of emerging capabilities, particularly in the areas of In-Context Learning (ICL) and Chain-of-Thought (CoT). To better understand and control model performance, many studies have begun investigating the underlying causes of these phenomena and their impact on task outcomes. However, existing explanatory frameworks predominantly focus on isolating and explaining ICL and CoT independently, leading to an incomplete understanding of their combined influence on model performance. To address this gap, we propose the Electronic Circuit Model (ECM), which provides a foundation for developing scalable, learnable policies and improving the management of AI-generated content. Specifically, ECM conceptualizes model behavior as an electronic circuit: ICL is represented as semantic magnetic field to providing an additional voltage following Faraday's Law, while CoT is modeled as series resistors to constrain the model output performance following Ohm's Law. Experimental results demonstrate that the ECM effectively predicts and explains LLM performance across a variety of prompting strategies. Furthermore, we apply ECM to advanced reasoning strategy optimization on a series of tasks, such as the International Olympiad in Informatics (IOI) and the International Mathematical Olympiad (IMO), achieving competitive performance that surpasses nearly 80% of top human competitors.

### Out-of-Distribution Detection using Synthetic Data Generation 
[[arxiv](https://arxiv.org/abs/2502.03323)] [[cool](https://papers.cool/arxiv/2502.03323)] [[pdf](https://arxiv.org/pdf/2502.03323)]
> **Authors**: Momin Abbas,Muneeza Azmat,Raya Horesh,Mikhail Yurochkin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: Distinguishing in- and out-of-distribution (OOD) inputs is crucial for reliable deployment of classification systems. However, OOD data is typically unavailable or difficult to collect, posing a significant challenge for accurate OOD detection. In this work, we present a method that harnesses the generative capabilities of Large Language Models (LLMs) to create high-quality synthetic OOD proxies, eliminating the dependency on any external OOD data source. We study the efficacy of our method on classical text classification tasks such as toxicity detection and sentiment classification as well as classification tasks arising in LLM development and deployment, such as training a reward model for RLHF and detecting misaligned generations. Extensive experiments on nine InD-OOD dataset pairs and various model sizes show that our approach dramatically lowers false positive rates (achieving a perfect zero in some cases) while maintaining high accuracy on in-distribution tasks, outperforming baseline methods by a significant margin.

### MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters 
[[arxiv](https://arxiv.org/abs/2502.03298)] [[cool](https://papers.cool/arxiv/2502.03298)] [[pdf](https://arxiv.org/pdf/2502.03298)]
> **Authors**: Amin Dada,Osman Alperen Koras,Marie Bauer,Amanda Butler,Kaleb E. Smith,Jens Kleesiek,Julian Friedrich
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: While increasing patients' access to medical documents improves medical care, this benefit is limited by varying health literacy levels and complex medical terminology. Large language models (LLMs) offer solutions by simplifying medical information. However, evaluating LLMs for safe and patient-friendly text generation is difficult due to the lack of standardized evaluation resources. To fill this gap, we developed MeDiSumQA. MeDiSumQA is a dataset created from MIMIC-IV discharge summaries through an automated pipeline combining LLM-based question-answer generation with manual quality checks. We use this dataset to evaluate various LLMs on patient-oriented question-answering. Our findings reveal that general-purpose LLMs frequently surpass biomedical-adapted models, while automated metrics correlate with human judgment. By releasing MeDiSumQA on PhysioNet, we aim to advance the development of LLMs to enhance patient understanding and ultimately improve care outcomes.

### ALPET: Active Few-shot Learning for Citation Worthiness Detection in Low-Resource Wikipedia Languages 
[[arxiv](https://arxiv.org/abs/2502.03292)] [[cool](https://papers.cool/arxiv/2502.03292)] [[pdf](https://arxiv.org/pdf/2502.03292)]
> **Authors**: Aida Halitaj,Arkaitz Zubiaga
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 24 pages, 8 figures, 4 tables
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: Citation Worthiness Detection (CWD) consists in determining which sentences, within an article or collection, should be backed up with a citation to validate the information it provides. This study, introduces ALPET, a framework combining Active Learning (AL) and Pattern-Exploiting Training (PET), to enhance CWD for languages with limited data resources. Applied to Catalan, Basque, and Albanian Wikipedia datasets, ALPET outperforms the existing CCW baseline while reducing the amount of labeled data in some cases above 80\%. ALPET's performance plateaus after 300 labeled samples, showing it suitability for low-resource scenarios where large, labeled datasets are not common. While specific active learning query strategies, like those employing K-Means clustering, can offer advantages, their effectiveness is not universal and often yields marginal gains over random sampling, particularly with smaller datasets. This suggests that random sampling, despite its simplicity, remains a strong baseline for CWD in constraint resource environments. Overall, ALPET's ability to achieve high performance with fewer labeled samples makes it a promising tool for enhancing the verifiability of online content in low-resource language settings.

### Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning 
[[arxiv](https://arxiv.org/abs/2502.03275)] [[cool](https://papers.cool/arxiv/2502.03275)] [[pdf](https://arxiv.org/pdf/2502.03275)]
> **Authors**: DiJia Su,Hanlin Zhu,Yingchen Xu,Jiantao Jiao,Yuandong Tian,Qinqing Zheng
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习,计算机科学中的逻辑
- **Abstract**: Large Language Models (LLMs) excel at reasoning and planning when trained on chainof-thought (CoT) data, where the step-by-step thought process is explicitly outlined by text tokens. However, this results in lengthy inputs where many words support textual coherence rather than core reasoning information, and processing these inputs consumes substantial computation resources. In this work, we propose a hybrid representation of the reasoning process, where we partially abstract away the initial reasoning steps using latent discrete tokens generated by VQ-VAE, significantly reducing the length of reasoning traces. We explore the use of latent trace abstractions in two scenarios: 1) training the model from scratch for the Keys-Finding Maze problem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary including unseen latent tokens, for both logical and mathematical reasoning problems. To facilitate effective learning, we introduce a simple training procedure that randomly mixes latent and text tokens, which enables fast adaptation to new latent tokens. Our approach consistently outperforms the baselines methods in various benchmarks.

### Efficient extraction of medication information from clinical notes: an evaluation in two languages 
[[arxiv](https://arxiv.org/abs/2502.03257)] [[cool](https://papers.cool/arxiv/2502.03257)] [[pdf](https://arxiv.org/pdf/2502.03257)]
> **Authors**: Thibaut Fabacher,Erik-André Sauleau,Emmanuelle Arcay,Bineta Faye,Maxime Alter,Archia Chahard,Nathan Miraillet,Adrien Coulet,Aurélie Névéol
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Submitted to JAMIA, 17 pages, 3 figures, 2 tables and 5 supplementary tables
- **标题**: None
- **领域**: 计算语言学,信息检索
- **Abstract**: Objective: To evaluate the accuracy, computational cost and portability of a new Natural Language Processing (NLP) method for extracting medication information from clinical narratives. Materials and Methods: We propose an original transformer-based architecture for the extraction of entities and their relations pertaining to patients' medication regimen. First, we used this approach to train and evaluate a model on French clinical notes, using a newly annotated corpus from Hôpitaux Universitaires de Strasbourg. Second, the portability of the approach was assessed by conducting an evaluation on clinical documents in English from the 2018 n2c2 shared task. Information extraction accuracy and computational cost were assessed by comparison with an available method using transformers. Results: The proposed architecture achieves on the task of relation extraction itself performance that are competitive with the state-of-the-art on both French and English (F-measures 0.82 and 0.96 vs 0.81 and 0.95), but reduce the computational cost by 10. End-to-end (Named Entity recognition and Relation Extraction) F1 performance is 0.69 and 0.82 for French and English corpus. Discussion: While an existing system developed for English notes was deployed in a French hospital setting with reasonable effort, we found that an alternative architecture offered end-to-end drug information extraction with comparable extraction performance and lower computational impact for both French and English clinical text processing, respectively. Conclusion: The proposed architecture can be used to extract medication information from clinical text with high performance and low computational cost and consequently suits with usually limited hospital IT resources

### How do Humans and Language Models Reason About Creativity? A Comparative Analysis 
[[arxiv](https://arxiv.org/abs/2502.03253)] [[cool](https://papers.cool/arxiv/2502.03253)] [[pdf](https://arxiv.org/pdf/2502.03253)]
> **Authors**: Antonio Laverghetta Jr.,Tuhin Chakrabarty,Tom Hope,Jimmy Pronchick,Krupa Bhawsar,Roger E. Beaty
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: CogSci 2025
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Creativity assessment in science and engineering is increasingly based on both human and AI judgment, but the cognitive processes and biases behind these evaluations remain poorly understood. We conducted two experiments examining how including example solutions with ratings impact creativity evaluation, using a finegrained annotation protocol where raters were tasked with explaining their originality scores and rating for the facets of remoteness (whether the response is "far" from everyday ideas), uncommonness (whether the response is rare), and cleverness. In Study 1, we analyzed creativity ratings from 72 experts with formal science or engineering training, comparing those who received example solutions with ratings (example) to those who did not (no example). Computational text analysis revealed that, compared to experts with examples, no-example experts used more comparative language (e.g., "better/worse") and emphasized solution uncommonness, suggesting they may have relied more on memory retrieval for comparisons. In Study 2, parallel analyses with state-of-the-art LLMs revealed that models prioritized uncommonness and remoteness of ideas when rating originality, suggesting an evaluative process rooted around the semantic similarity of ideas. In the example condition, while LLM accuracy in predicting the true originality scores improved, the correlations of remoteness, uncommonness, and cleverness with originality also increased substantially - to upwards of 0.99 - suggesting a homogenization in the LLMs evaluation of the individual facets. These findings highlight important implications for how humans and AI reason about creativity and suggest diverging preferences for what different populations prioritize when rating.

### A scale of conceptual orality and literacy: Automatic text categorization in the tradition of "Nähe und Distanz" 
[[arxiv](https://arxiv.org/abs/2502.03252)] [[cool](https://papers.cool/arxiv/2502.03252)] [[pdf](https://arxiv.org/pdf/2502.03252)]
> **Authors**: Volker Emmrich
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Koch and Oesterreicher's model of "Nähe und Distanz" (Nähe = immediacy, conceptual orality; Distanz = distance, conceptual literacy) is constantly used in German linguistics. However, there is no statistical foundation for use in corpus linguistic analyzes, while it is increasingly moving into empirical corpus linguistics. Theoretically, it is stipulated, among other things, that written texts can be rated on a scale of conceptual orality and literacy by linguistic features. This article establishes such a scale based on PCA and combines it with automatic analysis. Two corpora of New High German serve as examples. When evaluating established features, a central finding is that features of conceptual orality and literacy must be distinguished in order to rank texts in a differentiated manner. The scale is also discussed with a view to its use in corpus compilation and as a guide for analyzes in larger corpora. With a theory-driven starting point and as a "tailored" dimension, the approach compared to Biber's Dimension 1 is particularly suitable for these supporting, controlling tasks.

### Mitigating Language Bias in Cross-Lingual Job Retrieval: A Recruitment Platform Perspective 
[[arxiv](https://arxiv.org/abs/2502.03220)] [[cool](https://papers.cool/arxiv/2502.03220)] [[pdf](https://arxiv.org/pdf/2502.03220)]
> **Authors**: Napat Laosaengpha,Thanit Tativannarat,Attapol Rutherford,Ekapol Chuangsuwanich
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: To be published in CompJobs Workshop at AAAI 2025
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Understanding the textual components of resumes and job postings is critical for improving job-matching accuracy and optimizing job search systems in online recruitment platforms. However, existing works primarily focus on analyzing individual components within this information, requiring multiple specialized tools to analyze each aspect. Such disjointed methods could potentially hinder overall generalizability in recruitment-related text processing. Therefore, we propose a unified sentence encoder that utilized multi-task dual-encoder framework for jointly learning multiple component into the unified sentence encoder. The results show that our method outperforms other state-of-the-art models, despite its smaller model size. Moreover, we propose a novel metric, Language Bias Kullback-Leibler Divergence (LBKL), to evaluate language bias in the encoder, demonstrating significant bias reduction and superior cross-lingual performance.

### iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs 
[[arxiv](https://arxiv.org/abs/2502.03214)] [[cool](https://papers.cool/arxiv/2502.03214)] [[pdf](https://arxiv.org/pdf/2502.03214)]
> **Authors**: Julius Mayer,Mohamad Ballout,Serwan Jassim,Farbod Nosrat Nezami,Elia Bruni
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,计算机视觉和模式识别
- **Abstract**: Vision-Language Models (VLMs) are known to struggle with spatial reasoning and visual alignment. To help overcome these limitations, we introduce iVISPAR, an interactive multi-modal benchmark designed to evaluate the spatial reasoning capabilities of VLMs acting as agents. iVISPAR is based on a variant of the sliding tile puzzle-a classic problem that demands logical planning, spatial awareness, and multi-step reasoning. The benchmark supports visual 2D, 3D, and text-based input modalities, enabling comprehensive assessments of VLMs' planning and reasoning skills. We evaluate a broad suite of state-of-the-art open-source and closed-source VLMs, comparing their performance while also providing optimal path solutions and a human baseline to assess the task's complexity and feasibility for humans. Results indicate that while some VLMs perform well on simple spatial tasks, they encounter difficulties with more complex configurations and problem properties. Notably, while VLMs generally perform better in 2D vision compared to 3D or text-based representations, they consistently fall short of human performance, illustrating the persistent challenge of visual alignment. This highlights critical gaps in current VLM capabilities, highlighting their limitations in achieving human-level cognition.

### Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.03199)] [[cool](https://papers.cool/arxiv/2502.03199)] [[pdf](https://arxiv.org/pdf/2502.03199)]
> **Authors**: Jialiang Wu,Yi Shen,Sijia Liu,Yi Tang,Sen Song,Xiaoyi Wang,Longjun Cai
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: NAACL 2025 Findings
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the correlation between hidden-state prediction changes and output factuality into a deeper, token-wise level. Based on the insights , we propose cross-layer Entropy eNhanced Decoding (END), a decoding method that mitigates hallucinations without requiring extra training. END leverages inner probability changes across layers to individually quantify the factual knowledge required for each candidate token, and adjusts the final predicting distribution to prioritize tokens with higher factuality. Experiments on both hallucination and QA benchmarks demonstrate that END significantly enhances the truthfulness and informativeness of generated content while maintaining robust QA accuracy. Moreover, our work provides a deeper perspective on understanding the correlations between inherent knowledge and output factuality.

### EuskañolDS: A Naturally Sourced Corpus for Basque-Spanish Code-Switching 
[[arxiv](https://arxiv.org/abs/2502.03188)] [[cool](https://papers.cool/arxiv/2502.03188)] [[pdf](https://arxiv.org/pdf/2502.03188)]
> **Authors**: Maite Heredia,Jeremy Barnes,Aitor Soroa
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Code-switching (CS) remains a significant challenge in Natural Language Processing (NLP), mainly due a lack of relevant data. In the context of the contact between the Basque and Spanish languages in the north of the Iberian Peninsula, CS frequently occurs in both formal and informal spontaneous interactions. However, resources to analyse this phenomenon and support the development and evaluation of models capable of understanding and generating code-switched language for this language pair are almost non-existent. We introduce a first approach to develop a naturally sourced corpus for Basque-Spanish code-switching. Our methodology consists of identifying CS texts from previously available corpora using language identification models, which are then manually validated to obtain a reliable subset of CS instances. We present the properties of our corpus and make it available under the name EuskañolDS.

### Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.03147)] [[cool](https://papers.cool/arxiv/2502.03147)] [[pdf](https://arxiv.org/pdf/2502.03147)]
> **Authors**: Xumeng Wen,Shun Zheng,Zhen Xu,Yiming Sun,Jiang Bian
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Preprint
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Recent studies have shown that large language models (LLMs), when customized with post-training on tabular data, can acquire general tabular in-context learning (TabICL) capabilities. These models are able to transfer effectively across diverse data schemas and different task domains. However, existing LLM-based TabICL approaches are constrained to few-shot scenarios due to the sequence length limitations of LLMs, as tabular instances represented in plain text consume substantial tokens. To address this limitation and enable scalable TabICL for any data size, we propose retrieval-augmented LLMs tailored to tabular data. Our approach incorporates a customized retrieval module, combined with retrieval-guided instruction-tuning for LLMs. This enables LLMs to effectively leverage larger datasets, achieving significantly improved performance across 69 widely recognized datasets and demonstrating promising scaling behavior. Extensive comparisons with state-of-the-art tabular models reveal that, while LLM-based TabICL still lags behind well-tuned numeric models in overall performance, it uncovers powerful algorithms under limited contexts, enhances ensemble diversity, and excels on specific datasets. These unique properties underscore the potential of language as a universal and accessible interface for scalable tabular data learning.

### Teaching Large Language Models Number-Focused Headline Generation With Key Element Rationales 
[[arxiv](https://arxiv.org/abs/2502.03129)] [[cool](https://papers.cool/arxiv/2502.03129)] [[pdf](https://arxiv.org/pdf/2502.03129)]
> **Authors**: Zhen Qian,Xiuzhen Zhang,Xiaofei Xu,Feng Xia
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Pre-print for a paper accepted to findings of NAACL 2025
- **标题**: None
- **领域**: 计算语言学,机器学习
- **Abstract**: Number-focused headline generation is a summarization task requiring both high textual quality and precise numerical accuracy, which poses a unique challenge for Large Language Models (LLMs). Existing studies in the literature focus only on either textual quality or numerical reasoning and thus are inadequate to address this challenge. In this paper, we propose a novel chain-of-thought framework for using rationales comprising key elements of the Topic, Entities, and Numerical reasoning (TEN) in news articles to enhance the capability for LLMs to generate topic-aligned high-quality texts with precise numerical accuracy. Specifically, a teacher LLM is employed to generate TEN rationales as supervision data, which are then used to teach and fine-tune a student LLM. Our approach teaches the student LLM automatic generation of rationales with enhanced capability for numerical reasoning and topic-aligned numerical headline generation. Experiments show that our approach achieves superior performance in both textual quality and numerical accuracy.

### Policies and Evaluation for Online Meeting Summarization 
[[arxiv](https://arxiv.org/abs/2502.03111)] [[cool](https://papers.cool/arxiv/2502.03111)] [[pdf](https://arxiv.org/pdf/2502.03111)]
> **Authors**: Felix Schneider,Marco Turchi,Alex Waibel
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages, 1 figure
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: With more and more meetings moving to a digital domain, meeting summarization has recently gained interest in both academic and commercial research. However, prior academic research focuses on meeting summarization as an offline task, performed after the meeting concludes. In this paper, we perform the first systematic study of online meeting summarization. For this purpose, we propose several policies for conducting online summarization. We discuss the unique challenges of this task compared to the offline setting and define novel metrics to evaluate latency and partial summary quality. The experiments on the AutoMin dataset show that 1) online models can produce strong summaries, 2) our metrics allow a detailed analysis of different systems' quality-latency trade-off, also taking into account intermediate outputs and 3) adaptive policies perform better than fixed scheduled ones. These findings provide a starting point for the wider research community to explore this important task.

### Structured Token Retention and Computational Memory Paths in Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.03102)] [[cool](https://papers.cool/arxiv/2502.03102)] [[pdf](https://arxiv.org/pdf/2502.03102)]
> **Authors**: Jonathan Delena,Augustin Moreau,Dominic Ravensdale,Frederick Chatterton
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Memory retention mechanisms play a central role in determining the efficiency of computational architectures designed for processing extended sequences. Conventional methods for token management often impose fixed retention thresholds or rely on uniform attention weight distributions, leading to inefficient memory utilization and premature information loss in extended sequence modeling. Structured Token Retention (STR) introduces a probabilistic selection framework that dynamically adjusts token persistence based on contextual significance, ensuring that computational resources are allocated to semantically relevant elements. Computational Memory Paths (CMP) extend this framework through hierarchical memory allocation, refining retention efficiency through structured reallocation of token embeddings. Comparative assessments against baseline models demonstrate that STR and CMP improve token survival rates across long input sequences while reducing cumulative error propagation across processing layers. Experimental results further indicate reductions in computational overhead, improving inference speed without degrading contextual coherence. Token distribution analyses reveal that structured memory allocation prevents excessive redundancy in attention weight calculations, optimizing information retrieval efficiency in large-scale generative architectures. The integration of STR and CMP into an open-source model illustrates the adaptability of structured memory retention methodologies, highlighting their applicability in generative text processing, long-context comprehension, and scalable sequence modeling.

### IAO Prompting: Making Knowledge Flow Explicit in LLMs through Structured Reasoning Templates 
[[arxiv](https://arxiv.org/abs/2502.03080)] [[cool](https://papers.cool/arxiv/2502.03080)] [[pdf](https://arxiv.org/pdf/2502.03080)]
> **Authors**: Aissatou Diallo,Antonis Bikakis,Luke Dickens,Anthony Hunter,Rob Miller
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted as Oral at KnowFM @ AAAI 2025
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: While Large Language Models (LLMs) demonstrate impressive reasoning capabilities, understanding and validating their knowledge utilization remains challenging. Chain-of-thought (CoT) prompting partially addresses this by revealing intermediate reasoning steps, but the knowledge flow and application remain implicit. We introduce IAO (Input-Action-Output) prompting, a structured template-based method that explicitly models how LLMs access and apply their knowledge during complex reasoning tasks. IAO decomposes problems into sequential steps, each clearly identifying the input knowledge being used, the action being performed, and the resulting output. This structured decomposition enables us to trace knowledge flow, verify factual consistency, and identify potential knowledge gaps or misapplications. Through experiments across diverse reasoning tasks, we demonstrate that IAO not only improves zero-shot performance but also provides transparency in how LLMs leverage their stored knowledge. Human evaluation confirms that this structured approach enhances our ability to verify knowledge utilization and detect potential hallucinations or reasoning errors. Our findings provide insights into both knowledge representation within LLMs and methods for more reliable knowledge application.

### DOLFIN -- Document-Level Financial test set for Machine Translation 
[[arxiv](https://arxiv.org/abs/2502.03053)] [[cool](https://papers.cool/arxiv/2502.03053)] [[pdf](https://arxiv.org/pdf/2502.03053)]
> **Authors**: Mariam Nakhlé,Marco Dinarelli,Raheel Qader,Emmanuelle Esperança-Rodier,Hervé Blanchon
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: To be published in NAACL 2025 Findings
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Despite the strong research interest in document-level Machine Translation (MT), the test sets dedicated to this task are still scarce. The existing test sets mainly cover topics from the general domain and fall short on specialised domains, such as legal and financial. Also, in spite of their document-level aspect, they still follow a sentence-level logic that does not allow for including certain linguistic phenomena such as information reorganisation. In this work, we aim to fill this gap by proposing a novel test set: DOLFIN. The dataset is built from specialised financial documents, and it makes a step towards true document-level MT by abandoning the paradigm of perfectly aligned sentences, presenting data in units of sections rather than sentences. The test set consists of an average of 1950 aligned sections for five language pairs. We present a detailed data collection pipeline that can serve as inspiration for aligning new document-level datasets. We demonstrate the usefulness and quality of this test set by evaluating a number of models. Our results show that the test set is able to discriminate between context-sensitive and context-agnostic models and shows the weaknesses when models fail to accurately translate financial texts. The test set is made public for the community.

### Knowledge Distillation from Large Language Models for Household Energy Modeling 
[[arxiv](https://arxiv.org/abs/2502.03034)] [[cool](https://papers.cool/arxiv/2502.03034)] [[pdf](https://arxiv.org/pdf/2502.03034)]
> **Authors**: Mohannad Takrouri,Nicolás M. Cuadrado,Martin Takáč
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Source code is available at https://github.com/Singularity-AI-Lab/LLM-Energy-Knowledge-Distillation
- **标题**: None
- **领域**: 计算语言学,机器学习
- **Abstract**: Machine learning (ML) is increasingly vital for smart-grid research, yet restricted access to realistic, diverse data - often due to privacy concerns - slows progress and fuels doubts within the energy sector about adopting ML-based strategies. We propose integrating Large Language Models (LLMs) in energy modeling to generate realistic, culturally sensitive, and behavior-specific data for household energy usage across diverse geographies. In this study, we employ and compare five different LLMs to systematically produce family structures, weather patterns, and daily consumption profiles for households in six distinct countries. A four-stage methodology synthesizes contextual daily data, including culturally nuanced activities, realistic weather ranges, HVAC operations, and distinct `energy signatures' that capture unique consumption footprints. Additionally, we explore an alternative strategy where external weather datasets can be directly integrated, bypassing intermediate weather modeling stages while ensuring physically consistent data inputs. The resulting dataset provides insights into how cultural, climatic, and behavioral factors converge to shape carbon emissions, offering a cost-effective avenue for scenario-based energy optimization. This approach underscores how prompt engineering, combined with knowledge distillation, can advance sustainable energy research and climate mitigation efforts. Source code is available at https://github.com/Singularity-AI-Lab/LLM-Energy-Knowledge-Distillation .

### MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation 
[[arxiv](https://arxiv.org/abs/2502.03004)] [[cool](https://papers.cool/arxiv/2502.03004)] [[pdf](https://arxiv.org/pdf/2502.03004)]
> **Authors**: Seonok Kim
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Large Language Models (LLMs) have demonstrated impressive capabilities across natural language processing tasks. However, their application to specialized domains such as medicine and biology requires further optimization to ensure factual accuracy, reliability, and contextual depth. We introduce MedBioLM, a domain-adapted biomedical question-answering model designed to enhance both short-form and long-form queries. By integrating fine-tuning and retrieval-augmented generation (RAG), MedBioLM dynamically incorporates domain-specific knowledge, improving reasoning abilities and factual accuracy. To evaluate its effectiveness, we fine-tuned the model on diverse biomedical QA datasets, covering structured multiple-choice assessments and complex clinical reasoning tasks. Fine-tuning significantly improves accuracy on benchmark datasets, while RAG enhances factual consistency. These results highlight the potential of domain-optimized LLMs in advancing biomedical research, medical education, and clinical decision support.

### Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons 
[[arxiv](https://arxiv.org/abs/2502.02988)] [[cool](https://papers.cool/arxiv/2502.02988)] [[pdf](https://arxiv.org/pdf/2502.02988)]
> **Authors**: Renjun Hu,Yi Cheng,Libin Meng,Jiaxin Xia,Yi Zong,Xing Shi,Wei Lin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: accepted at WWW'25 (Industrial Track), extended version
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: The rapid advancement of large language models (LLMs) has opened new possibilities for their adoption as evaluative judges. This paper introduces Themis, a fine-tuned LLM judge that delivers sophisticated context-aware evaluations. We provide a comprehensive overview of the development pipeline for Themis, highlighting its scenario-dependent evaluation prompts and two novel methods for controlled instruction generation. These designs enable Themis to effectively distill evaluative skills from teacher models, while retaining flexibility for continuous development. We introduce two human-labeled benchmarks for meta-evaluation, demonstrating that Themis can achieve high alignment with human preferences in an economical manner. Additionally, we explore insights into the LLM-as-a-judge paradigm, revealing nuances in performance and the varied effects of reference answers. Notably, we observe that pure knowledge distillation from strong LLMs, though common, does not guarantee performance improvement through scaling. We propose a mitigation strategy based on instruction-following difficulty. Furthermore, we provide practical guidelines covering data balancing, prompt customization, multi-objective training, and metric aggregation. We aim for our method and findings, along with the fine-tuning data, benchmarks, and model checkpoints, to support future research and development in this area.

### Position: Editing Large Language Models Poses Serious Safety Risks 
[[arxiv](https://arxiv.org/abs/2502.02958)] [[cool](https://papers.cool/arxiv/2502.02958)] [[pdf](https://arxiv.org/pdf/2502.02958)]
> **Authors**: Paul Youssef,Zhixue Zhao,Daniel Braun,Jörg Schlötterer,Christin Seifert
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Large Language Models (LLMs) contain large amounts of facts about the world. These facts can become outdated over time, which has led to the development of knowledge editing methods (KEs) that can change specific facts in LLMs with limited side effects. This position paper argues that editing LLMs poses serious safety risks that have been largely overlooked. First, we note the fact that KEs are widely available, computationally inexpensive, highly performant, and stealthy makes them an attractive tool for malicious actors. Second, we discuss malicious use cases of KEs, showing how KEs can be easily adapted for a variety of malicious purposes. Third, we highlight vulnerabilities in the AI ecosystem that allow unrestricted uploading and downloading of updated models without verification. Fourth, we argue that a lack of social and institutional awareness exacerbates this risk, and discuss the implications for different stakeholders. We call on the community to (i) research tamper-resistant models and countermeasures against malicious model editing, and (ii) actively engage in securing the AI ecosystem.

### ReachAgent: Enhancing Mobile Agent via Page Reaching and Operation 
[[arxiv](https://arxiv.org/abs/2502.02955)] [[cool](https://papers.cool/arxiv/2502.02955)] [[pdf](https://arxiv.org/pdf/2502.02955)]
> **Authors**: Qinzhuo Wu,Wei Liu,Jian Luan,Bin Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Recently, mobile AI agents have gained increasing attention. Given a task, mobile AI agents can interact with mobile devices in multiple steps and finally form a GUI flow that solves the task. However, existing agents tend to focus on most task-relevant elements at each step, leading to local optimal solutions and ignoring the overall GUI flow. To address this issue, we constructed a training dataset called MobileReach, which breaks the task into page reaching and operation subtasks. Furthermore, we propose ReachAgent, a two-stage framework that focuses on improving its task-completion abilities. It utilizes the page reaching and page operation subtasks, along with reward-based preference GUI flows, to further enhance the agent. Experimental results show that ReachAgent significantly improves the IoU Acc and Text Acc by 7.12% and 7.69% on the step-level and 4.72% and 4.63% on the task-level compared to the SOTA agent. Our data and code will be released upon acceptance.

### LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction 
[[arxiv](https://arxiv.org/abs/2502.02945)] [[cool](https://papers.cool/arxiv/2502.02945)] [[pdf](https://arxiv.org/pdf/2502.02945)]
> **Authors**: Ziwei Wang,Jie Zhou,Qin Chen,Min Zhang,Bo Jiang,Aimin Zhou,Qinchun Bai,Liang He
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: The knowledge tracing (KT) problem is an extremely important topic in personalized education, which aims to predict whether students can correctly answer the next question based on their past question-answer records. Prior work on this task mainly focused on learning the sequence of behaviors based on the IDs or textual information. However, these studies usually fail to capture students' sufficient behavioral patterns without reasoning with rich world knowledge about questions. In this paper, we propose a large language models (LLMs)-based framework for KT, named \texttt{\textbf{LLM-KT}}, to integrate the strengths of LLMs and traditional sequence interaction models. For task-level alignment, we design Plug-and-Play instruction to align LLMs with KT, leveraging LLMs' rich knowledge and powerful reasoning capacity. For modality-level alignment, we design the plug-in context and sequence to integrate multiple modalities learned by traditional methods. To capture the long context of history records, we present a plug-in context to flexibly insert the compressed context embedding into LLMs using question-specific and concept-specific tokens. Furthermore, we introduce a plug-in sequence to enhance LLMs with sequence interaction behavior representation learned by traditional sequence models using a sequence adapter. Extensive experiments show that \texttt{\textbf{LLM-KT}} obtains state-of-the-art performance on four typical datasets by comparing it with approximately 20 strong baselines.

### What is in a name? Mitigating Name Bias in Text Embeddings via Anonymization 
[[arxiv](https://arxiv.org/abs/2502.02903)] [[cool](https://papers.cool/arxiv/2502.02903)] [[pdf](https://arxiv.org/pdf/2502.02903)]
> **Authors**: Sahil Manchanda,Pannaga Shivaswamy
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: Text-embedding models often exhibit biases arising from the data on which they are trained. In this paper, we examine a hitherto unexplored bias in text-embeddings: bias arising from the presence of $\textit{names}$ such as persons, locations, organizations etc. in the text. Our study shows how the presence of $\textit{name-bias}$ in text-embedding models can potentially lead to erroneous conclusions in assessment of thematic similarity.Text-embeddings can mistakenly indicate similarity between texts based on names in the text, even when their actual semantic content has no similarity or indicate dissimilarity simply because of the names in the text even when the texts match semantically. We first demonstrate the presence of name bias in different text-embedding models and then propose $\textit{text-anonymization}$ during inference which involves removing references to names, while preserving the core theme of the text. The efficacy of the anonymization approach is demonstrated on two downstream NLP tasks, achieving significant performance gains. Our simple and training-optimization-free approach offers a practical and easily implementable solution to mitigate name bias.

### A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs 
[[arxiv](https://arxiv.org/abs/2502.02896)] [[cool](https://papers.cool/arxiv/2502.02896)] [[pdf](https://arxiv.org/pdf/2502.02896)]
> **Authors**: Bradley P. Allen,Paul T. Groth
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 6 pages, 2 tables, to appear in Reham Alharbi, Jacopo de Berardinis, Paul Groth, Albert Meroño-Peñuela, Elena Simperl, Valentina Tamma (eds.), ISWC 2024 Special Session on Harmonising GenerativeAIand Semantic Web Technologies. CEUR-WS.org (forthcoming), for associated code and data see https://github.com/bradleypallen/trex-metalinguistic-disagreement
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Evaluating large language models (LLMs) for tasks like fact extraction in support of knowledge graph construction frequently involves computing accuracy metrics using a ground truth benchmark based on a knowledge graph (KG). These evaluations assume that errors represent factual disagreements. However, human discourse frequently features metalinguistic disagreement, where agents differ not on facts but on the meaning of the language used to express them. Given the complexity of natural language processing and generation using LLMs, we ask: do metalinguistic disagreements occur between LLMs and KGs? Based on an investigation using the T-REx knowledge alignment dataset, we hypothesize that metalinguistic disagreement does in fact occur between LLMs and KGs, with potential relevance for the practice of knowledge graph engineering. We propose a benchmark for evaluating the detection of factual and metalinguistic disagreements between LLMs and KGs. An initial proof of concept of such a benchmark is available on Github.

### Lowering the Barrier of Machine Learning: Achieving Zero Manual Labeling in Review Classification Using LLMs 
[[arxiv](https://arxiv.org/abs/2502.02893)] [[cool](https://papers.cool/arxiv/2502.02893)] [[pdf](https://arxiv.org/pdf/2502.02893)]
> **Authors**: Yejian Zhang,Shingo Takada
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted to 2025 11th International Conference on Computing and Artificial Intelligence (ICCAI 2025)
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: With the internet's evolution, consumers increasingly rely on online reviews for service or product choices, necessitating that businesses analyze extensive customer feedback to enhance their offerings. While machine learning-based sentiment classification shows promise in this realm, its technical complexity often bars small businesses and individuals from leveraging such advancements, which may end up making the competitive gap between small and large businesses even bigger in terms of improving customer satisfaction. This paper introduces an approach that integrates large language models (LLMs), specifically Generative Pre-trained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT)-based models, making it accessible to a wider audience. Our experiments across various datasets confirm that our approach retains high classification accuracy without the need for manual labeling, expert knowledge in tuning and data annotation, or substantial computational power. By significantly lowering the barriers to applying sentiment classification techniques, our methodology enhances competitiveness and paves the way for making machine learning technology accessible to a broader audience.

## 密码学和安全(cs.CR:Cryptography and Security)

### Detecting Backdoor Attacks via Similarity in Semantic Communication Systems 
[[arxiv](https://arxiv.org/abs/2502.03721)] [[cool](https://papers.cool/arxiv/2502.03721)] [[pdf](https://arxiv.org/pdf/2502.03721)]
> **Authors**: Ziyang Wei,Yili Jiang,Jiaqi Huang,Fangtian Zhong,Sohan Gyawali
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 密码学和安全,机器学习
- **Abstract**: Semantic communication systems, which leverage Generative AI (GAI) to transmit semantic meaning rather than raw data, are poised to revolutionize modern communications. However, they are vulnerable to backdoor attacks, a type of poisoning manipulation that embeds malicious triggers into training datasets. As a result, Backdoor attacks mislead the inference for poisoned samples while clean samples remain unaffected. The existing defenses may alter the model structure (such as neuron pruning that potentially degrades inference performance on clean inputs, or impose strict requirements on data formats (such as ``Semantic Shield" that requires image-text pairs). To address these limitations, this work proposes a defense mechanism that leverages semantic similarity to detect backdoor attacks without modifying the model structure or imposing data format constraints. By analyzing deviations in semantic feature space and establishing a threshold-based detection framework, the proposed approach effectively identifies poisoned samples. The experimental results demonstrate high detection accuracy and recall across varying poisoning ratios, underlining the significant effectiveness of our proposed solution.

### AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails 
[[arxiv](https://arxiv.org/abs/2502.03622)] [[cool](https://papers.cool/arxiv/2502.03622)] [[pdf](https://arxiv.org/pdf/2502.03622)]
> **Authors**: Rei Meguro,Ng S. T. Chong
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 7 pages, 3 figures, 2 tables, accepted in 4th IEEE International Conference onAIin Cybersecurity (ICAIC)
- **标题**: None
- **领域**: 密码学和安全,人工智能
- **Abstract**: Phishing attacks remain a significant threat in the digital age, yet organizations lack effective methods to tackle phishing attacks without leaking sensitive information. Phish bowl initiatives are a vital part of cybersecurity efforts against these attacks. However, traditional phish bowls require manual anonymization and are often limited to internal use. To overcome these limitations, we introduce AdaPhish, an AI-powered phish bowl platform that automatically anonymizes and analyzes phishing emails using large language models (LLMs) and vector databases. AdaPhish achieves real-time detection and adaptation to new phishing tactics while enabling long-term tracking of phishing trends. Through automated reporting, adaptive analysis, and real-time alerts, AdaPhish presents a scalable, collaborative solution for phishing detection and cybersecurity education.

### Lightweight Authenticated Task Offloading in 6G-Cloud Vehicular Twin Networks 
[[arxiv](https://arxiv.org/abs/2502.03403)] [[cool](https://papers.cool/arxiv/2502.03403)] [[pdf](https://arxiv.org/pdf/2502.03403)]
> **Authors**: Sarah Al-Shareeda,Fusun Ozguner,Keith Redmill,Trung Q. Duong,Berk Canberk
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 6 pages, 3 figures, IEEE Wireless Communications and Networking Conference (WCNC2025), Milan, Italy, 24-27 March 2025
- **标题**: None
- **领域**: 密码学和安全,人工智能
- **Abstract**: Task offloading management in 6G vehicular networks is crucial for maintaining network efficiency, particularly as vehicles generate substantial data. Integrating secure communication through authentication introduces additional computational and communication overhead, significantly impacting offloading efficiency and latency. This paper presents a unified framework incorporating lightweight Identity-Based Cryptographic (IBC) authentication into task offloading within cloud-based 6G Vehicular Twin Networks (VTNs). Utilizing Proximal Policy Optimization (PPO) in Deep Reinforcement Learning (DRL), our approach optimizes authenticated offloading decisions to minimize latency and enhance resource allocation. Performance evaluation under varying network sizes, task sizes, and data rates reveals that IBC authentication can reduce offloading efficiency by up to 50% due to the added overhead. Besides, increasing network size and task size can further reduce offloading efficiency by up to 91.7%. As a countermeasure, increasing the transmission data rate can improve the offloading performance by as much as 63%, even in the presence of authentication overhead. The code for the simulations and experiments detailed in this paper is available on GitHub for further reference and reproducibility [1].

## 计算机视觉和模式识别(cs.CV:Computer Vision and Pattern Recognition)

### A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma 
[[arxiv](https://arxiv.org/abs/2502.03772)] [[cool](https://papers.cool/arxiv/2502.03772)] [[pdf](https://arxiv.org/pdf/2502.03772)]
> **Authors**: Chaoyin She,Ruifang Lu,Danni He,Jiayi Lv,Yadan Lin,Meiqing Cheng,Hui Huang,Lida Chen,Wei Wang,Qinghua Huang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能
- **Abstract**: Hepatocellular carcinoma (HCC) ranks as the third leading cause of cancer-related mortality worldwide, with early detection being crucial for improving patient survival rates. However, early screening for HCC using ultrasound suffers from insufficient sensitivity and is highly dependent on the expertise of radiologists for interpretation. Leveraging the latest advancements in artificial intelligence (AI) in medical imaging, this study proposes an innovative Hierarchical Sparse Query Transformer (HSQformer) model that combines the strengths of Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasound screening. The HSQformer leverages sparse latent space representations to capture hierarchical details at various granularities without the need for complex adjustments, and adopts a modular, plug-and-play design philosophy, ensuring the model's versatility and ease of use. The HSQformer's performance was rigorously tested across three distinct clinical scenarios: single-center, multi-center, and high-risk patient testing. In each of these settings, it consistently outperformed existing state-of-the-art models, such as ConvNext and SwinTransformer. Notably, the HSQformer even matched the diagnostic capabilities of senior radiologists and comprehensively surpassed those of junior radiologists. The experimental results from this study strongly demonstrate the effectiveness and clinical potential of AI-assisted tools in HCC screening. The full code is available at https://github.com/Asunatan/HSQformer.

### RAMOTS: A Real-Time System for Aerial Multi-Object Tracking based on Deep Learning and Big Data Technology 
[[arxiv](https://arxiv.org/abs/2502.03760)] [[cool](https://papers.cool/arxiv/2502.03760)] [[pdf](https://arxiv.org/pdf/2502.03760)]
> **Authors**: Nhat-Tan Do,Nhi Ngoc-Yen Nguyen,Dieu-Phuong Nguyen,Trong-Hop Do
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Multi-object tracking (MOT) in UAV-based video is challenging due to variations in viewpoint, low resolution, and the presence of small objects. While other research on MOT dedicated to aerial videos primarily focuses on the academic aspect by developing sophisticated algorithms, there is a lack of attention to the practical aspect of these systems. In this paper, we propose a novel real-time MOT framework that integrates Apache Kafka and Apache Spark for efficient and fault-tolerant video stream processing, along with state-of-the-art deep learning models YOLOv8/YOLOv10 and BYTETRACK/BoTSORT for accurate object detection and tracking. Our work highlights the importance of not only the advanced algorithms but also the integration of these methods with scalable and distributed systems. By leveraging these technologies, our system achieves a HOTA of 48.14 and a MOTA of 43.51 on the Visdrone2019-MOT test set while maintaining a real-time processing speed of 28 FPS on a single GPU. Our work demonstrates the potential of big data technologies and deep learning for addressing the challenges of MOT in UAV applications.

### Improving Adversarial Robustness via Phase and Amplitude-aware Prompting 
[[arxiv](https://arxiv.org/abs/2502.03758)] [[cool](https://papers.cool/arxiv/2502.03758)] [[pdf](https://arxiv.org/pdf/2502.03758)]
> **Authors**: Yibo Xu,Dawei Zhou,Decheng Liu,Nannan Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Deep neural networks are found to be vulnerable to adversarial noises. The prompt-based defense has been increasingly studied due to its high efficiency. However, existing prompt-based defenses mainly exploited mixed prompt patterns, where critical patterns closely related to object semantics lack sufficient focus. The phase and amplitude spectra have been proven to be highly related to specific semantic patterns and crucial for robustness. To this end, in this paper, we propose a Phase and Amplitude-aware Prompting (PAP) defense. Specifically, we construct phase-level and amplitude-level prompts for each class, and adjust weights for prompting according to the model's robust performance under these prompts during training. During testing, we select prompts for each image using its predicted label to obtain the prompted image, which is inputted to the model to get the final prediction. Experimental results demonstrate the effectiveness of our method.

### Brain Tumor Identification using Improved YOLOv8 
[[arxiv](https://arxiv.org/abs/2502.03746)] [[cool](https://papers.cool/arxiv/2502.03746)] [[pdf](https://arxiv.org/pdf/2502.03746)]
> **Authors**: Rupesh Dulal,Rabin Dulal
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: ef:International Conference on System Engineering and Technology (ICSET) 2024
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: Identifying the extent of brain tumors is a significant challenge in brain cancer treatment. The main difficulty is in the approximate detection of tumor size. Magnetic resonance imaging (MRI) has become a critical diagnostic tool. However, manually detecting the boundaries of brain tumors from MRI scans is a labor-intensive task that requires extensive expertise. Deep learning and computer-aided detection techniques have led to notable advances in machine learning for this purpose. In this paper, we propose a modified You Only Look Once (YOLOv8) model to accurately detect the tumors within the MRI images. The proposed model replaced the Non-Maximum Suppression (NMS) algorithm with a Real-Time Detection Transformer (RT- DETR) in the detection head. NMS filters out redundant or overlapping bounding boxes in the detected tumors, but they are hand-designed and pre-set. RT-DETR removes hand-designed components. The second improvement was made by replacing the normal convolution block with ghost convolution. Ghost Convolution reduces computational and memory costs while maintaining high accuracy and enabling faster inference, making it ideal for resource-constrained environments and real-time applications. The third improvement was made by introducing a vision transformer block in the backbone of YOLOv8 to extract context-aware features. We used a publicly available dataset of brain tumors in the proposed model. The proposed model performed better than the original YOLOv8 model and also performed better than other object detectors (Faster R- CNN, Mask R-CNN, YOLO, YOLOv3, YOLOv4, YOLOv5, SSD, RetinaNet, EfficientDet, and DETR). The proposed model achieved 0.91 mAP (mean Average Precision)@0.5.

### Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More 
[[arxiv](https://arxiv.org/abs/2502.03738)] [[cool](https://papers.cool/arxiv/2502.03738)] [[pdf](https://arxiv.org/pdf/2502.03738)]
> **Authors**: Feng Wang,Yaodong Yu,Guoyizhe Wei,Wei Shao,Yuyin Zhou,Alan Yuille,Cihang Xie
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Since the introduction of Vision Transformer (ViT), patchification has long been regarded as a de facto image tokenization approach for plain visual architectures. By compressing the spatial size of images, this approach can effectively shorten the token sequence and reduce the computational cost of ViT-like plain architectures. In this work, we aim to thoroughly examine the information loss caused by this patchification-based compressive encoding paradigm and how it affects visual understanding. We conduct extensive patch size scaling experiments and excitedly observe an intriguing scaling law in patchification: the models can consistently benefit from decreased patch sizes and attain improved predictive performance, until it reaches the minimum patch size of 1x1, i.e., pixel tokenization. This conclusion is broadly applicable across different vision tasks, various input scales, and diverse architectures such as ViT and the recent Mamba models. Moreover, as a by-product, we discover that with smaller patches, task-specific decoder heads become less critical for dense prediction. In the experiments, we successfully scale up the visual sequence to an exceptional length of 50,176 tokens, achieving a competitive test accuracy of 84.6% with a base-sized model on the ImageNet-1k benchmark. We hope this study can provide insights and theoretical foundations for future works of building non-compressive vision models. Code is available at https://github.com/wangf3014/Patch_Scaling.

### MD-BERT: Action Recognition in Dark Videos via Dynamic Multi-Stream Fusion and Temporal Modeling 
[[arxiv](https://arxiv.org/abs/2502.03724)] [[cool](https://papers.cool/arxiv/2502.03724)] [[pdf](https://arxiv.org/pdf/2502.03724)]
> **Authors**: Sharana Dharshikgan Suresh Dass,Hrishav Bakul Barua,Ganesh Krishnasamy,Raveendran Paramesran,Raphael C. -W. Phan
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: :Machine learning…Deep learning(Artificial intelligence; Computer vision; Machine learning; Deep learning; Human-computer Interaction)ACM Class:I.2; I.2.9; I.2.10; I.3.3; I.4.5
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,人机交互,机器学习,多媒体
- **Abstract**: Action recognition in dark, low-light (under-exposed) or noisy videos is a challenging task due to visibility degradation, which can hinder critical spatiotemporal details. This paper proposes MD-BERT, a novel multi-stream approach that integrates complementary pre-processing techniques such as gamma correction and histogram equalization alongside raw dark frames to address these challenges. We introduce the Dynamic Feature Fusion (DFF) module, extending existing attentional fusion methods to a three-stream setting, thereby capturing fine-grained and global contextual information across different brightness and contrast enhancements. The fused spatiotemporal features are then processed by a BERT-based temporal model, which leverages its bidirectional self-attention to effectively capture long-range dependencies and contextual relationships across frames. Extensive experiments on the ARID V1.0 and ARID V1.5 dark video datasets show that MD-BERT outperforms existing methods, establishing a new state-of-the-art performance. Ablation studies further highlight the individual contributions of each input stream and the effectiveness of the proposed DFF and BERT modules. The official website of this work is available at: https://github.com/HrishavBakulBarua/DarkBERT

### Universal Sparse Autoencoders: Interpretable Cross-Model Concept Alignment 
[[arxiv](https://arxiv.org/abs/2502.03714)] [[cool](https://papers.cool/arxiv/2502.03714)] [[pdf](https://arxiv.org/pdf/2502.03714)]
> **Authors**: Harrish Thasarathan,Julian Forsyth,Thomas Fel,Matthew Kowal,Konstantinos Derpanis
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: We present Universal Sparse Autoencoders (USAEs), a framework for uncovering and aligning interpretable concepts spanning multiple pretrained deep neural networks. Unlike existing concept-based interpretability methods, which focus on a single model, USAEs jointly learn a universal concept space that can reconstruct and interpret the internal activations of multiple models at once. Our core insight is to train a single, overcomplete sparse autoencoder (SAE) that ingests activations from any model and decodes them to approximate the activations of any other model under consideration. By optimizing a shared objective, the learned dictionary captures common factors of variation-concepts-across different tasks, architectures, and datasets. We show that USAEs discover semantically coherent and important universal concepts across vision models; ranging from low-level features (e.g., colors and textures) to higher-level structures (e.g., parts and objects). Overall, USAEs provide a powerful new method for interpretable cross-model analysis and offers novel applications, such as coordinated activation maximization, that open avenues for deeper insights in multi-model AI systems

### Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free 
[[arxiv](https://arxiv.org/abs/2502.03687)] [[cool](https://papers.cool/arxiv/2502.03687)] [[pdf](https://arxiv.org/pdf/2502.03687)]
> **Authors**: Gian Mario Favero,Parham Saremi,Emily Kaczmarek,Brennan Nichyporuk,Tal Arbel
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: Discriminative classifiers have become a foundational tool in deep learning for medical imaging, excelling at learning separable features of complex data distributions. However, these models often need careful design, augmentation, and training techniques to ensure safe and reliable deployment. Recently, diffusion models have become synonymous with generative modeling in 2D. These models showcase robustness across a range of tasks including natural image classification, where classification is performed by comparing reconstruction errors across images generated for each possible conditioning input. This work presents the first exploration of the potential of class conditional diffusion models for 2D medical image classification. First, we develop a novel majority voting scheme shown to improve the performance of medical diffusion classifiers. Next, extensive experiments on the CheXpert and ISIC Melanoma skin cancer datasets demonstrate that foundation and trained-from-scratch diffusion models achieve competitive performance against SOTA discriminative classifiers without the need for explicit supervision. In addition, we show that diffusion classifiers are intrinsically explainable, and can be used to quantify the uncertainty of their predictions, increasing their trustworthiness and reliability in safety-critical, clinical contexts. Further information is available on our project page: https://faverogian.github.io/med-diffusion-classifier.github.io/

### A Study in Dataset Distillation for Image Super-Resolution 
[[arxiv](https://arxiv.org/abs/2502.03656)] [[cool](https://papers.cool/arxiv/2502.03656)] [[pdf](https://arxiv.org/pdf/2502.03656)]
> **Authors**: Tobias Dietz,Brian B. Moser,Tobias Nauen,Federico Raue,Stanislav Frolov,Andreas Dengel
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,机器学习
- **Abstract**: Dataset distillation is the concept of condensing large datasets into smaller but highly representative synthetic samples. While previous research has primarily focused on image classification, its application to image Super-Resolution (SR) remains underexplored. This exploratory work studies multiple dataset distillation techniques applied to SR, including pixel- and latent-space approaches under different aspects. Our experiments demonstrate that a 91.12% dataset size reduction can be achieved while maintaining comparable SR performance to the full dataset. We further analyze initialization strategies and distillation methods to optimize memory efficiency and computational costs. Our findings provide new insights into dataset distillation for SR and set the stage for future advancements.

### REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations 
[[arxiv](https://arxiv.org/abs/2502.03629)] [[cool](https://papers.cool/arxiv/2502.03629)] [[pdf](https://arxiv.org/pdf/2502.03629)]
> **Authors**: Peter Sushko,Ayana Bharadwaj,Zhi Yang Lim,Vasily Ilin,Ben Caffee,Dongping Chen,Mohammadreza Salehi,Cheng-Yu Hsieh,Ranjay Krishna
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,计算语言学,机器学习
- **Abstract**: Existing image editing models struggle to meet real-world demands. Despite excelling in academic benchmarks, they have yet to be widely adopted for real user needs. Datasets that power these models use artificial edits, lacking the scale and ecological validity necessary to address the true diversity of user requests. We introduce REALEDIT, a large-scale image editing dataset with authentic user requests and human-made edits sourced from Reddit. REALEDIT includes a test set of 9300 examples to evaluate models on real user requests. Our results show that existing models fall short on these tasks, highlighting the need for realistic training data. To address this, we introduce 48K training examples and train our REALEDIT model, achieving substantial gains - outperforming competitors by up to 165 Elo points in human judgment and 92 percent relative improvement on the automated VIEScore metric. We deploy our model on Reddit, testing it on new requests, and receive positive feedback. Beyond image editing, we explore REALEDIT's potential in detecting edited images by partnering with a deepfake detection non-profit. Finetuning their model on REALEDIT data improves its F1-score by 14 percentage points, underscoring the dataset's value for broad applications.

### The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering 
[[arxiv](https://arxiv.org/abs/2502.03628)] [[cool](https://papers.cool/arxiv/2502.03628)] [[pdf](https://arxiv.org/pdf/2502.03628)]
> **Authors**: Zhuowei Li,Haizhou Shi,Yunhe Gao,Di Liu,Zhenting Wang,Yuxiao Chen,Ting Liu,Long Zhao,Hao Wang,Dimitris N. Metaxas
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,机器学习
- **Abstract**: Large Vision-Language Models (LVLMs) can reason effectively over both textual and visual inputs, but they tend to hallucinate syntactically coherent yet visually ungrounded contents. In this paper, we investigate the internal dynamics of hallucination by examining the tokens logits rankings throughout the generation process, revealing three key patterns in how LVLMs process information: (1) gradual visual information loss -- visually grounded tokens gradually become less favored throughout generation, and (2) early excitation -- semantically meaningful tokens achieve peak activation in the layers earlier than the final layer. (3) hidden genuine information -- visually grounded tokens though not being eventually decided still retain relatively high rankings at inference. Based on these insights, we propose VISTA (Visual Information Steering with Token-logit Augmentation), a training-free inference-time intervention framework that reduces hallucination while promoting genuine information. VISTA works by combining two complementary approaches: reinforcing visual information in activation space and leveraging early layer activations to promote semantically meaningful decoding. Compared to existing methods, VISTA requires no external supervision and is applicable to various decoding strategies. Extensive experiments show that VISTA on average reduces hallucination by abount 40% on evaluated open-ended generation task, and it consistently outperforms existing methods on four benchmarks across four architectures under three decoding strategies.

### DynVFX: Augmenting Real Videos with Dynamic Content 
[[arxiv](https://arxiv.org/abs/2502.03621)] [[cool](https://papers.cool/arxiv/2502.03621)] [[pdf](https://arxiv.org/pdf/2502.03621)]
> **Authors**: Danah Yatim,Rafail Fridman,Omer Bar-Tal,Tali Dekel
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Project page: https://dynvfx.github.io
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: We present a method for augmenting real-world videos with newly generated dynamic content. Given an input video and a simple user-provided text instruction describing the desired content, our method synthesizes dynamic objects or complex scene effects that naturally interact with the existing scene over time. The position, appearance, and motion of the new content are seamlessly integrated into the original footage while accounting for camera motion, occlusions, and interactions with other dynamic objects in the scene, resulting in a cohesive and realistic output video. We achieve this via a zero-shot, training-free framework that harnesses a pre-trained text-to-video diffusion transformer to synthesize the new content and a pre-trained Vision Language Model to envision the augmented scene in detail. Specifically, we introduce a novel inference-based method that manipulates features within the attention mechanism, enabling accurate localization and seamless integration of the new content while preserving the integrity of the original scene. Our method is fully automated, requiring only a simple user instruction. We demonstrate its effectiveness on a wide range of edits applied to real-world videos, encompassing diverse objects and scenarios involving both camera and object motion.

### Solar Panel Mapping via Oriented Object Detection 
[[arxiv](https://arxiv.org/abs/2502.03592)] [[cool](https://papers.cool/arxiv/2502.03592)] [[pdf](https://arxiv.org/pdf/2502.03592)]
> **Authors**: Conor Wallace,Isaac Corley,Jonathan Lwowski
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Maintaining the integrity of solar power plants is a vital component in dealing with the current climate crisis. This process begins with analysts creating a detailed map of a plant with the coordinates of every solar panel, making it possible to quickly locate and mitigate potential faulty solar panels. However, this task is extremely tedious and is not scalable for the ever increasing capacity of solar power across the globe. Therefore, we propose an end-to-end deep learning framework for detecting individual solar panels using a rotated object detection architecture. We evaluate our approach on a diverse dataset of solar power plants collected from across the United States and report a mAP score of 83.3%.

### Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function 
[[arxiv](https://arxiv.org/abs/2502.03591)] [[cool](https://papers.cool/arxiv/2502.03591)] [[pdf](https://arxiv.org/pdf/2502.03591)]
> **Authors**: Mehrdad Asadi,Komi Sodoké,Ian J. Gerard,Marta Kersten-Oertel
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 9 pages with 3 figures, for associated implementation see https://github.com/the-mercury/CIHMLC
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,机器学习
- **Abstract**: In this work, we present a novel approach to multi-label chest X-ray (CXR) image classification that enhances clinical interpretability while maintaining a streamlined, single-model, single-run training pipeline. Leveraging the CheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchical label groupings to capture clinically meaningful relationships between diagnoses. To achieve this, we designed a custom hierarchical binary cross-entropy (HBCE) loss function that enforces label dependencies using either fixed or data-driven penalty types. Our model achieved a mean area under the receiver operating characteristic curve (AUROC) of 0.903 on the test set. Additionally, we provide visual explanations and uncertainty estimations to further enhance model interpretability. All code, model configurations, and experiment details are made available.

### CLIP Behaves like a Bag-of-Words Model Cross-modally but not Uni-modally 
[[arxiv](https://arxiv.org/abs/2502.03566)] [[cool](https://papers.cool/arxiv/2502.03566)] [[pdf](https://arxiv.org/pdf/2502.03566)]
> **Authors**: Darina Koishigarina,Arnas Uselis,Seong Joon Oh
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: CLIP (Contrastive Language-Image Pretraining) has become a popular choice for various downstream tasks. However, recent studies have questioned its ability to represent compositional concepts effectively. These works suggest that CLIP often acts like a bag-of-words (BoW) model, interpreting images and text as sets of individual concepts without grasping the structural relationships. In particular, CLIP struggles to correctly bind attributes to their corresponding objects when multiple objects are present in an image or text. In this work, we investigate why CLIP exhibits this BoW-like behavior. We find that the correct attribute-object binding information is already present in individual text and image modalities. Instead, the issue lies in the cross-modal alignment, which relies on cosine similarity. To address this, we propose Linear Attribute Binding CLIP or LABCLIP. It applies a linear transformation to text embeddings before computing cosine similarity. This approach significantly improves CLIP's ability to bind attributes to correct objects, thereby enhancing its compositional understanding. The code is available at https://github.com/kdariina/CLIP-not-BoW-unimodally.

### Efficient Global Neural Architecture Search 
[[arxiv](https://arxiv.org/abs/2502.03553)] [[cool](https://papers.cool/arxiv/2502.03553)] [[pdf](https://arxiv.org/pdf/2502.03553)]
> **Authors**: Shahid Siddiqui,Christos Kyrkou,Theocharis Theocharides
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: CAIP2023
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Neural architecture search (NAS) has shown promise towards automating neural network design for a given task, but it is computationally demanding due to training costs associated with evaluating a large number of architectures to find the optimal one. To speed up NAS, recent works limit the search to network building blocks (modular search) instead of searching the entire architecture (global search), approximate candidates' performance evaluation in lieu of complete training, and use gradient descent rather than naturally suitable discrete optimization approaches. However, modular search does not determine network's macro architecture i.e. depth and width, demanding manual trial and error post-search, hence lacking automation. In this work, we revisit NAS and design a navigable, yet architecturally diverse, macro-micro search space. In addition, to determine relative rankings of candidates, existing methods employ consistent approximations across entire search spaces, whereas different networks may not be fairly comparable under one training protocol. Hence, we propose an architecture-aware approximation with variable training schemes for different networks. Moreover, we develop an efficient search strategy by disjoining macro-micro network design that yields competitive architectures in terms of both accuracy and size. Our proposed framework achieves a new state-of-the-art on EMNIST and KMNIST, while being highly competitive on the CIFAR-10, CIFAR-100, and FashionMNIST datasets and being 2-4x faster than the fastest global search methods. Lastly, we demonstrate the transferability of our framework to real-world computer vision problems by discovering competitive architectures for face recognition applications.

### Kronecker Mask and Interpretive Prompts are Language-Action Video Learners 
[[arxiv](https://arxiv.org/abs/2502.03549)] [[cool](https://papers.cool/arxiv/2502.03549)] [[pdf](https://arxiv.org/pdf/2502.03549)]
> **Authors**: Jingyi Yang,Zitong Yu,Xiuming Ni,Jia He,Hui Li
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted to ICLR 2025
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Contrastive language-image pretraining (CLIP) has significantly advanced image-based vision learning. A pressing topic subsequently arises: how can we effectively adapt CLIP to the video domain? Recent studies have focused on adjusting either the textual or visual branch of CLIP for action recognition. However, we argue that adaptations of both branches are crucial. In this paper, we propose \textbf{CLAVER}: a \textbf{C}ontrastive \textbf{L}anguage-\textbf{A}ction \textbf{V}ideo Learn\textbf{er}, designed to shift CLIP's focus from the alignment of static visual objects and concrete nouns to the alignment of dynamic action behaviors and abstract verbs. Specifically, we introduce a novel Kronecker mask attention for temporal modeling. Our tailored Kronecker mask offers three benefits 1) it expands the temporal receptive field for each token, 2) it serves as an effective spatiotemporal heterogeneity inductive bias, mitigating the issue of spatiotemporal homogenization, and 3) it can be seamlessly plugged into transformer-based models. Regarding the textual branch, we leverage large language models to generate diverse, sentence-level and semantically rich interpretive prompts of actions, which shift the model's focus towards the verb comprehension. Extensive experiments on various benchmarks and learning scenarios demonstrate the superiority and generality of our approach.

### Seeing World Dynamics in a Nutshell 
[[arxiv](https://arxiv.org/abs/2502.03465)] [[cool](https://papers.cool/arxiv/2502.03465)] [[pdf](https://arxiv.org/pdf/2502.03465)]
> **Authors**: Qiuhong Shen,Xuanyu Yi,Mingbao Lin,Hanwang Zhang,Shuicheng Yan,Xinchao Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,图形,多媒体
- **Abstract**: We consider the problem of efficiently representing casually captured monocular videos in a spatially- and temporally-coherent manner. While existing approaches predominantly rely on 2D/2.5D techniques treating videos as collections of spatiotemporal pixels, they struggle with complex motions, occlusions, and geometric consistency due to absence of temporal coherence and explicit 3D structure. Drawing inspiration from monocular video as a projection of the dynamic 3D world, we explore representing videos in their intrinsic 3D form through continuous flows of Gaussian primitives in space-time. In this paper, we propose NutWorld, a novel framework that efficiently transforms monocular videos into dynamic 3D Gaussian representations in a single forward pass. At its core, NutWorld introduces a structured spatial-temporal aligned Gaussian (STAG) representation, enabling optimization-free scene modeling with effective depth and flow regularization. Through comprehensive experiments, we demonstrate that NutWorld achieves high-fidelity video reconstruction quality while enabling various downstream applications in real-time. Demos and code will be available at https://github.com/Nut-World/NutWorld.

### SKI Models: Skeleton Induced Vision-Language Embeddings for Understanding Activities of Daily Living 
[[arxiv](https://arxiv.org/abs/2502.03459)] [[cool](https://papers.cool/arxiv/2502.03459)] [[pdf](https://arxiv.org/pdf/2502.03459)]
> **Authors**: Arkaprava Sinha,Dominick Reilly,Francois Bremond,Pu Wang,Srijan Das
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: The introduction of vision-language models like CLIP has enabled the development of foundational video models capable of generalizing to unseen videos and human actions. However, these models are typically trained on web videos, which often fail to capture the challenges present in Activities of Daily Living (ADL) videos. Existing works address ADL-specific challenges, such as similar appearances, subtle motion patterns, and multiple viewpoints, by combining 3D skeletons and RGB videos. However, these approaches are not integrated with language, limiting their ability to generalize to unseen action classes. In this paper, we introduce SKI models, which integrate 3D skeletons into the vision-language embedding space. SKI models leverage a skeleton-language model, SkeletonCLIP, to infuse skeleton information into Vision Language Models (VLMs) and Large Vision Language Models (LVLMs) through collaborative training. Notably, SKI models do not require skeleton data during inference, enhancing their robustness for real-world applications. The effectiveness of SKI models is validated on three popular ADL datasets for zero-shot action recognition and video caption generation tasks.

### Masked Autoencoders Are Effective Tokenizers for Diffusion Models 
[[arxiv](https://arxiv.org/abs/2502.03444)] [[cool](https://papers.cool/arxiv/2502.03444)] [[pdf](https://arxiv.org/pdf/2502.03444)]
> **Authors**: Hao Chen,Yujin Han,Fangyi Chen,Xiang Li,Yidong Wang,Jindong Wang,Ze Wang,Zicheng Liu,Difan Zou,Bhiksha Raj
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,机器学习
- **Abstract**: Recent advances in latent diffusion models have demonstrated their effectiveness for high-resolution image synthesis. However, the properties of the latent space from tokenizer for better learning and generation of diffusion models remain under-explored. Theoretically and empirically, we find that improved generation quality is closely tied to the latent distributions with better structure, such as the ones with fewer Gaussian Mixture modes and more discriminative features. Motivated by these insights, we propose MAETok, an autoencoder (AE) leveraging mask modeling to learn semantically rich latent space while maintaining reconstruction fidelity. Extensive experiments validate our analysis, demonstrating that the variational form of autoencoders is not necessary, and a discriminative latent space from AE alone enables state-of-the-art performance on ImageNet generation using only 128 tokens. MAETok achieves significant practical improvements, enabling a gFID of 1.69 with 76x faster training and 31x higher inference throughput for 512x512 generation. Our findings show that the structure of the latent space, rather than variational constraints, is crucial for effective diffusion models. Code and trained models are released.

### TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer 
[[arxiv](https://arxiv.org/abs/2502.03426)] [[cool](https://papers.cool/arxiv/2502.03426)] [[pdf](https://arxiv.org/pdf/2502.03426)]
> **Authors**: Zhihong Xu,Dongxia Wang,Peng Du,Yang Cao,Qing Guo
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能
- **Abstract**: Pose-Guided Person Image Synthesis (PGPIS) generates images that maintain a subject's identity from a source image while adopting a specified target pose (e.g., skeleton). While diffusion-based PGPIS methods effectively preserve facial features during pose transformation, they often struggle to accurately maintain clothing details from the source image throughout the diffusion process. This limitation becomes particularly problematic when there is a substantial difference between the source and target poses, significantly impacting PGPIS applications in the fashion industry where clothing style preservation is crucial for copyright protection. Our analysis reveals that this limitation primarily stems from the conditional diffusion model's attention modules failing to adequately capture and preserve clothing patterns. To address this limitation, we propose human-parsing-guided attention diffusion, a novel approach that effectively preserves both facial and clothing appearance while generating high-quality results. We propose a human-parsing-aware Siamese network that consists of three key components: dual identical UNets (TargetNet for diffusion denoising and SourceNet for source image embedding extraction), a human-parsing-guided fusion attention (HPFA), and a CLIP-guided attention alignment (CAA). The HPFA and CAA modules can embed the face and clothes patterns into the target image generation adaptively and effectively. Extensive experiments on both the in-shop clothes retrieval benchmark and the latest in-the-wild human editing dataset demonstrate our method's significant advantages over 13 baseline approaches for preserving both facial and clothes appearance in the source image.

### Concept Based Explanations and Class Contrasting 
[[arxiv](https://arxiv.org/abs/2502.03422)] [[cool](https://papers.cool/arxiv/2502.03422)] [[pdf](https://arxiv.org/pdf/2502.03422)]
> **Authors**: Rudolf Herdt,Daniel Otero Baguer
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Explaining deep neural networks is challenging, due to their large size and non-linearity. In this paper, we introduce a concept-based explanation method, in order to explain the prediction for an individual class, as well as contrasting any two classes, i.e. explain why the model predicts one class over the other. We test it on several openly available classification models trained on ImageNet1K, as well as on a segmentation model trained to detect tumor in stained tissue samples. We perform both qualitative and quantitative tests. For example, for a ResNet50 model from pytorch model zoo, we can use the explanation for why the model predicts a class 'A' to automatically select six dataset crops where the model does not predict class 'A'. The model then predicts class 'A' again for the newly combined image in 71\% of the cases (works for 710 out of the 1000 classes). The code including an .ipynb example is available on git: https://github.com/rherdt185/concept-based-explanations-and-class-contrasting.

### Deep Learning-Based Approach for Identification of Potato Leaf Diseases Using Wrapper Feature Selection and Feature Concatenation 
[[arxiv](https://arxiv.org/abs/2502.03370)] [[cool](https://papers.cool/arxiv/2502.03370)] [[pdf](https://arxiv.org/pdf/2502.03370)]
> **Authors**: Muhammad Ahtsam Naeem,Muhammad Asim Saleem,Muhammad Imran Sharif,Shahzad Akber,Sajjad Saleem,Zahid Akhtar,Kamran Siddique
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: The potato is a widely grown crop in many regions of the world. In recent decades, potato farming has gained incredible traction in the world. Potatoes are susceptible to several illnesses that stunt their development. This plant seems to have significant leaf disease. Early Blight and Late Blight are two prevalent leaf diseases that affect potato plants. The early detection of these diseases would be beneficial for enhancing the yield of this crop. The ideal solution is to use image processing to identify and analyze these disorders. Here, we present an autonomous method based on image processing and machine learning to detect late blight disease affecting potato leaves. The proposed method comprises four different phases: (1) Histogram Equalization is used to improve the quality of the input image; (2) feature extraction is performed using a Deep CNN model, then these extracted features are concatenated; (3) feature selection is performed using wrapper-based feature selection; (4) classification is performed using an SVM classifier and its variants. This proposed method achieves the highest accuracy of 99% using SVM by selecting 550 features.

### GHOST: Gaussian Hypothesis Open-Set Technique 
[[arxiv](https://arxiv.org/abs/2502.03359)] [[cool](https://papers.cool/arxiv/2502.03359)] [[pdf](https://arxiv.org/pdf/2502.03359)]
> **Authors**: Ryan Rabinowitz,Steve Cruz,Manuel Günther,Terrance E. Boult
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted at AAAI Conference on Artificial Intelligence 2025
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,机器学习
- **Abstract**: Evaluations of large-scale recognition methods typically focus on overall performance. While this approach is common, it often fails to provide insights into performance across individual classes, which can lead to fairness issues and misrepresentation. Addressing these gaps is crucial for accurately assessing how well methods handle novel or unseen classes and ensuring a fair evaluation. To address fairness in Open-Set Recognition (OSR), we demonstrate that per-class performance can vary dramatically. We introduce Gaussian Hypothesis Open Set Technique (GHOST), a novel hyperparameter-free algorithm that models deep features using class-wise multivariate Gaussian distributions with diagonal covariance matrices. We apply Z-score normalization to logits to mitigate the impact of feature magnitudes that deviate from the model's expectations, thereby reducing the likelihood of the network assigning a high score to an unknown sample. We evaluate GHOST across multiple ImageNet-1K pre-trained deep networks and test it with four different unknown datasets. Using standard metrics such as AUOSCR, AUROC and FPR95, we achieve statistically significant improvements, advancing the state-of-the-art in large-scale OSR. Source code is provided online.

### RadVLM: A Multitask Conversational Vision-Language Model for Radiology 
[[arxiv](https://arxiv.org/abs/2502.03333)] [[cool](https://papers.cool/arxiv/2502.03333)] [[pdf](https://arxiv.org/pdf/2502.03333)]
> **Authors**: Nicolas Deperrois,Hidetoshi Matsuo,Samuel Ruipérez-Campillo,Moritz Vandenhirtz,Sonia Laguna,Alain Ryser,Koji Fujimoto,Mizuho Nishio,Thomas M. Sutter,Julia E. Vogt,Jonas Kluckert,Thomas Frauenfelder,Christian Blüthgen,Farhad Nooralahzadeh,Michael Krauthammer
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 21 pages, 15 figures
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能
- **Abstract**: The widespread use of chest X-rays (CXRs), coupled with a shortage of radiologists, has driven growing interest in automated CXR analysis and AI-assisted reporting. While existing vision-language models (VLMs) show promise in specific tasks such as report generation or abnormality detection, they often lack support for interactive diagnostic capabilities. In this work we present RadVLM, a compact, multitask conversational foundation model designed for CXR interpretation. To this end, we curate a large-scale instruction dataset comprising over 1 million image-instruction pairs containing both single-turn tasks -- such as report generation, abnormality classification, and visual grounding -- and multi-turn, multi-task conversational interactions. After fine-tuning RadVLM on this instruction dataset, we evaluate it across different tasks along with re-implemented baseline VLMs. Our results show that RadVLM achieves state-of-the-art performance in conversational capabilities and visual grounding while remaining competitive in other radiology tasks. Ablation studies further highlight the benefit of joint training across multiple tasks, particularly for scenarios with limited annotated data. Together, these findings highlight the potential of RadVLM as a clinically relevant AI assistant, providing structured CXR interpretation and conversational capabilities to support more effective and accessible diagnostic workflows.

### Deep Learning-based Event Data Coding: A Joint Spatiotemporal and Polarity Solution 
[[arxiv](https://arxiv.org/abs/2502.03285)] [[cool](https://papers.cool/arxiv/2502.03285)] [[pdf](https://arxiv.org/pdf/2502.03285)]
> **Authors**: Abdelrahman Seleem,André F. R. Guarda,Nuno M. M. Rodrigues,Fernando Pereira
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,图像和视频处理
- **Abstract**: Neuromorphic vision sensors, commonly referred to as event cameras, have recently gained relevance for applications requiring high-speed, high dynamic range and low-latency data acquisition. Unlike traditional frame-based cameras that capture 2D images, event cameras generate a massive number of pixel-level events, composed by spatiotemporal and polarity information, with very high temporal resolution, thus demanding highly efficient coding solutions. Existing solutions focus on lossless coding of event data, assuming that no distortion is acceptable for the target use cases, mostly including computer vision tasks. One promising coding approach exploits the similarity between event data and point clouds, thus allowing to use current point cloud coding solutions to code event data, typically adopting a two-point clouds representation, one for each event polarity. This paper proposes a novel lossy Deep Learning-based Joint Event data Coding (DL-JEC) solution adopting a single-point cloud representation, thus enabling to exploit the correlation between the spatiotemporal and polarity event information. DL-JEC can achieve significant compression performance gains when compared with relevant conventional and DL-based state-of-the-art event data coding solutions. Moreover, it is shown that it is possible to use lossy event data coding with its reduced rate regarding lossless coding without compromising the target computer vision task performance, notably for event classification. The use of novel adaptive voxel binarization strategies, adapted to the target task, further enables DL-JEC to reach a superior performance.

### ZISVFM: Zero-Shot Object Instance Segmentation in Indoor Robotic Environments with Vision Foundation Models 
[[arxiv](https://arxiv.org/abs/2502.03266)] [[cool](https://papers.cool/arxiv/2502.03266)] [[pdf](https://arxiv.org/pdf/2502.03266)]
> **Authors**: Ying Zhang,Maoliang Yin,Wenfu Bi,Haibao Yan,Shaohan Bian,Cui-Hua Zhang,Changchun Hua
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器人技术
- **Abstract**: Service robots operating in unstructured environments must effectively recognize and segment unknown objects to enhance their functionality. Traditional supervised learningbased segmentation techniques require extensive annotated datasets, which are impractical for the diversity of objects encountered in real-world scenarios. Unseen Object Instance Segmentation (UOIS) methods aim to address this by training models on synthetic data to generalize to novel objects, but they often suffer from the simulation-to-reality gap. This paper proposes a novel approach (ZISVFM) for solving UOIS by leveraging the powerful zero-shot capability of the segment anything model (SAM) and explicit visual representations from a selfsupervised vision transformer (ViT). The proposed framework operates in three stages: (1) generating object-agnostic mask proposals from colorized depth images using SAM, (2) refining these proposals using attention-based features from the selfsupervised ViT to filter non-object masks, and (3) applying K-Medoids clustering to generate point prompts that guide SAM towards precise object segmentation. Experimental validation on two benchmark datasets and a self-collected dataset demonstrates the superior performance of ZISVFM in complex environments, including hierarchical settings such as cabinets, drawers, and handheld objects. Our source code is available at https://github.com/Yinmlmaoliang/zisvfm.

### Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration 
[[arxiv](https://arxiv.org/abs/2502.03238)] [[cool](https://papers.cool/arxiv/2502.03238)] [[pdf](https://arxiv.org/pdf/2502.03238)]
> **Authors**: Li Pan,Yupei Zhang,Qiushi Yang,Tan Li,Zhen Chen
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This work has been accepted in Computers in Biology and Medicine
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,机器学习,多媒体
- **Abstract**: Recently computer-aided diagnosis has demonstrated promising performance, effectively alleviating the workload of clinicians. However, the inherent sample imbalance among different diseases leads algorithms biased to the majority categories, leading to poor performance for rare categories. Existing works formulated this challenge as a long-tailed problem and attempted to tackle it by decoupling the feature representation and classification. Yet, due to the imbalanced distribution and limited samples from tail classes, these works are prone to biased representation learning and insufficient classifier calibration. To tackle these problems, we propose a new Long-tailed Medical Diagnosis (LMD) framework for balanced medical image classification on long-tailed datasets. In the initial stage, we develop a Relation-aware Representation Learning (RRL) scheme to boost the representation ability by encouraging the encoder to capture intrinsic semantic features through different data augmentations. In the subsequent stage, we propose an Iterative Classifier Calibration (ICC) scheme to calibrate the classifier iteratively. This is achieved by generating a large number of balanced virtual features and fine-tuning the encoder using an Expectation-Maximization manner. The proposed ICC compensates for minority categories to facilitate unbiased classifier optimization while maintaining the diagnostic knowledge in majority classes. Comprehensive experiments on three public long-tailed medical datasets demonstrate that our LMD framework significantly surpasses state-of-the-art approaches. The source code can be accessed at https://github.com/peterlipan/LMD.

### Efficient Vision Language Model Fine-tuning for Text-based Person Anomaly Search 
[[arxiv](https://arxiv.org/abs/2502.03230)] [[cool](https://papers.cool/arxiv/2502.03230)] [[pdf](https://arxiv.org/pdf/2502.03230)]
> **Authors**: Jiayi He,Shengeng Tang,Ao Liu,Lechao Cheng,Jingjing Wu,Yanyan Wei
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by 2025 WWW Workshop on MORE
- **标题**: None
- **领域**: 计算机视觉和模式识别,多媒体
- **Abstract**: This paper presents the HFUT-LMC team's solution to the WWW 2025 challenge on Text-based Person Anomaly Search (TPAS). The primary objective of this challenge is to accurately identify pedestrians exhibiting either normal or abnormal behavior within a large library of pedestrian images. Unlike traditional video analysis tasks, TPAS significantly emphasizes understanding and interpreting the subtle relationships between text descriptions and visual data. The complexity of this task lies in the model's need to not only match individuals to text descriptions in massive image datasets but also accurately differentiate between search results when faced with similar descriptions. To overcome these challenges, we introduce the Similarity Coverage Analysis (SCA) strategy to address the recognition difficulty caused by similar text descriptions. This strategy effectively enhances the model's capacity to manage subtle differences, thus improving both the accuracy and reliability of the search. Our proposed solution demonstrated excellent performance in this challenge.

### MaxInfo: A Training-Free Key-Frame Selection Method Using Maximum Volume for Enhanced Video Understanding 
[[arxiv](https://arxiv.org/abs/2502.03183)] [[cool](https://papers.cool/arxiv/2502.03183)] [[pdf](https://arxiv.org/pdf/2502.03183)]
> **Authors**: Pengyi Li,Irina Abdullaeva,Alexander Gambashidze,Andrey Kuznetsov,Ivan Oseledets
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: Modern Video Large Language Models (VLLMs) often rely on uniform frame sampling for video understanding, but this approach frequently fails to capture critical information due to frame redundancy and variations in video content. We propose MaxInfo, a training-free method based on the maximum volume principle, which selects and retains the most representative frames from the input video. By maximizing the geometric volume formed by selected embeddings, MaxInfo ensures that the chosen frames cover the most informative regions of the embedding space, effectively reducing redundancy while preserving diversity. This method enhances the quality of input representations and improves long video comprehension performance across benchmarks. For instance, MaxInfo achieves a 3.28% improvement on LongVideoBench and a 6.4% improvement on EgoSchema for LLaVA-Video-7B. It also achieves a 3.47% improvement for LLaVA-Video-72B. The approach is simple to implement and works with existing VLLMs without the need for additional training, making it a practical and effective alternative to traditional uniform sampling methods.

### Tell2Reg: Establishing spatial correspondence between images by the same language prompts 
[[arxiv](https://arxiv.org/abs/2502.03118)] [[cool](https://papers.cool/arxiv/2502.03118)] [[pdf](https://arxiv.org/pdf/2502.03118)]
> **Authors**: Wen Yan,Qianye Yang,Shiqi Huang,Yipei Wang,Shonit Punwani,Mark Emberton,Vasilis Stavrinides,Yipeng Hu,Dean Barratt
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 5 pages, 3 figures, conference paper
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,图像和视频处理
- **Abstract**: Spatial correspondence can be represented by pairs of segmented regions, such that the image registration networks aim to segment corresponding regions rather than predicting displacement fields or transformation parameters. In this work, we show that such a corresponding region pair can be predicted by the same language prompt on two different images using the pre-trained large multimodal models based on GroundingDINO and SAM. This enables a fully automated and training-free registration algorithm, potentially generalisable to a wide range of image registration tasks. In this paper, we present experimental results using one of the challenging tasks, registering inter-subject prostate MR images, which involves both highly variable intensity and morphology between patients. Tell2Reg is training-free, eliminating the need for costly and time-consuming data curation and labelling that was previously required for this registration task. This approach outperforms unsupervised learning-based registration methods tested, and has a performance comparable to weakly-supervised methods. Additional qualitative results are also presented to suggest that, for the first time, there is a potential correlation between language semantics and spatial correspondence, including the spatial invariance in language-prompted regions and the difference in language prompts between the obtained local and global correspondences. Code is available at https://github.com/yanwenCi/Tell2Reg.git.

### Edge Attention Module for Object Classification 
[[arxiv](https://arxiv.org/abs/2502.03103)] [[cool](https://papers.cool/arxiv/2502.03103)] [[pdf](https://arxiv.org/pdf/2502.03103)]
> **Authors**: Santanu Roy,Ashvath Suresh,Archit Gupta
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 11 pages
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: A novel ``edge attention-based Convolutional Neural Network (CNN)'' is proposed in this research for object classification task. With the advent of advanced computing technology, CNN models have achieved to remarkable success, particularly in computer vision applications. Nevertheless, the efficacy of the conventional CNN is often hindered due to class imbalance and inter-class similarity problems, which are particularly prominent in the computer vision field. In this research, we introduce for the first time an ``Edge Attention Module (EAM)'' consisting of a Max-Min pooling layer, followed by convolutional layers. This Max-Min pooling is entirely a novel pooling technique, specifically designed to capture only the edge information that is crucial for any object classification task. Therefore, by integrating this novel pooling technique into the attention module, the CNN network inherently prioritizes on essential edge features, thereby boosting the accuracy and F1-score of the model significantly. We have implemented our proposed EAM or 2EAMs on several standard pre-trained CNN models for Caltech-101, Caltech-256, CIFAR-100 and Tiny ImageNet-200 datasets. The extensive experiments reveal that our proposed framework (that is, EAM with CNN and 2EAMs with CNN), outperforms all pre-trained CNN models as well as recent trend models ``Pooling-based Vision Transformer (PiT)'', ``Convolutional Block Attention Module (CBAM)'', and ConvNext, by substantial margins. We have achieved the accuracy of 95.5% and 86% by the proposed framework on Caltech-101 and Caltech-256 datasets, respectively. So far, this is the best results on these datasets, to the best of our knowledge.

### Human-Aligned Image Models Improve Visual Decoding from the Brain 
[[arxiv](https://arxiv.org/abs/2502.03081)] [[cool](https://papers.cool/arxiv/2502.03081)] [[pdf](https://arxiv.org/pdf/2502.03081)]
> **Authors**: Nona Rajabi,Antônio H. Ribeiro,Miguel Vasco,Farzaneh Taleb,Mårten Björkman,Danica Kragic
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: Decoding visual images from brain activity has significant potential for advancing brain-computer interaction and enhancing the understanding of human perception. Recent approaches align the representation spaces of images and brain activity to enable visual decoding. In this paper, we introduce the use of human-aligned image encoders to map brain signals to images. We hypothesize that these models more effectively capture perceptual attributes associated with the rapid visual stimuli presentations commonly used in visual brain data recording experiments. Our empirical results support this hypothesis, demonstrating that this simple modification improves image retrieval accuracy by up to 21% compared to state-of-the-art methods. Comprehensive experiments confirm consistent performance improvements across diverse EEG architectures, image encoders, alignment methods, participants, and brain imaging modalities.

### High-frequency near-eye ground truth for event-based eye tracking 
[[arxiv](https://arxiv.org/abs/2502.03057)] [[cool](https://papers.cool/arxiv/2502.03057)] [[pdf](https://arxiv.org/pdf/2502.03057)]
> **Authors**: Andrea Simpsi,Andrea Aspesi,Simone Mentasti,Luca Merigo,Tommaso Ongarello,Matteo Matteucci
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Event-based eye tracking is a promising solution for efficient and low-power eye tracking in smart eyewear technologies. However, the novelty of event-based sensors has resulted in a limited number of available datasets, particularly those with eye-level annotations, crucial for algorithm validation and deep-learning training. This paper addresses this gap by presenting an improved version of a popular event-based eye-tracking dataset. We introduce a semi-automatic annotation pipeline specifically designed for event-based data annotation. Additionally, we provide the scientific community with the computed annotations for pupil detection at 200Hz.

### Driver Assistance System Based on Multimodal Data Hazard Detection 
[[arxiv](https://arxiv.org/abs/2502.03005)] [[cool](https://papers.cool/arxiv/2502.03005)] [[pdf](https://arxiv.org/pdf/2502.03005)]
> **Authors**: Long Zhouxiang,Ovanes Petrosian
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: Autonomous driving technology has advanced significantly, yet detecting driving anomalies remains a major challenge due to the long-tailed distribution of driving events. Existing methods primarily rely on single-modal road condition video data, which limits their ability to capture rare and unpredictable driving incidents. This paper proposes a multimodal driver assistance detection system that integrates road condition video, driver facial video, and audio data to enhance incident recognition accuracy. Our model employs an attention-based intermediate fusion strategy, enabling end-to-end learning without separate feature extraction. To support this approach, we develop a new three-modality dataset using a driving simulator. Experimental results demonstrate that our method effectively captures cross-modal correlations, reducing misjudgments and improving driving safety.

### Disentangling CLIP Features for Enhanced Localized Understanding 
[[arxiv](https://arxiv.org/abs/2502.02977)] [[cool](https://papers.cool/arxiv/2502.02977)] [[pdf](https://arxiv.org/pdf/2502.02977)]
> **Authors**: Samyak Rawlekar,Yujun Cai,Yiwei Wang,Ming-Hsuan Yang,Narendra Ahuja
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Vision-language models (VLMs) demonstrate impressive capabilities in coarse-grained tasks like image classification and retrieval. However, they struggle with fine-grained tasks that require localized understanding. To investigate this weakness, we comprehensively analyze CLIP features and identify an important issue: semantic features are highly correlated. Specifically, the features of a class encode information about other classes, which we call mutual feature information (MFI). This mutual information becomes evident when we query a specific class and unrelated objects are activated along with the target class. To address this issue, we propose Unmix-CLIP, a novel framework designed to reduce MFI and improve feature disentanglement. We introduce MFI loss, which explicitly separates text features by projecting them into a space where inter-class similarity is minimized. To ensure a corresponding separation in image features, we use multi-label recognition (MLR) to align the image features with the separated text features. This ensures that both image and text features are disentangled and aligned across modalities, improving feature separation for downstream tasks. For the COCO- 14 dataset, Unmix-CLIP reduces feature similarity by 24.9%. We demonstrate its effectiveness through extensive evaluations of MLR and zeroshot semantic segmentation (ZS3). In MLR, our method performs competitively on the VOC2007 and surpasses SOTA approaches on the COCO-14 dataset, using fewer training parameters. Additionally, Unmix-CLIP consistently outperforms existing ZS3 methods on COCO and VOC

### VQA-Levels: A Hierarchical Approach for Classifying Questions in VQA 
[[arxiv](https://arxiv.org/abs/2502.02951)] [[cool](https://papers.cool/arxiv/2502.02951)] [[pdf](https://arxiv.org/pdf/2502.02951)]
> **Authors**: Madhuri Latha Madaka,Chakravarthy Bhagvati
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能,机器学习
- **Abstract**: Designing datasets for Visual Question Answering (VQA) is a difficult and complex task that requires NLP for parsing and computer vision for analysing the relevant aspects of the image for answering the question asked. Several benchmark datasets have been developed by researchers but there are many issues with using them for methodical performance tests. This paper proposes a new benchmark dataset -- a pilot version called VQA-Levels is ready now -- for testing VQA systems systematically and assisting researchers in advancing the field. The questions are classified into seven levels ranging from direct answers based on low-level image features (without needing even a classifier) to those requiring high-level abstraction of the entire image content. The questions in the dataset exhibit one or many of ten properties. Each is categorised into a specific level from 1 to 7. Levels 1 - 3 are directly on the visual content while the remaining levels require extra knowledge about the objects in the image. Each question generally has a unique one or two-word answer. The questions are 'natural' in the sense that a human is likely to ask such a question when seeing the images. An example question at Level 1 is, ``What is the shape of the red colored region in the image?" while at Level 7, it is, ``Why is the man cutting the paper?". Initial testing of the proposed dataset on some of the existing VQA systems reveals that their success is high on Level 1 (low level features) and Level 2 (object classification) questions, least on Level 3 (scene text) followed by Level 6 (extrapolation) and Level 7 (whole scene analysis) questions. The work in this paper will go a long way to systematically analyze VQA systems.

### Every Angle Is Worth A Second Glance: Mining Kinematic Skeletal Structures from Multi-view Joint Cloud 
[[arxiv](https://arxiv.org/abs/2502.02936)] [[cool](https://papers.cool/arxiv/2502.02936)] [[pdf](https://arxiv.org/pdf/2502.02936)]
> **Authors**: Junkun Jiang,Jie Chen,Ho Yin Au,Mingyuan Chen,Wei Xue,Yike Guo
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by IEEE Transactions on Visualization and Computer Graphics
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Multi-person motion capture over sparse angular observations is a challenging problem under interference from both self- and mutual-occlusions. Existing works produce accurate 2D joint detection, however, when these are triangulated and lifted into 3D, available solutions all struggle in selecting the most accurate candidates and associating them to the correct joint type and target identity. As such, in order to fully utilize all accurate 2D joint location information, we propose to independently triangulate between all same-typed 2D joints from all camera views regardless of their target ID, forming the Joint Cloud. Joint Cloud consist of both valid joints lifted from the same joint type and target ID, as well as falsely constructed ones that are from different 2D sources. These redundant and inaccurate candidates are processed over the proposed Joint Cloud Selection and Aggregation Transformer (JCSAT) involving three cascaded encoders which deeply explore the trajectile, skeletal structural, and view-dependent correlations among all 3D point candidates in the cross-embedding space. An Optimal Token Attention Path (OTAP) module is proposed which subsequently selects and aggregates informative features from these redundant observations for the final prediction of human motion. To demonstrate the effectiveness of JCSAT, we build and publish a new multi-person motion capture dataset BUMocap-X with complex interactions and severe occlusions. Comprehensive experiments over the newly presented as well as benchmark datasets validate the effectiveness of the proposed framework, which outperforms all existing state-of-the-art methods, especially under challenging occlusion scenarios.

### Maximizing the Position Embedding for Vision Transformers with Global Average Pooling 
[[arxiv](https://arxiv.org/abs/2502.02919)] [[cool](https://papers.cool/arxiv/2502.02919)] [[pdf](https://arxiv.org/pdf/2502.02919)]
> **Authors**: Wonjun Lee,Bumsub Ham,Suhyun Kim
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted at AAAI 2025
- **标题**: None
- **领域**: 计算机视觉和模式识别,机器学习
- **Abstract**: In vision transformers, position embedding (PE) plays a crucial role in capturing the order of tokens. However, in vision transformer structures, there is a limitation in the expressiveness of PE due to the structure where position embedding is simply added to the token embedding. A layer-wise method that delivers PE to each layer and applies independent Layer Normalizations for token embedding and PE has been adopted to overcome this limitation. In this paper, we identify the conflicting result that occurs in a layer-wise structure when using the global average pooling (GAP) method instead of the class token. To overcome this problem, we propose MPVG, which maximizes the effectiveness of PE in a layer-wise structure with GAP. Specifically, we identify that PE counterbalances token embedding values at each layer in a layer-wise structure. Furthermore, we recognize that the counterbalancing role of PE is insufficient in the layer-wise structure, and we address this by maximizing the effectiveness of PE through MPVG. Through experiments, we demonstrate that PE performs a counterbalancing role and that maintaining this counterbalancing directionality significantly impacts vision transformers. As a result, the experimental results show that MPVG outperforms existing methods across vision transformers on various tasks.

### PoleStack: Robust Pole Estimation of Irregular Objects from Silhouette Stacking 
[[arxiv](https://arxiv.org/abs/2502.02907)] [[cool](https://papers.cool/arxiv/2502.02907)] [[pdf](https://arxiv.org/pdf/2502.02907)]
> **Authors**: Jacopo Villa,Jay W. McMahon,Issa A. D. Nesnas
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: We present an algorithm to estimate the rotation pole of a principal-axis rotator using silhouette images collected from multiple camera poses. First, a set of images is stacked to form a single silhouette-stack image, where the object's rotation introduces reflective symmetry about the imaged pole direction. We estimate this projected-pole direction by identifying maximum symmetry in the silhouette stack. To handle unknown center-of-mass image location, we apply the Discrete Fourier Transform to produce the silhouette-stack amplitude spectrum, achieving translation invariance and increased robustness to noise. Second, the 3D pole orientation is estimated by combining two or more projected-pole measurements collected from different camera orientations. We demonstrate degree-level pole estimation accuracy using low-resolution imagery, showing robustness to severe surface shadowing and centroid-based image-registration errors. The proposed approach could be suitable for pole estimation during both the approach phase toward a target object and while hovering.

## 计算机与社会(cs.CY:Computers and Society)

### Artificial Intelligence and Legal Analysis: Implications for Legal Education and the Profession 
[[arxiv](https://arxiv.org/abs/2502.03487)] [[cool](https://papers.cool/arxiv/2502.03487)] [[pdf](https://arxiv.org/pdf/2502.03487)]
> **Authors**: Lee Peoples
> **First submission**: 2025-02-04
> **First announcement**: 2025-02-06
> **comment**: ef:117 Law Library Journal No. 1 2025
- **标题**: None
- **领域**: 计算机与社会,人工智能
- **Abstract**: This article reports the results of a study examining the ability of legal and non-legal Large Language Models to perform legal analysis using the Issue-Rule-Application-Conclusion framework. LLMs were tested on legal reasoning tasks involving rule analysis and analogical reasoning. The results show that LLMs can conduct basic IRAC analysis, but are limited by brief responses lacking detail, an inability to commit to answers, false confidence, and hallucinations. The study compares legal and nonlegal LLMs, identifies shortcomings, and explores traits that may hinder their ability to think like a lawyer. It also discusses the implications for legal education and practice, highlighting the need for critical thinking skills in future lawyers and the potential pitfalls of overreliance on artificial intelligence AI resulting in a loss of logic, reasoning, and critical thinking skills.

### A Capability Approach to AI Ethics 
[[arxiv](https://arxiv.org/abs/2502.03469)] [[cool](https://papers.cool/arxiv/2502.03469)] [[pdf](https://arxiv.org/pdf/2502.03469)]
> **Authors**: Emanuele Ratti,Mark Graves
> **First submission**: 2025-01-10
> **First announcement**: 2025-02-06
> **comment**: ef:American Philosophical Quarterly, 62 (1), 2025
- **标题**: None
- **领域**: 计算机与社会,人工智能
- **Abstract**: We propose a conceptualization and implementation of AI ethics via the capability approach. We aim to show that conceptualizing AI ethics through the capability approach has two main advantages for AI ethics as a discipline. First, it helps clarify the ethical dimension of AI tools. Second, it provides guidance to implementing ethical considerations within the design of AI tools. We illustrate these advantages in the context of AI tools in medicine, by showing how ethics-based auditing of AI tools in medicine can greatly benefit from our capability-based approach.

### Where AI Assurance Might Go Wrong: Initial lessons from engineering of critical systems 
[[arxiv](https://arxiv.org/abs/2502.03467)] [[cool](https://papers.cool/arxiv/2502.03467)] [[pdf](https://arxiv.org/pdf/2502.03467)]
> **Authors**: Robin Bloomfield,John Rushby
> **First submission**: 2025-01-07
> **First announcement**: 2025-02-06
> **comment**: Presented at UKAISafety Institute (AISI) Conference on FrontierAISafety Frameworks (FAISC 24), Berkeley CA, November 2024
- **标题**: None
- **领域**: 计算机与社会,人工智能,软件工程
- **Abstract**: We draw on our experience working on system and software assurance and evaluation for systems important to society to summarise how safety engineering is performed in traditional critical systems, such as aircraft flight control. We analyse how this critical systems perspective might support the development and implementation of AI Safety Frameworks. We present the analysis in terms of: system engineering, safety and risk analysis, and decision analysis and support. We consider four key questions: What is the system? How good does it have to be? What is the impact of criticality on system development? and How much should we trust it? We identify topics worthy of further discussion. In particular, we are concerned that system boundaries are not broad enough, that the tolerability and nature of the risks are not sufficiently elaborated, and that the assurance methods lack theories that would allow behaviours to be adequately assured. We advocate the use of assurance cases based on Assurance 2.0 to support decision making in which the criticality of the decision as well as the criticality of the system are evaluated. We point out the orders of magnitude difference in confidence needed in critical rather than everyday systems and how everyday techniques do not scale in rigour. Finally we map our findings in detail to two of the questions posed by the FAISC organisers and we note that the engineering of critical systems has evolved through open and diverse discussion. We hope that topics identified here will support the post-FAISC dialogues.

### Ethical Considerations for the Military Use of Artificial Intelligence in Visual Reconnaissance 
[[arxiv](https://arxiv.org/abs/2502.03376)] [[cool](https://papers.cool/arxiv/2502.03376)] [[pdf](https://arxiv.org/pdf/2502.03376)]
> **Authors**: Mathias Anneken,Nadia Burkart,Fabian Jeschke,Achim Kuwertz-Wolf,Almuth Mueller,Arne Schumann,Michael Teutsch
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: White Paper, 30 pages, 7 figures
- **标题**: None
- **领域**: 计算机与社会,计算机视觉和模式识别
- **Abstract**: This white paper underscores the critical importance of responsibly deploying Artificial Intelligence (AI) in military contexts, emphasizing a commitment to ethical and legal standards. The evolving role of AI in the military goes beyond mere technical applications, necessitating a framework grounded in ethical principles. The discussion within the paper delves into ethical AI principles, particularly focusing on the Fairness, Accountability, Transparency, and Ethics (FATE) guidelines. Noteworthy considerations encompass transparency, justice, non-maleficence, and responsibility. Importantly, the paper extends its examination to military-specific ethical considerations, drawing insights from the Just War theory and principles established by prominent entities. In addition to the identified principles, the paper introduces further ethical considerations specifically tailored for military AI applications. These include traceability, proportionality, governability, responsibility, and reliability. The application of these ethical principles is discussed on the basis of three use cases in the domains of sea, air, and land. Methods of automated sensor data analysis, eXplainable AI (XAI), and intuitive user experience are utilized to specify the use cases close to real-world scenarios. This comprehensive approach to ethical considerations in military AI reflects a commitment to aligning technological advancements with established ethical frameworks. It recognizes the need for a balance between leveraging AI's potential benefits in military operations while upholding moral and legal standards. The inclusion of these ethical principles serves as a foundation for responsible and accountable use of AI in the complex and dynamic landscape of military scenarios.

## 分布式、并行和集群计算(cs.DC:Distributed, Parallel, and Cluster Computing)

### HACK: Homomorphic Acceleration via Compression of the Key-Value Cache for Disaggregated LLM Inference 
[[arxiv](https://arxiv.org/abs/2502.03589)] [[cool](https://papers.cool/arxiv/2502.03589)] [[pdf](https://arxiv.org/pdf/2502.03589)]
> **Authors**: Zeyu Zhang,Haiying Shen,Shay Vargaftik,Ran Ben Basat,Michael Mitzenmacher,Minlan Yu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 分布式、并行和集群计算,机器学习
- **Abstract**: Disaggregated Large Language Model (LLM) inference has gained popularity as it separates the computation-intensive prefill stage from the memory-intensive decode stage, avoiding the prefill-decode interference and improving resource utilization. However, transmitting Key-Value (KV) data between the two stages can be a bottleneck, especially for long prompts. Additionally, the computation time overhead for prefill and decode is key for optimizing Job Completion Time (JCT), and KV data size can become prohibitive for long prompts and sequences. Existing KV quantization methods can alleviate the transmission bottleneck and reduce memory requirements, but they introduce significant dequantization overhead, exacerbating the computation time. We propose Homomorphic Acceleration via Compression of the KV cache (HACK) for disaggregated LLM inference. HACK eliminates the heavy KV dequantization step, and directly performs computations on quantized KV data to approximate and reduce the cost of the expensive matrix-multiplication step. Extensive trace-driven experiments show that HACK reduces JCT by up to 70.9% compared to disaggregated LLM inference baseline and by up to 52.3% compared to state-of-the-art KV quantization methods.

## 数据结构和算法(cs.DS:Data Structures and Algorithms)

### Cascaded Learned Bloom Filter for Optimal Model-Filter Size Balance and Fast Rejection 
[[arxiv](https://arxiv.org/abs/2502.03696)] [[cool](https://papers.cool/arxiv/2502.03696)] [[pdf](https://arxiv.org/pdf/2502.03696)]
> **Authors**: Atsuki Sato,Yusuke Matsui
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 数据结构和算法,计算复杂度,机器学习
- **Abstract**: Recent studies have demonstrated that learned Bloom filters, which combine machine learning with the classical Bloom filter, can achieve superior memory efficiency. However, existing learned Bloom filters face two critical unresolved challenges: the balance between the machine learning model size and the Bloom filter size is not optimal, and the reject time cannot be minimized effectively. We propose the Cascaded Learned Bloom Filter (CLBF) to address these issues. Our dynamic programming-based optimization automatically selects configurations that achieve an optimal balance between the model and filter sizes while minimizing reject time. Experiments on real-world datasets show that CLBF reduces memory usage by up to 24% and decreases reject time by up to 14 times compared to state-of-the-art learned Bloom filters.

## 新兴技术(cs.ET:Emerging Technologies)

### Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing 
[[arxiv](https://arxiv.org/abs/2502.03086)] [[cool](https://papers.cool/arxiv/2502.03086)] [[pdf](https://arxiv.org/pdf/2502.03086)]
> **Authors**: Salvatore Sinno,Markus Bertl,Arati Sahoo,Bhavika Bhalgamiya,Thomas Groß,Nicholas Chancellor
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: accapted at IEEE International Conference on Next Generation Information System Engineering
- **标题**: None
- **领域**: 新兴技术,人工智能,机器学习,神经和进化计算,量子物理学
- **Abstract**: This study explores the implementation of large Quantum Restricted Boltzmann Machines (QRBMs), a key advancement in Quantum Machine Learning (QML), as generative models on D-Wave's Pegasus quantum hardware to address dataset imbalance in Intrusion Detection Systems (IDS). By leveraging Pegasus's enhanced connectivity and computational capabilities, a QRBM with 120 visible and 120 hidden units was successfully embedded, surpassing the limitations of default embedding tools. The QRBM synthesized over 1.6 million attack samples, achieving a balanced dataset of over 4.2 million records. Comparative evaluations with traditional balancing methods, such as SMOTE and RandomOversampler, revealed that QRBMs produced higher-quality synthetic samples, significantly improving detection rates, precision, recall, and F1 score across diverse classifiers. The study underscores the scalability and efficiency of QRBMs, completing balancing tasks in milliseconds. These findings highlight the transformative potential of QML and QRBMs as next-generation tools in data preprocessing, offering robust solutions for complex computational challenges in modern information systems.

## 计算机科学与博弈论(cs.GT:Computer Science and Game Theory)

### Policy Abstraction and Nash Refinement in Tree-Exploiting PSRO 
[[arxiv](https://arxiv.org/abs/2502.02901)] [[cool](https://papers.cool/arxiv/2502.02901)] [[pdf](https://arxiv.org/pdf/2502.02901)]
> **Authors**: Christine Konicki,Mithun Chakraborty,Michael P. Wellman
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 计算机科学与博弈论,人工智能
- **Abstract**: Policy Space Response Oracles (PSRO) interleaves empirical game-theoretic analysis with deep reinforcement learning (DRL) to solve games too complex for traditional analytic methods. Tree-exploiting PSRO (TE-PSRO) is a variant of this approach that iteratively builds a coarsened empirical game model in extensive form using data obtained from querying a simulator that represents a detailed description of the game. We make two main methodological advances to TE-PSRO that enhance its applicability to complex games of imperfect information. First, we introduce a scalable representation for the empirical game tree where edges correspond to implicit policies learned through DRL. These policies cover conditions in the underlying game abstracted in the game model, supporting sustainable growth of the tree over epochs. Second, we leverage extensive form in the empirical model by employing refined Nash equilibria to direct strategy exploration. To enable this, we give a modular and scalable algorithm based on generalized backward induction for computing a subgame perfect equilibrium (SPE) in an imperfect-information game. We experimentally evaluate our approach on a suite of games including an alternating-offer bargaining game with outside offers; our results demonstrate that TE-PSRO converges toward equilibrium faster when new strategies are generated based on SPE rather than Nash equilibrium, and with reasonable time/memory requirements for the growing empirical model.

## 人机交互(cs.HC:Human-Computer Interaction)

### Controllable GUI Exploration 
[[arxiv](https://arxiv.org/abs/2502.03330)] [[cool](https://papers.cool/arxiv/2502.03330)] [[pdf](https://arxiv.org/pdf/2502.03330)]
> **Authors**: Aryan Garg,Yue Jiang,Antti Oulasvirta
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 人机交互,人工智能,计算机视觉和模式识别,图形
- **Abstract**: During the early stages of interface design, designers need to produce multiple sketches to explore a design space. Design tools often fail to support this critical stage, because they insist on specifying more details than necessary. Although recent advances in generative AI have raised hopes of solving this issue, in practice they fail because expressing loose ideas in a prompt is impractical. In this paper, we propose a diffusion-based approach to the low-effort generation of interface sketches. It breaks new ground by allowing flexible control of the generation process via three types of inputs: A) prompts, B) wireframes, and C) visual flows. The designer can provide any combination of these as input at any level of detail, and will get a diverse gallery of low-fidelity solutions in response. The unique benefit is that large design spaces can be explored rapidly with very little effort in input-specification. We present qualitative results for various combinations of input specifications. Additionally, we demonstrate that our model aligns more accurately with these specifications than other models.

### Automatic Prompt Optimization Techniques: Exploring the Potential for Synthetic Data Generation 
[[arxiv](https://arxiv.org/abs/2502.03078)] [[cool](https://papers.cool/arxiv/2502.03078)] [[pdf](https://arxiv.org/pdf/2502.03078)]
> **Authors**: Nina Freise,Marius Heitlinger,Ruben Nuredini,Gerrit Meixner
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This preprint represents the submitted manuscript version of our paper for the 2025 HCI International Conference and has not yet undergone peer review or any post-submission revisions or corrections
- **标题**: None
- **领域**: 人机交互,机器学习
- **Abstract**: Artificial Intelligence (AI) advancement is heavily dependent on access to large-scale, high-quality training data. However, in specialized domains such as healthcare, data acquisition faces significant constraints due to privacy regulations, ethical considerations, and limited availability. While synthetic data generation offers a promising solution, conventional approaches typically require substantial real data for training generative models. The emergence of large-scale prompt-based models presents new opportunities for synthetic data generation without direct access to protected data. However, crafting effective prompts for domain-specific data generation remains challenging, and manual prompt engineering proves insufficient for achieving output with sufficient precision and authenticity. We review recent developments in automatic prompt optimization, following PRISMA guidelines. We analyze six peer-reviewed studies published between 2020 and 2024 that focus on automatic data-free prompt optimization methods. Our analysis reveals three approaches: feedback-driven, error-based, and control-theoretic. Although all approaches demonstrate promising capabilities in prompt refinement and adaptation, our findings suggest the need for an integrated framework that combines complementary optimization techniques to enhance synthetic data generation while minimizing manual intervention. We propose future research directions toward developing robust, iterative prompt optimization frameworks capable of improving the quality of synthetic data. This advancement can be particularly crucial for sensitive fields and in specialized domains where data access is restricted, potentially transforming how we approach synthetic data generation for AI development.

## 信息检索(cs.IR:Information Retrieval)

### Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.03715)] [[cool](https://papers.cool/arxiv/2502.03715)] [[pdf](https://arxiv.org/pdf/2502.03715)]
> **Authors**: Rui Cai,Chao Wang,Qianyi Cai,Dazhong Shen,Hui Xiong
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 信息检索,人工智能
- **Abstract**: Knowledge Graph-based recommendations have gained significant attention due to their ability to leverage rich semantic relationships. However, constructing and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy of KGs can suffer from noisy, outdated, or irrelevant triplets. Recent advancements in Large Language Models (LLMs) offer a promising way to improve the quality and relevance of KGs for recommendation tasks. Despite this, integrating LLMs into KG-based systems presents challenges, such as efficiently augmenting KGs, addressing hallucinations, and developing effective joint learning methods. In this paper, we propose the Confidence-aware KG-based Recommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework that combines KGs and LLMs for recommendation task. The framework includes: (1) an LLM-based subgraph augmenter for enriching KGs with high-quality information, (2) a confidence-aware message propagation mechanism to filter noisy triplets, and (3) a dual-view contrastive learning method to integrate user-item interactions and KG data. Additionally, we employ a confidence-aware explanation generation process to guide LLMs in producing realistic explanations for recommendations. Finally, extensive experiments demonstrate the effectiveness of CKG-LLMA across multiple public datasets.

### Contrastive Learning for Cold Start Recommendation with Adaptive Feature Fusion 
[[arxiv](https://arxiv.org/abs/2502.03664)] [[cool](https://papers.cool/arxiv/2502.03664)] [[pdf](https://arxiv.org/pdf/2502.03664)]
> **Authors**: Jiacheng Hu,Tai An,Zidong Yu,Junliang Du,Yuanshuai Luo
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 信息检索,机器学习
- **Abstract**: This paper proposes a cold start recommendation model that integrates contrastive learning, aiming to solve the problem of performance degradation of recommendation systems in cold start scenarios due to the scarcity of user and item interaction data. The model dynamically adjusts the weights of key features through an adaptive feature selection module and effectively integrates user attributes, item meta-information, and contextual features by combining a multimodal feature fusion mechanism, thereby improving recommendation performance. In addition, the model introduces a contrastive learning mechanism to enhance the robustness and generalization ability of feature representation by constructing positive and negative sample pairs. Experiments are conducted on the MovieLens-1M dataset. The results show that the proposed model significantly outperforms mainstream recommendation methods such as Matrix Factorization, LightGBM, DeepFM, and AutoRec in terms of HR, NDCG, MRR, and Recall, especially in cold start scenarios. Ablation experiments further verify the key role of each module in improving model performance, and the learning rate sensitivity analysis shows that a moderate learning rate is crucial to the optimization effect of the model. This study not only provides a new solution to the cold start problem but also provides an important reference for the application of contrastive learning in recommendation systems. In the future, this model is expected to play a role in a wider range of scenarios, such as real-time recommendation and cross-domain recommendation.

### Large Language Models Are Universal Recommendation Learners 
[[arxiv](https://arxiv.org/abs/2502.03041)] [[cool](https://papers.cool/arxiv/2502.03041)] [[pdf](https://arxiv.org/pdf/2502.03041)]
> **Authors**: Junguang Jiang,Yanwen Huang,Bin Liu,Xiaoyu Kong,Ziru Xu,Han Zhu,Jian Xu,Bo Zheng
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 信息检索,机器学习
- **Abstract**: In real-world recommender systems, different tasks are typically addressed using supervised learning on task-specific datasets with carefully designed model architectures. We demonstrate that large language models (LLMs) can function as universal recommendation learners, capable of handling multiple tasks within a unified input-output framework, eliminating the need for specialized model designs. To improve the recommendation performance of LLMs, we introduce a multimodal fusion module for item representation and a sequence-in-set-out approach for efficient candidate generation. When applied to industrial-scale data, our LLM achieves competitive results with expert models elaborately designed for different recommendation tasks. Furthermore, our analysis reveals that recommendation outcomes are highly sensitive to text input, highlighting the potential of prompt engineering in optimizing industrial-scale recommender systems.

### FACTER: Fairness-Aware Conformal Thresholding and Prompt Engineering for Enabling Fair LLM-Based Recommender Systems 
[[arxiv](https://arxiv.org/abs/2502.02966)] [[cool](https://papers.cool/arxiv/2502.02966)] [[pdf](https://arxiv.org/pdf/2502.02966)]
> **Authors**: Arya Fayyazi,Mehdi Kamal,Massoud Pedram
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 信息检索,人工智能,计算机与社会,机器学习
- **Abstract**: We propose FACTER, a fairness-aware framework for LLM-based recommendation systems that integrates conformal prediction with dynamic prompt engineering. By introducing an adaptive semantic variance threshold and a violation-triggered mechanism, FACTER automatically tightens fairness constraints whenever biased patterns emerge. We further develop an adversarial prompt generator that leverages historical violations to reduce repeated demographic biases without retraining the LLM. Empirical results on MovieLens and Amazon show that FACTER substantially reduces fairness violations (up to 95.5%) while maintaining strong recommendation accuracy, revealing semantic variance as a potent proxy of bias.

## 机器学习(cs.LG:Machine Learning)

### StarMAP: Global Neighbor Embedding for Faithful Data Visualization 
[[arxiv](https://arxiv.org/abs/2502.03776)] [[cool](https://papers.cool/arxiv/2502.03776)] [[pdf](https://arxiv.org/pdf/2502.03776)]
> **Authors**: Koshi Watanabe,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Neighbor embedding is widely employed to visualize high-dimensional data; however, it frequently overlooks the global structure, e.g., intercluster similarities, thereby impeding accurate visualization. To address this problem, this paper presents Star-attracted Manifold Approximation and Projection (StarMAP), which incorporates the advantage of principal component analysis (PCA) in neighbor embedding. Inspired by the property of PCA embedding, which can be viewed as the largest shadow of the data, StarMAP introduces the concept of \textit{star attraction} by leveraging the PCA embedding. This approach yields faithful global structure preservation while maintaining the interpretability and computational efficiency of neighbor embedding. StarMAP was compared with existing methods in the visualization tasks of toy datasets, single-cell RNA sequencing data, and deep representation. The experimental results show that StarMAP is simple but effective in realizing faithful visualizations.

### ExpProof : Operationalizing Explanations for Confidential Models with ZKPs 
[[arxiv](https://arxiv.org/abs/2502.03773)] [[cool](https://papers.cool/arxiv/2502.03773)] [[pdf](https://arxiv.org/pdf/2502.03773)]
> **Authors**: Chhavi Yadav,Evan Monroe Laufer,Dan Boneh,Kamalika Chaudhuri
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,密码学和安全
- **Abstract**: In principle, explanations are intended as a way to increase trust in machine learning models and are often obligated by regulations. However, many circumstances where these are demanded are adversarial in nature, meaning the involved parties have misaligned interests and are incentivized to manipulate explanations for their purpose. As a result, explainability methods fail to be operational in such settings despite the demand \cite{bordt2022post}. In this paper, we take a step towards operationalizing explanations in adversarial scenarios with Zero-Knowledge Proofs (ZKPs), a cryptographic primitive. Specifically we explore ZKP-amenable versions of the popular explainability algorithm LIME and evaluate their performance on Neural Networks and Random Forests.

### Adaptive Semantic Prompt Caching with VectorQ 
[[arxiv](https://arxiv.org/abs/2502.03771)] [[cool](https://papers.cool/arxiv/2502.03771)] [[pdf](https://arxiv.org/pdf/2502.03771)]
> **Authors**: Luis Gaspar Schroeder,Shu Liu,Alejandro Cuadron,Mark Zhao,Stephan Krusche,Alfons Kemper,Matei Zaharia,Joseph E. Gonzalez
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,计算语言学
- **Abstract**: Semantic prompt caches reduce the latency and cost of large language model (LLM) inference by reusing cached LLM-generated responses for semantically similar prompts. Vector similarity metrics assign a numerical score to quantify the similarity between an embedded prompt and its nearest neighbor in the cache. Existing systems rely on a static threshold to classify whether the similarity score is sufficiently high to result in a cache hit. We show that this one-size-fits-all threshold is insufficient across different prompts. We propose VectorQ, a framework to learn embedding-specific threshold regions that adapt to the complexity and uncertainty of an embedding. Through evaluations on a combination of four diverse datasets, we show that VectorQ consistently outperforms state-of-the-art systems across all static thresholds, achieving up to 12x increases in cache hit rate and error rate reductions up to 92%.

### Learning Reward Machines from Partially Observed Optimal Policies 
[[arxiv](https://arxiv.org/abs/2502.03762)] [[cool](https://papers.cool/arxiv/2502.03762)] [[pdf](https://arxiv.org/pdf/2502.03762)]
> **Authors**: Mohamad Louai Shehab,Antoine Aspeel,Necmiye Ozay
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,形式语言和自动机理论
- **Abstract**: Inverse reinforcement learning is the problem of inferring a reward function from an optimal policy. In this work, it is assumed that the reward is expressed as a reward machine whose transitions depend on atomic propositions associated with the state of a Markov Decision Process (MDP). Our goal is to identify the true reward machine using finite information. To this end, we first introduce the notion of a prefix tree policy which associates a distribution of actions to each state of the MDP and each attainable finite sequence of atomic propositions. Then, we characterize an equivalence class of reward machines that can be identified given the prefix tree policy. Finally, we propose a SAT-based algorithm that uses information extracted from the prefix tree policy to solve for a reward machine. It is proved that if the prefix tree policy is known up to a sufficient (but finite) depth, our algorithm recovers the exact reward machine up to the equivalence class. This sufficient depth is derived as a function of the number of MDP states and (an upper bound on) the number of states of the reward machine. Several examples are used to demonstrate the effectiveness of the approach.

### Regularization via f-Divergence: An Application to Multi-Oxide Spectroscopic Analysis 
[[arxiv](https://arxiv.org/abs/2502.03755)] [[cool](https://papers.cool/arxiv/2502.03755)] [[pdf](https://arxiv.org/pdf/2502.03755)]
> **Authors**: Weizhi Li,Natalie Klein,Brendan Gifford,Elizabeth Sklute,Carey Legett,Samuel Clegg
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: In this paper, we address the task of characterizing the chemical composition of planetary surfaces using convolutional neural networks (CNNs). Specifically, we seek to predict the multi-oxide weights of rock samples based on spectroscopic data collected under Martian conditions. We frame this problem as a multi-target regression task and propose a novel regularization method based on f-divergence. The f-divergence regularization is designed to constrain the distributional discrepancy between predictions and noisy targets. This regularizer serves a dual purpose: on the one hand, it mitigates overfitting by enforcing a constraint on the distributional difference between predictions and noisy targets. On the other hand, it acts as an auxiliary loss function, penalizing the neural network when the divergence between the predicted and target distributions becomes too large. To enable backpropagation during neural network training, we develop a differentiable f-divergence and incorporate it into the f-divergence regularization, making the network training feasible. We conduct experiments using spectra collected in a Mars-like environment by the remote-sensing instruments aboard the Curiosity and Perseverance rovers. Experimental results on multi-oxide weight prediction demonstrate that the proposed $f$-divergence regularization performs better than or comparable to standard regularization methods including $L_1$, $L_2$, and dropout. Notably, combining the $f$-divergence regularization with these standard regularization further enhances performance, outperforming each regularization method used independently.

### PRISM: A Robust Framework for Skill-based Meta-Reinforcement Learning with Noisy Demonstrations 
[[arxiv](https://arxiv.org/abs/2502.03752)] [[cool](https://papers.cool/arxiv/2502.03752)] [[pdf](https://arxiv.org/pdf/2502.03752)]
> **Authors**: Sanghyeon Lee,Sangjun Bae,Yisak Park,Seungyul Han
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages main, 19 pages appendix with reference. Submitted to ICML 2025
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Meta-reinforcement learning (Meta-RL) facilitates rapid adaptation to unseen tasks but faces challenges in long-horizon environments. Skill-based approaches tackle this by decomposing state-action sequences into reusable skills and employing hierarchical decision-making. However, these methods are highly susceptible to noisy offline demonstrations, resulting in unstable skill learning and degraded performance. To overcome this, we propose Prioritized Refinement for Skill-Based Meta-RL (PRISM), a robust framework that integrates exploration near noisy data to generate online trajectories and combines them with offline data. Through prioritization, PRISM extracts high-quality data to learn task-relevant skills effectively. By addressing the impact of noise, our method ensures stable skill learning and achieves superior performance in long-horizon tasks, even with noisy and sub-optimal data.

### Principal Curvatures Estimation with Applications to Single Cell Data 
[[arxiv](https://arxiv.org/abs/2502.03750)] [[cool](https://papers.cool/arxiv/2502.03750)] [[pdf](https://arxiv.org/pdf/2502.03750)]
> **Authors**: Yanlei Zhang,Lydia Mezrag,Xingzhi Sun,Charles Xu,Kincaid Macdonald,Dhananjay Bhaskar,Smita Krishnaswamy,Guy Wolf,Bastian Rieck
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: To be published in ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: The rapidly growing field of single-cell transcriptomic sequencing (scRNAseq) presents challenges for data analysis due to its massive datasets. A common method in manifold learning consists in hypothesizing that datasets lie on a lower dimensional manifold. This allows to study the geometry of point clouds by extracting meaningful descriptors like curvature. In this work, we will present Adaptive Local PCA (AdaL-PCA), a data-driven method for accurately estimating various notions of intrinsic curvature on data manifolds, in particular principal curvatures for surfaces. The model relies on local PCA to estimate the tangent spaces. The evaluation of AdaL-PCA on sampled surfaces shows state-of-the-art results. Combined with a PHATE embedding, the model applied to single-cell RNA sequencing data allows us to identify key variations in the cellular differentiation.

### PINS: Proximal Iterations with Sparse Newton and Sinkhorn for Optimal Transport 
[[arxiv](https://arxiv.org/abs/2502.03749)] [[cool](https://papers.cool/arxiv/2502.03749)] [[pdf](https://arxiv.org/pdf/2502.03749)]
> **Authors**: Di Wu,Ling Liang,Haizhao Yang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 12 pages, 5 figures
- **标题**: None
- **领域**: 机器学习,优化与控制
- **Abstract**: Optimal transport (OT) is a critical problem in optimization and machine learning, where accuracy and efficiency are paramount. Although entropic regularization and the Sinkhorn algorithm improve scalability, they frequently encounter numerical instability and slow convergence, especially when the regularization parameter is small. In this work, we introduce Proximal Iterations with Sparse Newton and Sinkhorn methods (PINS) to efficiently compute highly accurate solutions for large-scale OT problems. A reduced computational complexity through overall sparsity and global convergence are guaranteed by rigorous theoretical analysis. Our approach offers three key advantages: it achieves accuracy comparable to exact solutions, progressively accelerates each iteration for greater efficiency, and enhances robustness by reducing sensitivity to regularization parameters. Extensive experiments confirm these advantages, demonstrating superior performance compared to related methods.

### Multiple Invertible and Partial-Equivariant Function for Latent Vector Transformation to Enhance Disentanglement in VAEs 
[[arxiv](https://arxiv.org/abs/2502.03740)] [[cool](https://papers.cool/arxiv/2502.03740)] [[pdf](https://arxiv.org/pdf/2502.03740)]
> **Authors**: Hee-Jun Jung,Jaehyoung Jeong,Kangil Kim
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 24 pages, 21 figures
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Disentanglement learning is a core issue for understanding and re-using trained information in Variational AutoEncoder (VAE), and effective inductive bias has been reported as a key factor. However, the actual implementation of such bias is still vague. In this paper, we propose a novel method, called Multiple Invertible and partial-equivariant transformation (MIPE-transformation), to inject inductive bias by 1) guaranteeing the invertibility of latent-to-latent vector transformation while preserving a certain portion of equivariance of input-to-latent vector transformation, called Invertible and partial-equivariant transformation (IPE-transformation), 2) extending the form of prior and posterior in VAE frameworks to an unrestricted form through a learnable conversion to an approximated exponential family, called Exponential Family conversion (EF-conversion), and 3) integrating multiple units of IPE-transformation and EF-conversion, and their training. In experiments on 3D Cars, 3D Shapes, and dSprites datasets, MIPE-transformation improves the disentanglement performance of state-of-the-art VAEs.

### Mitigating the Participation Bias by Balancing Extreme Ratings 
[[arxiv](https://arxiv.org/abs/2502.03737)] [[cool](https://papers.cool/arxiv/2502.03737)] [[pdf](https://arxiv.org/pdf/2502.03737)]
> **Authors**: Yongkang Guo,Yuqing Kong,Jialiang Liu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: In Proceedings of the ACM Web Conference 2025,15 pages
- **标题**: None
- **领域**: 机器学习,计算机科学与博弈论
- **Abstract**: Rating aggregation plays a crucial role in various fields, such as product recommendations, hotel rankings, and teaching evaluations. However, traditional averaging methods can be affected by participation bias, where some raters do not participate in the rating process, leading to potential distortions. In this paper, we consider a robust rating aggregation task under the participation bias. We assume that raters may not reveal their ratings with a certain probability depending on their individual ratings, resulting in partially observed samples. Our goal is to minimize the expected squared loss between the aggregated ratings and the average of all underlying ratings (possibly unobserved) in the worst-case scenario. We focus on two settings based on whether the sample size (i.e. the number of raters) is known. In the first setting, where the sample size is known, we propose an aggregator, named as the Balanced Extremes Aggregator. It estimates unrevealed ratings with a balanced combination of extreme ratings. When the sample size is unknown, we derive another aggregator, the Polarizing-Averaging Aggregator, which becomes optimal as the sample size grows to infinity. Numerical results demonstrate the superiority of our proposed aggregators in mitigating participation bias, compared to simple averaging and the spectral method. Furthermore, we validate the effectiveness of our aggregators on a real-world dataset.

### Optimal Control of Fluid Restless Multi-armed Bandits: A Machine Learning Approach 
[[arxiv](https://arxiv.org/abs/2502.03725)] [[cool](https://papers.cool/arxiv/2502.03725)] [[pdf](https://arxiv.org/pdf/2502.03725)]
> **Authors**: Dimitris Bertsimas,Cheol Woo Kim,José Niño-Mora
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: We propose a machine learning approach to the optimal control of fluid restless multi-armed bandits (FRMABs) with state equations that are either affine or quadratic in the state variables. By deriving fundamental properties of FRMAB problems, we design an efficient machine learning based algorithm. Using this algorithm, we solve multiple instances with varying initial states to generate a comprehensive training set. We then learn a state feedback policy using Optimal Classification Trees with hyperplane splits (OCT-H). We test our approach on machine maintenance, epidemic control and fisheries control problems. Our method yields high-quality state feedback policies and achieves a speed-up of up to 26 million times compared to a direct numerical algorithm for fluid problems.

### On the Expressive Power of Subgraph Graph Neural Networks for Graphs with Bounded Cycles 
[[arxiv](https://arxiv.org/abs/2502.03703)] [[cool](https://papers.cool/arxiv/2502.03703)] [[pdf](https://arxiv.org/pdf/2502.03703)]
> **Authors**: Ziang Chen,Qiao Zhang,Runzhong Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Graph neural networks (GNNs) have been widely used in graph-related contexts. It is known that the separation power of GNNs is equivalent to that of the Weisfeiler-Lehman (WL) test; hence, GNNs are imperfect at identifying all non-isomorphic graphs, which severely limits their expressive power. This work investigates $k$-hop subgraph GNNs that aggregate information from neighbors with distances up to $k$ and incorporate the subgraph structure. We prove that under appropriate assumptions, the $k$-hop subgraph GNNs can approximate any permutation-invariant/equivariant continuous function over graphs without cycles of length greater than $2k+1$ within any error tolerance. We also provide an extension to $k$-hop GNNs without incorporating the subgraph structure. Our numerical experiments on established benchmarks and novel architectures validate our theory on the relationship between the information aggregation distance and the cycle size.

### How vulnerable is my policy? Adversarial attacks on modern behavior cloning policies 
[[arxiv](https://arxiv.org/abs/2502.03698)] [[cool](https://papers.cool/arxiv/2502.03698)] [[pdf](https://arxiv.org/pdf/2502.03698)]
> **Authors**: Basavasagar Patil,Akansha Kalra,Guanhong Tao,Daniel S. Brown
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,密码学和安全,机器人技术
- **Abstract**: Learning from Demonstration (LfD) algorithms have shown promising results in robotic manipulation tasks, but their vulnerability to adversarial attacks remains underexplored. This paper presents a comprehensive study of adversarial attacks on both classic and recently proposed algorithms, including Behavior Cloning (BC), LSTM-GMM, Implicit Behavior Cloning (IBC), Diffusion Policy (DP), and VQ-Behavior Transformer (VQ-BET). We study the vulnerability of these methods to untargeted, targeted and universal adversarial perturbations. While explicit policies, such as BC, LSTM-GMM and VQ-BET can be attacked in the same manner as standard computer vision models, we find that attacks for implicit and denoising policy models are nuanced and require developing novel attack methods. Our experiments on several simulated robotic manipulation tasks reveal that most of the current methods are highly vulnerable to adversarial perturbations. We also show that these attacks are transferable across algorithms, architectures, and tasks, raising concerning security vulnerabilities with potentially a white-box threat model. In addition, we test the efficacy of a randomized smoothing, a widely used adversarial defense technique, and highlight its limitation in defending against attacks on complex and multi-modal action distribution common in complex control tasks. In summary, our findings highlight the vulnerabilities of modern BC algorithms, paving way for future work in addressing such limitations.

### DocMIA: Document-Level Membership Inference Attacks against DocVQA Models 
[[arxiv](https://arxiv.org/abs/2502.03692)] [[cool](https://papers.cool/arxiv/2502.03692)] [[pdf](https://arxiv.org/pdf/2502.03692)]
> **Authors**: Khanh Nguyen,Raouf Kerkouche,Mario Fritz,Dimosthenis Karatzas
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: ICLR 2025
- **标题**: None
- **领域**: 机器学习,计算语言学,密码学和安全
- **Abstract**: Document Visual Question Answering (DocVQA) has introduced a new paradigm for end-to-end document understanding, and quickly became one of the standard benchmarks for multimodal LLMs. Automating document processing workflows, driven by DocVQA models, presents significant potential for many business sectors. However, documents tend to contain highly sensitive information, raising concerns about privacy risks associated with training such DocVQA models. One significant privacy vulnerability, exploited by the membership inference attack, is the possibility for an adversary to determine if a particular record was part of the model's training data. In this paper, we introduce two novel membership inference attacks tailored specifically to DocVQA models. These attacks are designed for two different adversarial scenarios: a white-box setting, where the attacker has full access to the model architecture and parameters, and a black-box setting, where only the model's outputs are available. Notably, our attacks assume the adversary lacks access to auxiliary datasets, which is more realistic in practice but also more challenging. Our unsupervised methods outperform existing state-of-the-art membership inference attacks across a variety of DocVQA models and datasets, demonstrating their effectiveness and highlighting the privacy risks in this domain.

### Variational Control for Guidance in Diffusion Models 
[[arxiv](https://arxiv.org/abs/2502.03686)] [[cool](https://papers.cool/arxiv/2502.03686)] [[pdf](https://arxiv.org/pdf/2502.03686)]
> **Authors**: Kushagra Pandey,Farrin Marouf Sofian,Felix Draxler,Theofanis Karaletsos,Stephan Mandt
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages in main text. Total of 20 pages
- **标题**: None
- **领域**: 机器学习,人工智能,计算机视觉和模式识别,机器学习
- **Abstract**: Diffusion models exhibit excellent sample quality, but existing guidance methods often require additional model training or are limited to specific tasks. We revisit guidance in diffusion models from the perspective of variational inference and control, introducing Diffusion Trajectory Matching (DTM) that enables guiding pretrained diffusion trajectories to satisfy a terminal cost. DTM unifies a broad class of guidance methods and enables novel instantiations. We introduce a new method within this framework that achieves state-of-the-art results on several linear and (blind) non-linear inverse problems without requiring additional model training or modifications. For instance, in ImageNet non-linear deblurring, our model achieves an FID score of 34.31, significantly improving over the best pretrained-method baseline (FID 78.07). We will make the code available in a future update.

### Chaos into Order: Neural Framework for Expected Value Estimation of Stochastic Partial Differential Equations 
[[arxiv](https://arxiv.org/abs/2502.03670)] [[cool](https://papers.cool/arxiv/2502.03670)] [[pdf](https://arxiv.org/pdf/2502.03670)]
> **Authors**: Ísak Pétursson,María Óskarsdóttir
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Stochastic Partial Differential Equations (SPDEs) are fundamental to modeling complex systems in physics, finance, and engineering, yet their numerical estimation remains a formidable challenge. Traditional methods rely on discretization, introducing computational inefficiencies, and limiting applicability in high-dimensional settings. In this work, we introduce a novel neural framework for SPDE estimation that eliminates the need for discretization, enabling direct estimation of expected values across arbitrary spatio-temporal points. We develop and compare two distinct neural architectures: Loss Enforced Conditions (LEC), which integrates physical constraints into the loss function, and Model Enforced Conditions (MEC), which embeds these constraints directly into the network structure. Through extensive experiments on the stochastic heat equation, Burgers' equation, and Kardar-Parisi-Zhang (KPZ) equation, we reveal a trade-off: While LEC achieves superior residual minimization and generalization, MEC enforces initial conditions with absolute precision and exceptionally high accuracy in boundary condition enforcement. Our findings highlight the immense potential of neural-based SPDE solvers, particularly for high-dimensional problems where conventional techniques falter. By circumventing discretization and explicitly modeling uncertainty, our approach opens new avenues for solving SPDEs in fields ranging from quantitative finance to turbulence modeling. To the best of our knowledge, this is the first neural framework capable of directly estimating the expected values of SPDEs in an entirely non-discretized manner, offering a step forward in scientific computing.

### Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set 
[[arxiv](https://arxiv.org/abs/2502.03669)] [[cool](https://papers.cool/arxiv/2502.03669)] [[pdf](https://arxiv.org/pdf/2502.03669)]
> **Authors**: Yikai Wu,Haoyu Zhao,Sanjeev Arora
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 24 pages, 7 figures, 8 tables
- **标题**: None
- **领域**: 机器学习,人工智能,离散数学,优化与控制,机器学习
- **Abstract**: AI methods, such as generative models and reinforcement learning, have recently been applied to combinatorial optimization (CO) problems, especially NP-hard ones. This paper compares such GPU-based methods with classical CPU-based methods on Maximum Independent Set (MIS). Experiments on standard graph families show that AI-based algorithms fail to outperform and, in many cases, to match the solution quality of the state-of-art classical solver KaMIS running on a single CPU. Some GPU-based methods even perform similarly to the simplest heuristic, degree-based greedy. Even with post-processing techniques like local search, AI-based methods still perform worse than CPU-based solvers. We develop a new mode of analysis to reveal that non-backtracking AI methods, e.g. LTFT (which is based on GFlowNets), end up reasoning similarly to the simplest degree-based greedy approach, and thus worse than KaMIS. We also find that CPU-based algorithms, notably KaMIS, have strong performance on sparse random graphs, which appears to refute a well-known conjectured upper bound for efficient algorithms from Coja-Oghlan & Efthymiou (2015).

### Privacy-Preserving Generative Models: A Comprehensive Survey 
[[arxiv](https://arxiv.org/abs/2502.03668)] [[cool](https://papers.cool/arxiv/2502.03668)] [[pdf](https://arxiv.org/pdf/2502.03668)]
> **Authors**: Debalina Padariya,Isabel Wagner,Aboozar Taherkhani,Eerke Boiten
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,密码学和安全
- **Abstract**: Despite the generative model's groundbreaking success, the need to study its implications for privacy and utility becomes more urgent. Although many studies have demonstrated the privacy threats brought by GANs, no existing survey has systematically categorized the privacy and utility perspectives of GANs and VAEs. In this article, we comprehensively study privacy-preserving generative models, articulating the novel taxonomies for both privacy and utility metrics by analyzing 100 research publications. Finally, we discuss the current challenges and future research directions that help new researchers gain insight into the underlying concepts.

### Advancing Weight and Channel Sparsification with Enhanced Saliency 
[[arxiv](https://arxiv.org/abs/2502.03658)] [[cool](https://papers.cool/arxiv/2502.03658)] [[pdf](https://arxiv.org/pdf/2502.03658)]
> **Authors**: Xinglong Sun,Maying Shen,Hongxu Yin,Lei Mao,Pavlo Molchanov,Jose M. Alvarez
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted at WACV 2025
- **标题**: None
- **领域**: 机器学习,计算机视觉和模式识别
- **Abstract**: Pruning aims to accelerate and compress models by removing redundant parameters, identified by specifically designed importance scores which are usually imperfect. This removal is irreversible, often leading to subpar performance in pruned models. Dynamic sparse training, while attempting to adjust sparse structures during training for continual reassessment and refinement, has several limitations including criterion inconsistency between pruning and growth, unsuitability for structured sparsity, and short-sighted growth strategies. Our paper introduces an efficient, innovative paradigm to enhance a given importance criterion for either unstructured or structured sparsity. Our method separates the model into an active structure for exploitation and an exploration space for potential updates. During exploitation, we optimize the active structure, whereas in exploration, we reevaluate and reintegrate parameters from the exploration space through a pruning and growing step consistently guided by the same given importance criterion. To prepare for exploration, we briefly "reactivate" all parameters in the exploration space and train them for a few iterations while keeping the active part frozen, offering a preview of the potential performance gains from reintegrating these parameters. We show on various datasets and configurations that existing importance criterion even simple as magnitude can be enhanced with ours to achieve state-of-the-art performance and training cost reductions. Notably, on ImageNet with ResNet50, ours achieves an +1.3 increase in Top-1 accuracy over prior art at 90% ERK sparsity. Compared with the SOTA latency pruning method HALP, we reduced its training cost by over 70% while attaining a faster and more accurate pruned model.

### Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics 
[[arxiv](https://arxiv.org/abs/2502.03654)] [[cool](https://papers.cool/arxiv/2502.03654)] [[pdf](https://arxiv.org/pdf/2502.03654)]
> **Authors**: Indrashis Das,Mahmoud Safari,Steven Adriaensen,Frank Hutter
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages, excluding references and appendix
- **标题**: None
- **领域**: 机器学习,人工智能,计算机视觉和模式识别
- **Abstract**: Activation functions are fundamental elements of deep learning architectures as they significantly influence training dynamics. ReLU, while widely used, is prone to the dying neuron problem, which has been mitigated by variants such as LeakyReLU, PReLU, and ELU that better handle negative neuron outputs. Recently, self-gated activations like GELU and Swish have emerged as state-of-the-art alternatives, leveraging their smoothness to ensure stable gradient flow and prevent neuron inactivity. In this work, we introduce the Gompertz Linear Unit (GoLU), a novel self-gated activation function defined as $\mathrm{GoLU}(x) = x \, \mathrm{Gompertz}(x)$, where $\mathrm{Gompertz}(x) = e^{-e^{-x}}$. The GoLU activation leverages the asymmetry in the Gompertz function to reduce variance in the latent space more effectively compared to GELU and Swish, while preserving robust gradient flow. Extensive experiments across diverse tasks, including Image Classification, Language Modeling, Semantic Segmentation, Object Detection, Instance Segmentation, and Diffusion, highlight GoLU's superior performance relative to state-of-the-art activation functions, establishing GoLU as a robust alternative to existing activation functions.

### The Cost of Shuffling in Private Gradient Based Optimization 
[[arxiv](https://arxiv.org/abs/2502.03652)] [[cool](https://papers.cool/arxiv/2502.03652)] [[pdf](https://arxiv.org/pdf/2502.03652)]
> **Authors**: Shuli Jiang,Pranay Sharma,Zhiwei Steven Wu,Gauri Joshi
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 54 pages, 6 figures
- **标题**: None
- **领域**: 机器学习
- **Abstract**: We consider the problem of differentially private (DP) convex empirical risk minimization (ERM). While the standard DP-SGD algorithm is theoretically well-established, practical implementations often rely on shuffled gradient methods that traverse the training data sequentially rather than sampling with replacement in each iteration. Despite their widespread use, the theoretical privacy-accuracy trade-offs of private shuffled gradient methods (\textit{DP-ShuffleG}) remain poorly understood, leading to a gap between theory and practice. In this work, we leverage privacy amplification by iteration (PABI) and a novel application of Stein's lemma to provide the first empirical excess risk bound of \textit{DP-ShuffleG}. Our result shows that data shuffling results in worse empirical excess risk for \textit{DP-ShuffleG} compared to DP-SGD. To address this limitation, we propose \textit{Interleaved-ShuffleG}, a hybrid approach that integrates public data samples in private optimization. By alternating optimization steps that use private and public samples, \textit{Interleaved-ShuffleG} effectively reduces empirical excess risk. Our analysis introduces a new optimization framework with surrogate objectives, adaptive noise injection, and a dissimilarity metric, which can be of independent interest. Our experiments on diverse datasets and tasks demonstrate the superiority of \textit{Interleaved-ShuffleG} over several baselines.

### Efficient Optimal PAC Learning 
[[arxiv](https://arxiv.org/abs/2502.03620)] [[cool](https://papers.cool/arxiv/2502.03620)] [[pdf](https://arxiv.org/pdf/2502.03620)]
> **Authors**: Mikael Møller Høgsgaard
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Recent advances in the binary classification setting by Hanneke [2016b] and Larsen [2023] have resulted in optimal PAC learners. These learners leverage, respectively, a clever deterministic subsampling scheme and the classic heuristic of bagging Breiman [1996]. Both optimal PAC learners use, as a subroutine, the natural algorithm of empirical risk minimization. Consequently, the computational cost of these optimal PAC learners is tied to that of the empirical risk minimizer algorithm. In this work, we seek to provide an alternative perspective on the computational cost imposed by the link to the empirical risk minimizer algorithm. To this end, we show the existence of an optimal PAC learner, which offers a different tradeoff in terms of the computational cost induced by the empirical risk minimizer.

### Swarm Characteristic Classification using Robust Neural Networks with Optimized Controllable Inputs 
[[arxiv](https://arxiv.org/abs/2502.03619)] [[cool](https://papers.cool/arxiv/2502.03619)] [[pdf](https://arxiv.org/pdf/2502.03619)]
> **Authors**: Donald W. Peltier III,Isaac Kaminer,Abram Clark,Marko Orescanin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Having the ability to infer characteristics of autonomous agents would profoundly revolutionize defense, security, and civil applications. Our previous work was the first to demonstrate that supervised neural network time series classification (NN TSC) could rapidly predict the tactics of swarming autonomous agents in military contexts, providing intelligence to inform counter-maneuvers. However, most autonomous interactions, especially military engagements, are fraught with uncertainty, raising questions about the practicality of using a pretrained classifier. This article addresses that challenge by leveraging expected operational variations to construct a richer dataset, resulting in a more robust NN with improved inference performance in scenarios characterized by significant uncertainties. Specifically, diverse datasets are created by simulating variations in defender numbers, defender motions, and measurement noise levels. Key findings indicate that robust NNs trained on an enriched dataset exhibit enhanced classification accuracy and offer operational flexibility, such as reducing resources required and offering adherence to trajectory constraints. Furthermore, we present a new framework for optimally deploying a trained NN by the defenders. The framework involves optimizing defender trajectories that elicit adversary responses that maximize the probability of correct NN tactic classification while also satisfying operational constraints imposed on the defenders.

### The Logical Implication Steering Method for Conditional Interventions on Transformer Generation 
[[arxiv](https://arxiv.org/abs/2502.03618)] [[cool](https://papers.cool/arxiv/2502.03618)] [[pdf](https://arxiv.org/pdf/2502.03618)]
> **Authors**: Damjan Kalajdzievski
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: The field of mechanistic interpretability in pre-trained transformer models has demonstrated substantial evidence supporting the ''linear representation hypothesis'', which is the idea that high level concepts are encoded as vectors in the space of activations of a model. Studies also show that model generation behavior can be steered toward a given concept by adding the concept's vector to the corresponding activations. We show how to leverage these properties to build a form of logical implication into models, enabling transparent and interpretable adjustments that induce a chosen generation behavior in response to the presence of any given concept. Our method, Logical Implication Model Steering (LIMS), unlocks new hand engineered reasoning capabilities by integrating neuro-symbolic logic into pre-trained transformer models.

### A Novel Zero-Touch, Zero-Trust, AI/ML Enablement Framework for IoT Network Security 
[[arxiv](https://arxiv.org/abs/2502.03614)] [[cool](https://papers.cool/arxiv/2502.03614)] [[pdf](https://arxiv.org/pdf/2502.03614)]
> **Authors**: Sushil Shakya,Robert Abbas,Sasa Maric
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,密码学和安全
- **Abstract**: The IoT facilitates a connected, intelligent, and sustainable society; therefore, it is imperative to protect the IoT ecosystem. The IoT-based 5G and 6G will leverage the use of machine learning and artificial intelligence (ML/AI) more to pave the way for autonomous and collaborative secure IoT networks. Zero-touch, zero-trust IoT security with AI and machine learning (ML) enablement frameworks offers a powerful approach to securing the expanding landscape of Internet of Things (IoT) devices. This paper presents a novel framework based on the integration of Zero Trust, Zero Touch, and AI/ML powered for the detection, mitigation, and prevention of DDoS attacks in modern IoT ecosystems. The focus will be on the new integrated framework by establishing zero trust for all IoT traffic, fixed and mobile 5G/6G IoT network traffic, and data security (quarantine-zero touch and dynamic policy enforcement). We perform a comparative analysis of five machine learning models, namely, XGBoost, Random Forest, K-Nearest Neighbors, Stochastic Gradient Descent, and Native Bayes, by comparing these models based on accuracy, precision, recall, F1-score, and ROC-AUC. Results show that the best performance in detecting and mitigating different DDoS vectors comes from the ensemble-based approaches.

### (GG) MoE vs. MLP on Tabular Data 
[[arxiv](https://arxiv.org/abs/2502.03608)] [[cool](https://papers.cool/arxiv/2502.03608)] [[pdf](https://arxiv.org/pdf/2502.03608)]
> **Authors**: Andrei Chernov
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: In recent years, significant efforts have been directed toward adapting modern neural network architectures for tabular data. However, despite their larger number of parameters and longer training and inference times, these models often fail to consistently outperform vanilla multilayer perceptron (MLP) neural networks. Moreover, MLP-based ensembles have recently demonstrated superior performance and efficiency compared to advanced deep learning methods. Therefore, rather than focusing on building deeper and more complex deep learning models, we propose investigating whether MLP neural networks can be replaced with more efficient architectures without sacrificing performance. In this paper, we first introduce GG MoE, a mixture-of-experts (MoE) model with a Gumbel-Softmax gating function. We then demonstrate that GG MoE with an embedding layer achieves the highest performance across $38$ datasets compared to standard MoE and MLP models. Finally, we show that both MoE and GG MoE utilize significantly fewer parameters than MLPs, making them a promising alternative for scaling and ensemble methods.

### Bilevel ZOFO: Bridging Parameter-Efficient and Zeroth-Order Techniques for Efficient LLM Fine-Tuning and Meta-Training 
[[arxiv](https://arxiv.org/abs/2502.03604)] [[cool](https://papers.cool/arxiv/2502.03604)] [[pdf](https://arxiv.org/pdf/2502.03604)]
> **Authors**: Reza Shirkavand,Qi He,Peiran Yu,Heng Huang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Fine-tuning pre-trained Large Language Models (LLMs) for downstream tasks using First-Order (FO) optimizers presents significant computational challenges. Parameter-Efficient Fine-Tuning(PEFT) methods have been proposed to address these challenges by freezing most model parameters and training only a small subset. While PEFT is efficient, it may not outperform full fine-tuning when high task-specific performance is required. Zeroth-Order (ZO) methods offer an alternative for fine-tuning the entire pre-trained model by approximating gradients using only the forward pass, thus eliminating the computational burden of back-propagation in first-order methods. However, when implementing ZO methods, a hard prompt is crucial, and relying on simple, fixed hard prompts may not be optimal. In this paper, we propose a bilevel optimization framework that complements ZO methods with PEFT to mitigate sensitivity to hard prompts while efficiently and effectively fine-tuning LLMs. Our Bilevel ZOFO (Zeroth-Order-First-Order) method employs a double-loop optimization strategy, where only the gradient of the PEFT model and the forward pass of the base model are required. We provide convergence guarantees for Bilevel ZOFO. Empirically, we demonstrate that Bilevel ZOFO outperforms both PEFT and ZO methods in single-task settings while maintaining similar memory efficiency. Additionally, we show its strong potential for multitask learning. Compared to current first-order meta-training algorithms for multitask learning, our method has significantly lower computational demands while maintaining or improving performance.

### Stein Discrepancy for Unsupervised Domain Adaptation 
[[arxiv](https://arxiv.org/abs/2502.03587)] [[cool](https://papers.cool/arxiv/2502.03587)] [[pdf](https://arxiv.org/pdf/2502.03587)]
> **Authors**: Anneke von Seeger,Dongmian Zou,Gilad Lerman
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 24 pages, 9 figures
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Unsupervised domain adaptation (UDA) leverages information from a labeled source dataset to improve accuracy on a related but unlabeled target dataset. A common approach to UDA is aligning representations from the source and target domains by minimizing the distance between their data distributions. Previous methods have employed distances such as Wasserstein distance and maximum mean discrepancy. However, these approaches are less effective when the target data is significantly scarcer than the source data. Stein discrepancy is an asymmetric distance between distributions that relies on one distribution only through its score function. In this paper, we propose a novel UDA method that uses Stein discrepancy to measure the distance between source and target domains. We develop a learning framework using both non-kernelized and kernelized Stein discrepancy. Theoretically, we derive an upper bound for the generalization error. Numerical experiments show that our method outperforms existing methods using other domain discrepancy measures when only small amounts of target data are available.

### Clone-Resistant Weights in Metric Spaces: A Framework for Handling Redundancy Bias 
[[arxiv](https://arxiv.org/abs/2502.03576)] [[cool](https://papers.cool/arxiv/2502.03576)] [[pdf](https://arxiv.org/pdf/2502.03576)]
> **Authors**: Damien Berriaud,Roger Wattenhofer
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: v1
- **标题**: None
- **领域**: 机器学习,计算机科学与博弈论
- **Abstract**: We are given a set of elements in a metric space. The distribution of the elements is arbitrary, possibly adversarial. Can we weigh the elements in a way that is resistant to such (adversarial) manipulations? This problem arises in various contexts. For instance, the elements could represent data points, requiring robust domain adaptation. Alternatively, they might represent tasks to be aggregated into a benchmark; or questions about personal political opinions in voting advice applications. This article introduces a theoretical framework for dealing with such problems. We propose clone-proof representation functions as a solution concept. These functions distribute importance across elements of a set such that similar objects (``clones'') share (some of) their weights, thus avoiding a potential bias introduced by their multiplicity. Our framework extends the maximum uncertainty principle to accommodate general metric spaces and includes a set of axioms - symmetry, continuity, and clone-proofness - that guide the construction of representation functions. Finally, we address the existence of representation functions satisfying our axioms in the significant case of Euclidean spaces and propose a general method for their construction.

### A Multi-Task Learning Approach to Linear Multivariate Forecasting 
[[arxiv](https://arxiv.org/abs/2502.03571)] [[cool](https://papers.cool/arxiv/2502.03571)] [[pdf](https://arxiv.org/pdf/2502.03571)]
> **Authors**: Liran Nochumsohn,Hedi Zisling,Omri Azencot
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Accurate forecasting of multivariate time series data is important in many engineering and scientific applications. Recent state-of-the-art works ignore the inter-relations between variates, using their model on each variate independently. This raises several research questions related to proper modeling of multivariate data. In this work, we propose to view multivariate forecasting as a multi-task learning problem, facilitating the analysis of forecasting by considering the angle between task gradients and their balance. To do so, we analyze linear models to characterize the behavior of tasks. Our analysis suggests that tasks can be defined by grouping similar variates together, which we achieve via a simple clustering that depends on correlation-based similarities. Moreover, to balance tasks, we scale gradients with respect to their prediction error. Then, each task is solved with a linear model within our MTLinear framework. We evaluate our approach on challenging benchmarks in comparison to strong baselines, and we show it obtains on-par or better results on multivariate forecasting problems. The implementation is available at: https://github.com/azencot-group/MTLinear

### Controllable Sequence Editing for Counterfactual Generation 
[[arxiv](https://arxiv.org/abs/2502.03569)] [[cool](https://papers.cool/arxiv/2502.03569)] [[pdf](https://arxiv.org/pdf/2502.03569)]
> **Authors**: Michelle M. Li,Kevin Li,Yasha Ektefaie,Shvat Messica,Marinka Zitnik
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,基因组学,种群与进化
- **Abstract**: Sequence models generate counterfactuals by modifying parts of a sequence based on a given condition, enabling reasoning about "what if" scenarios. While these models excel at conditional generation, they lack fine-grained control over when and where edits occur. Existing approaches either focus on univariate sequences or assume that interventions affect the entire sequence globally. However, many applications require precise, localized modifications, where interventions take effect only after a specified time and impact only a subset of co-occurring variables. We introduce CLEF, a controllable sequence editing model for counterfactual reasoning about both immediate and delayed effects. CLEF learns temporal concepts that encode how and when interventions should influence a sequence. With these concepts, CLEF selectively edits relevant time steps while preserving unaffected portions of the sequence. We evaluate CLEF on cellular and patient trajectory datasets, where gene regulation affects only certain genes at specific time steps, or medical interventions alter only a subset of lab measurements. CLEF improves immediate sequence editing by up to 36.01% in MAE compared to baselines. Unlike prior methods, CLEF enables one-step generation of counterfactual sequences at any future time step, outperforming baselines by up to 65.71% in MAE. A case study on patients with type 1 diabetes mellitus shows that CLEF identifies clinical interventions that shift patient trajectories toward healthier outcomes.

### Code Simulation as a Proxy for High-order Tasks in Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.03568)] [[cool](https://papers.cool/arxiv/2502.03568)] [[pdf](https://arxiv.org/pdf/2502.03568)]
> **Authors**: Emanuele La Malfa,Christoph Weinhuber,Orazio Torre,Fangru Lin,X. Angelo Huang,Samuele Marro,Anthony Cohn,Nigel Shadbolt,Michael Wooldridge
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: arXiv admin note: substantial text overlap with arXiv:2401.09074 Authors note: this article is a substantial revision of arXiv:2401.09074 (same team)
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Many reasoning, planning, and problem-solving tasks share an intrinsic algorithmic nature: correctly simulating each step is a sufficient condition to solve them correctly. We collect pairs of naturalistic and synthetic reasoning tasks to assess the capabilities of Large Language Models (LLM). While naturalistic tasks often require careful human handcrafting, we show that synthetic data is, in many cases, a good proxy that is much easier to collect at scale. We leverage common constructs in programming as the counterpart of the building blocks of naturalistic reasoning tasks, such as straight-line programs, code that contains critical paths, and approximate and redundant instructions. We further assess the capabilities of LLMs on sorting problems and repeated operations via sorting algorithms and nested loops. Our synthetic datasets further reveal that while the most powerful LLMs exhibit relatively strong execution capabilities, the process is fragile: it is negatively affected by memorisation and seems to rely heavily on pattern recognition. Our contribution builds upon synthetically testing the reasoning capabilities of LLMs as a scalable complement to handcrafted human-annotated problems.

### TD-M(PC)$^2$: Improving Temporal Difference MPC Through Policy Constraint 
[[arxiv](https://arxiv.org/abs/2502.03550)] [[cool](https://papers.cool/arxiv/2502.03550)] [[pdf](https://arxiv.org/pdf/2502.03550)]
> **Authors**: Haotian Lin,Pengcheng Wang,Jeff Schneider,Guanya Shi
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器人技术
- **Abstract**: Model-based reinforcement learning algorithms that combine model-based planning and learned value/policy prior have gained significant recognition for their high data efficiency and superior performance in continuous control. However, we discover that existing methods that rely on standard SAC-style policy iteration for value learning, directly using data generated by the planner, often result in \emph{persistent value overestimation}. Through theoretical analysis and experiments, we argue that this issue is deeply rooted in the structural policy mismatch between the data generation policy that is always bootstrapped by the planner and the learned policy prior. To mitigate such a mismatch in a minimalist way, we propose a policy regularization term reducing out-of-distribution (OOD) queries, thereby improving value learning. Our method involves minimum changes on top of existing frameworks and requires no additional computation. Extensive experiments demonstrate that the proposed approach improves performance over baselines such as TD-MPC2 by large margins, particularly in 61-DoF humanoid tasks. View qualitative results at https://darthutopian.github.io/tdmpc_square/.

### Path Planning for Masked Diffusion Model Sampling 
[[arxiv](https://arxiv.org/abs/2502.03540)] [[cool](https://papers.cool/arxiv/2502.03540)] [[pdf](https://arxiv.org/pdf/2502.03540)]
> **Authors**: Fred Zhangzhi Peng,Zachary Bezemek,Sawan Patel,Jarrid Rector-Brooks,Sherwood Yao,Alexander Tong,Pranam Chatterjee
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: In this paper, we explore how token unmasking order influences generative quality in masked diffusion models (MDMs). We derive an expanded evidence lower bound (ELBO) that introduces a planner to select which tokens to unmask at each step. Our analysis reveals that alternative unmasking strategies can enhance generation performance. Building on this, we propose Path Planning (P2), a sampling framework that uses a pre-trained BERT model or the denoiser itself to guide unmasking decisions. P2 generalizes all known MDM sampling strategies and significantly improves performance across diverse domains, including language generation (in-context learning, code generation, story infilling, mathematical reasoning, reverse curse correction) and biological sequence generation (protein and RNA sequences).

### Teaching Language Models to Critique via Reinforcement Learning 
[[arxiv](https://arxiv.org/abs/2502.03492)] [[cool](https://papers.cool/arxiv/2502.03492)] [[pdf](https://arxiv.org/pdf/2502.03492)]
> **Authors**: Zhihui Xie,Jie chen,Liyu Chen,Weichao Mao,Jingjing Xu,Lingpeng Kong
> **First submission**: 2025-02-04
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,计算语言学
- **Abstract**: Teaching large language models (LLMs) to critique and refine their outputs is crucial for building systems that can iteratively improve, yet it is fundamentally limited by the ability to provide accurate judgments and actionable suggestions. In this work, we study LLM critics for code generation and propose $\texttt{CTRL}$, a framework for $\texttt{C}$ritic $\texttt{T}$raining via $\texttt{R}$einforcement $\texttt{L}$earning, which trains a critic model to generate feedback that maximizes correction performance for a fixed generator model without human supervision. Our results demonstrate that critics trained with $\texttt{CTRL}$ significantly enhance pass rates and mitigate compounding errors across both base and stronger generator models. Furthermore, we show that these critic models act as accurate generative reward models and enable test-time scaling through iterative critique-revision, achieving up to 106.1% relative improvements across challenging code generation benchmarks.

### Do Large Language Model Benchmarks Test Reliability? 
[[arxiv](https://arxiv.org/abs/2502.03461)] [[cool](https://papers.cool/arxiv/2502.03461)] [[pdf](https://arxiv.org/pdf/2502.03461)]
> **Authors**: Joshua Vendrow,Edward Vendrow,Sara Beery,Aleksander Madry
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,计算语言学
- **Abstract**: When deploying large language models (LLMs), it is important to ensure that these models are not only capable, but also reliable. Many benchmarks have been created to track LLMs' growing capabilities, however there has been no similar focus on measuring their reliability. To understand the potential ramifications of this gap, we investigate how well current benchmarks quantify model reliability. We find that pervasive label errors can compromise these evaluations, obscuring lingering model failures and hiding unreliable behavior. Motivated by this gap in the evaluation of reliability, we then propose the concept of so-called platinum benchmarks, i.e., benchmarks carefully curated to minimize label errors and ambiguity. As a first attempt at constructing such benchmarks, we revise examples from fifteen existing popular benchmarks. We evaluate a wide range of models on these platinum benchmarks and find that, indeed, frontier LLMs still exhibit failures on simple tasks such as elementary-level math word problems. Analyzing these failures further reveals previously unidentified patterns of problems on which frontier models consistently struggle. We provide code at https://github.com/MadryLab/platinum-benchmarks

### Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training 
[[arxiv](https://arxiv.org/abs/2502.03460)] [[cool](https://papers.cool/arxiv/2502.03460)] [[pdf](https://arxiv.org/pdf/2502.03460)]
> **Authors**: Boyao Wang,Rui Pan,Shizhe Diao,Xingyuan Pan,Jipeng Zhang,Renjie Pi,Tong Zhang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,计算语言学
- **Abstract**: Small language models (SLMs) have attracted considerable attention from both academia and industry due to their broad range of applications in edge devices. To obtain SLMs with strong performance, conventional approaches either pre-train the models from scratch, which incurs substantial computational costs, or compress/prune existing large language models (LLMs), which results in performance drops and falls short in comparison to pre-training. In this paper, we investigate the family of acceleration methods that involve both structured pruning and model training. We found 1) layer-wise adaptive pruning (Adapt-Pruner) is extremely effective in LLMs and yields significant improvements over existing pruning techniques, 2) adaptive pruning equipped with further training leads to models comparable to those pre-training from scratch, 3) incremental pruning brings non-trivial performance gain by interleaving pruning with training and only removing a small portion of neurons ($\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate that Adapt-Pruner outperforms conventional pruning methods, such as LLM-Pruner, FLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsense benchmarks. Additionally, Adapt-Pruner restores the performance of MobileLLM-125M to 600M on the MMLU benchmark with 200$\times$ fewer tokens via pruning from its larger counterparts, and discovers a new 1B model that surpasses LLaMA-3.2-1B in multiple benchmarks.

### A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs) 
[[arxiv](https://arxiv.org/abs/2502.03450)] [[cool](https://papers.cool/arxiv/2502.03450)] [[pdf](https://arxiv.org/pdf/2502.03450)]
> **Authors**: Yiye Chen,Harpreet Sawhney,Nicholas Gydé,Yanan Jian,Jack Saunders,Patricio Vela,Ben Lundell
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,多代理系统,机器人技术
- **Abstract**: Scene graphs have emerged as a structured and serializable environment representation for grounded spatial reasoning with Large Language Models (LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason framework for reasoning and planning with scene graphs. Our approach employs two cooperative, code-writing LLM agents: a (1) Reasoner for task planning and information queries generation, and a (2) Retriever for extracting corresponding graph information following the queries. Two agents collaborate iteratively, enabling sequential reasoning and adaptive attention to graph information. Unlike prior works, both agents are prompted only with the scene graph schema rather than the full graph data, which reduces the hallucination by limiting input tokens, and drives the Reasoner to generate reasoning trace abstractly.Following the trace, the Retriever programmatically query the scene graph data based on the schema understanding, allowing dynamic and global attention on the graph that enhances alignment between reasoning and retrieval. Through experiments in multiple simulation environments, we show that our framework surpasses existing LLM-based approaches in numerical Q\&A and planning tasks, and can benefit from task-level few-shot examples, even in the absence of agent-level demonstrations. Project code will be released.

### Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators 
[[arxiv](https://arxiv.org/abs/2502.03424)] [[cool](https://papers.cool/arxiv/2502.03424)] [[pdf](https://arxiv.org/pdf/2502.03424)]
> **Authors**: Yuan Xinjie,Khalid M. Mosalam
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This paper is currently under review at Computer-Aided Civil and Infrastructure Engineering
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Fire safety is a critical area of research in civil and mechanical engineering, particularly in ensuring the structural stability of buildings during fire events. The Most Fire-Sensitive Point (MFSP) in a structure is the location where a fire would cause the greatest impact on structural stability. Accurate prediction of the MFSP is vital for streamlining structural assessments and optimizing the design process. This paper presents a novel framework for MFSP prediction using a neural network-based approach that integrates fire dynamics and finite element analysis through a differentiable agent model. The framework focuses on predicting the Maximum Interstory Drift Ratio (MIDR), a key indicator of structural performance under fire conditions. By leveraging the differentiable agent model, we efficiently generate labeled data for MFSP and directly train a predictor for this critical metric. To achieve this, we generated extensive simulation data encompassing structural and fire scenarios and employed graph neural networks to represent the building structures. Transfer learning was applied to optimize the training process, and an edge update mechanism was introduced to dynamically adjust edge attributes, reflecting property changes under fire conditions. The proposed model was rigorously evaluated on simulation data, demonstrating strong performance in accurately predicting both MIDR and MFSP, thus advancing fire safety analysis for building structures.

### From Features to Transformers: Redefining Ranking for Scalable Impact 
[[arxiv](https://arxiv.org/abs/2502.03417)] [[cool](https://papers.cool/arxiv/2502.03417)] [[pdf](https://arxiv.org/pdf/2502.03417)]
> **Authors**: Fedor Borisyuk,Lars Hertel,Ganesh Parameswaran,Gaurav Srivastava,Sudarshan Srinivasa Ramanujam,Borja Ocejo,Peng Du,Andrei Akterskii,Neil Daftary,Shao Tang,Daqi Sun,Qiang Charles Xiao,Deepesh Nathani,Mohit Kothari,Yun Dai,Aman Gupta
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: We present LiGR, a large-scale ranking framework developed at LinkedIn that brings state-of-the-art transformer-based modeling architectures into production. We introduce a modified transformer architecture that incorporates learned normalization and simultaneous set-wise attention to user history and ranked items. This architecture enables several breakthrough achievements, including: (1) the deprecation of most manually designed feature engineering, outperforming the prior state-of-the-art system using only few features (compared to hundreds in the baseline), (2) validation of the scaling law for ranking systems, showing improved performance with larger models, more training data, and longer context sequences, and (3) simultaneous joint scoring of items in a set-wise manner, leading to automated improvements in diversity. To enable efficient serving of large ranking models, we describe techniques to scale inference effectively using single-pass processing of user history and set-wise attention. We also summarize key insights from various ablation studies and A/B tests, highlighting the most impactful technical approaches.

### Detecting Strategic Deception Using Linear Probes 
[[arxiv](https://arxiv.org/abs/2502.03407)] [[cool](https://papers.cool/arxiv/2502.03407)] [[pdf](https://arxiv.org/pdf/2502.03407)]
> **Authors**: Nicholas Goldowsky-Dill,Bilal Chughtai,Stefan Heimersheim,Marius Hobbhahn
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Website: http://data.apolloresearch.ai/dd/ Code: http://www.github.com/ApolloResearch/deception-detection/
- **标题**: None
- **领域**: 机器学习
- **Abstract**: AI models might use deceptive strategies as part of scheming or misaligned behaviour. Monitoring outputs alone is insufficient, since the AI might produce seemingly benign outputs while their internal reasoning is misaligned. We thus evaluate if linear probes can robustly detect deception by monitoring model activations. We test two probe-training datasets, one with contrasting instructions to be honest or deceptive (following Zou et al., 2023) and one of responses to simple roleplaying scenarios. We test whether these probes generalize to realistic settings where Llama-3.3-70B-Instruct behaves deceptively, such as concealing insider trading (Scheurer et al., 2023) and purposely underperforming on safety evaluations (Benton et al., 2024). We find that our probe distinguishes honest and deceptive responses with AUROCs between 0.96 and 0.999 on our evaluation datasets. If we set the decision threshold to have a 1% false positive rate on chat data not related to deception, our probe catches 95-99% of the deceptive responses. Overall we think white-box probes are promising for future monitoring systems, but current performance is insufficient as a robust defence against deception. Our probes' outputs can be viewed at data.apolloresearch.ai/dd and our code at github.com/ApolloResearch/deception-detection.

### Deep Clustering via Probabilistic Ratio-Cut Optimization 
[[arxiv](https://arxiv.org/abs/2502.03405)] [[cool](https://papers.cool/arxiv/2502.03405)] [[pdf](https://arxiv.org/pdf/2502.03405)]
> **Authors**: Ayoub Ghriss,Claire Monteleoni
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Proceedings of the 28th International Conference on Artificial Intelligence and Statistics (AISTATS) 2025, Mai Khao, Thailand. PMLR: Volume 258
- **标题**: None
- **领域**: 机器学习,计算机视觉和模式识别
- **Abstract**: We propose a novel approach for optimizing the graph ratio-cut by modeling the binary assignments as random variables. We provide an upper bound on the expected ratio-cut, as well as an unbiased estimate of its gradient, to learn the parameters of the assignment variables in an online setting. The clustering resulting from our probabilistic approach (PRCut) outperforms the Rayleigh quotient relaxation of the combinatorial problem, its online learning extensions, and several widely used methods. We demonstrate that the PRCut clustering closely aligns with the similarity measure and can perform as well as a supervised classifier when label-based similarities are provided. This novel approach can leverage out-of-the-box self-supervised representations to achieve competitive performance and serve as an evaluation method for the quality of these representations.

### Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin 
[[arxiv](https://arxiv.org/abs/2502.03396)] [[cool](https://papers.cool/arxiv/2502.03396)] [[pdf](https://arxiv.org/pdf/2502.03396)]
> **Authors**: Sarah Al-Shareeda,Yasar Celik,Bilge Bilgili,Ahmed Al-Dubai,Berk Canberk
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages, 8 figures, 5th IEEE Middle East & North Africa COMMunications Conference (MENACOMM'25), Lebanon Feb 20-23, 2025
- **标题**: None
- **领域**: 机器学习,人工智能,新兴技术
- **Abstract**: Creating a Digital Twin (DT) for Healthcare Intelligent Transportation Systems (HITS) is a hot research trend focusing on enhancing HITS management, particularly in emergencies where ambulance vehicles must arrive at the crash scene on time and track their real-time location is crucial to the medical authorities. Despite the claim of real-time representation, a temporal misalignment persists between the physical and virtual domains, leading to discrepancies in the ambulance's location representation. This study proposes integrating AI predictive models, specifically Support Vector Regression (SVR) and Deep Neural Networks (DNN), within a constructed mock DT data pipeline framework to anticipate the medical vehicle's next location in the virtual world. These models align virtual representations with their physical counterparts, i.e., metaphorically offsetting the synchronization delay between the two worlds. Trained meticulously on a historical geospatial dataset, SVR and DNN exhibit exceptional prediction accuracy in MATLAB and Python environments. Through various testing scenarios, we visually demonstrate the efficacy of our methodology, showcasing SVR and DNN's key role in significantly reducing the witnessed gap within the HITS's DT. This transformative approach enhances real-time synchronization in emergency HITS by approximately 88% to 93%.

### Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications 
[[arxiv](https://arxiv.org/abs/2502.03395)] [[cool](https://papers.cool/arxiv/2502.03395)] [[pdf](https://arxiv.org/pdf/2502.03395)]
> **Authors**: Issar Arab,Rodrigo Benitez
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Time series forecasting is essential for operational intelligence in the hospitality industry, and particularly challenging in large-scale, distributed systems. This study evaluates the performance of statistical, machine learning (ML), deep learning, and foundation models in forecasting hourly sales over a 14-day horizon using real-world data from a network of thousands of restaurants across Germany. The forecasting solution includes features such as weather conditions, calendar events, and time-of-day patterns. Results demonstrate the strong performance of ML-based meta-models and highlight the emerging potential of foundation models like Chronos and TimesFM, which deliver competitive performance with minimal feature engineering, leveraging only the pre-trained model (zero-shot inference). Additionally, a hybrid PySpark-Pandas approach proves to be a robust solution for achieving horizontal scalability in large-scale deployments.

### CAPE: Covariate-Adjusted Pre-Training for Epidemic Time Series Forecasting 
[[arxiv](https://arxiv.org/abs/2502.03393)] [[cool](https://papers.cool/arxiv/2502.03393)] [[pdf](https://arxiv.org/pdf/2502.03393)]
> **Authors**: Zewen Liu,Juntong Ni,Max S. Y. Lau,Wei Jin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Accurate forecasting of epidemic infection trajectories is crucial for safeguarding public health. However, limited data availability during emerging outbreaks and the complex interaction between environmental factors and disease dynamics present significant challenges for effective forecasting. In response, we introduce CAPE, a novel epidemic pre-training framework designed to harness extensive disease datasets from diverse regions and integrate environmental factors directly into the modeling process for more informed decision-making on downstream diseases. Based on a covariate adjustment framework, CAPE utilizes pre-training combined with hierarchical environment contrasting to identify universal patterns across diseases while estimating latent environmental influences. We have compiled a diverse collection of epidemic time series datasets and validated the effectiveness of CAPE under various evaluation scenarios, including full-shot, few-shot, zero-shot, cross-location, and cross-disease settings, where it outperforms the leading baseline by an average of 9.9% in full-shot and 14.3% in zero-shot settings. The code will be released upon acceptance.

### Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise Sufficient Reasons 
[[arxiv](https://arxiv.org/abs/2502.03391)] [[cool](https://papers.cool/arxiv/2502.03391)] [[pdf](https://arxiv.org/pdf/2502.03391)]
> **Authors**: Shahaf Bassan,Ron Eliav,Shlomit Gur
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: To appear in ICLR 2025
- **标题**: None
- **领域**: 机器学习,计算机科学中的逻辑
- **Abstract**: *Minimal sufficient reasons* represent a prevalent form of explanation - the smallest subset of input features which, when held constant at their corresponding values, ensure that the prediction remains unchanged. Previous *post-hoc* methods attempt to obtain such explanations but face two main limitations: (1) Obtaining these subsets poses a computational challenge, leading most scalable methods to converge towards suboptimal, less meaningful subsets; (2) These methods heavily rely on sampling out-of-distribution input assignments, potentially resulting in counterintuitive behaviors. To tackle these limitations, we propose in this work a self-supervised training approach, which we term *sufficient subset training* (SST). Using SST, we train models to generate concise sufficient reasons for their predictions as an integral part of their output. Our results indicate that our framework produces succinct and faithful subsets substantially more efficiently than competing post-hoc methods, while maintaining comparable predictive performance.

### A Structured Reasoning Framework for Unbalanced Data Classification Using Probabilistic Models 
[[arxiv](https://arxiv.org/abs/2502.03386)] [[cool](https://papers.cool/arxiv/2502.03386)] [[pdf](https://arxiv.org/pdf/2502.03386)]
> **Authors**: Junliang Du,Shiyu Dou,Bohuan Yang,Jiacheng Hu,Tai An
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: This paper studies a Markov network model for unbalanced data, aiming to solve the problems of classification bias and insufficient minority class recognition ability of traditional machine learning models in environments with uneven class distribution. By constructing joint probability distribution and conditional dependency, the model can achieve global modeling and reasoning optimization of sample categories. The study introduced marginal probability estimation and weighted loss optimization strategies, combined with regularization constraints and structured reasoning methods, effectively improving the generalization ability and robustness of the model. In the experimental stage, a real credit card fraud detection dataset was selected and compared with models such as logistic regression, support vector machine, random forest and XGBoost. The experimental results show that the Markov network performs well in indicators such as weighted accuracy, F1 score, and AUC-ROC, significantly outperforming traditional classification models, demonstrating its strong decision-making ability and applicability in unbalanced data scenarios. Future research can focus on efficient model training, structural optimization, and deep learning integration in large-scale unbalanced data environments and promote its wide application in practical applications such as financial risk control, medical diagnosis, and intelligent monitoring.

### Transformers and Their Roles as Time Series Foundation Models 
[[arxiv](https://arxiv.org/abs/2502.03383)] [[cool](https://papers.cool/arxiv/2502.03383)] [[pdf](https://arxiv.org/pdf/2502.03383)]
> **Authors**: Dennis Wu,Yihan He,Yuan Cao,Jianqing Fan,Han Liu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 34 Pages, 2 Figures
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: We give a comprehensive analysis of transformers as time series foundation models, focusing on their approximation and generalization capabilities. First, we demonstrate that there exist transformers that fit an autoregressive model on input univariate time series via gradient descent. We then analyze MOIRAI, a multivariate time series foundation model capable of handling an arbitrary number of covariates. We prove that it is capable of automatically fitting autoregressive models with an arbitrary number of covariates, offering insights into its design and empirical success. For generalization, we establish bounds for pretraining when the data satisfies Dobrushin's condition. Experiments support our theoretical findings, highlighting the efficacy of transformers as time series foundation models.

### SyMANTIC: An Efficient Symbolic Regression Method for Interpretable and Parsimonious Model Discovery in Science and Beyond 
[[arxiv](https://arxiv.org/abs/2502.03367)] [[cool](https://papers.cool/arxiv/2502.03367)] [[pdf](https://arxiv.org/pdf/2502.03367)]
> **Authors**: Madhav R. Muthyala,Farshud Sorourifar,You Peng,Joel A. Paulson
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Main and SI compiled into the pdf Main:48 pages, 7 figures SI: 29 pages, 2 figures
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Symbolic regression (SR) is an emerging branch of machine learning focused on discovering simple and interpretable mathematical expressions from data. Although a wide-variety of SR methods have been developed, they often face challenges such as high computational cost, poor scalability with respect to the number of input dimensions, fragility to noise, and an inability to balance accuracy and complexity. This work introduces SyMANTIC, a novel SR algorithm that addresses these challenges. SyMANTIC efficiently identifies (potentially several) low-dimensional descriptors from a large set of candidates (from $\sim 10^5$ to $\sim 10^{10}$ or more) through a unique combination of mutual information-based feature selection, adaptive feature expansion, and recursively applied $\ell_0$-based sparse regression. In addition, it employs an information-theoretic measure to produce an approximate set of Pareto-optimal equations, each offering the best-found accuracy for a given complexity. Furthermore, our open-source implementation of SyMANTIC, built on the PyTorch ecosystem, facilitates easy installation and GPU acceleration. We demonstrate the effectiveness of SyMANTIC across a range of problems, including synthetic examples, scientific benchmarks, real-world material property predictions, and chaotic dynamical system identification from small datasets. Extensive comparisons show that SyMANTIC uncovers similar or more accurate models at a fraction of the cost of existing SR methods.

### Rethinking Approximate Gaussian Inference in Classification 
[[arxiv](https://arxiv.org/abs/2502.03366)] [[cool](https://papers.cool/arxiv/2502.03366)] [[pdf](https://arxiv.org/pdf/2502.03366)]
> **Authors**: Bálint Mucsányi,Nathaël Da Costa,Philipp Hennig
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 29 pages, 15 figures
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: In classification tasks, softmax functions are ubiquitously used as output activations to produce predictive probabilities. Such outputs only capture aleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian inference methods have been proposed, which output Gaussian distributions over the logit space. Predictives are then obtained as the expectations of the Gaussian distributions pushed forward through the softmax. However, such softmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC) approximations can be costly and noisy. We propose a simple change in the learning objective which allows the exact computation of predictives and enjoys improved training dynamics, with no runtime or memory overhead. This framework is compatible with a family of output activation functions that includes the softmax, as well as element-wise normCDF and sigmoid. Moreover, it allows for approximating the Gaussian pushforwards with Dirichlet distributions by analytic moment matching. We evaluate our approach combined with several approximate Gaussian inference methods (Laplace, HET, SNGP) on large- and small-scale datasets (ImageNet, CIFAR-10), demonstrating improved uncertainty quantification capabilities compared to softmax MC sampling. Code is available at https://github.com/bmucsanyi/probit.

### Scaling laws in wearable human activity recognition 
[[arxiv](https://arxiv.org/abs/2502.03364)] [[cool](https://papers.cool/arxiv/2502.03364)] [[pdf](https://arxiv.org/pdf/2502.03364)]
> **Authors**: Tom Hoddes,Alex Bijamov,Saket Joshi,Daniel Roggen,Ali Etemad,Robert Harle,David Racz
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Many deep architectures and self-supervised pre-training techniques have been proposed for human activity recognition (HAR) from wearable multimodal sensors. Scaling laws have the potential to help move towards more principled design by linking model capacity with pre-training data volume. Yet, scaling laws have not been established for HAR to the same extent as in language and vision. By conducting an exhaustive grid search on both amount of pre-training data and Transformer architectures, we establish the first known scaling laws for HAR. We show that pre-training loss scales with a power law relationship to amount of data and parameter count and that increasing the number of users in a dataset results in a steeper improvement in performance than increasing data per user, indicating that diversity of pre-training data is important, which contrasts to some previously reported findings in self-supervised HAR. We show that these scaling laws translate to downstream performance improvements on three HAR benchmark datasets of postures, modes of locomotion and activities of daily living: UCI HAR and WISDM Phone and WISDM Watch. Finally, we suggest some previously published works should be revisited in light of these scaling laws with more adequate model capacities.

### Robust Autonomy Emerges from Self-Play 
[[arxiv](https://arxiv.org/abs/2502.03349)] [[cool](https://papers.cool/arxiv/2502.03349)] [[pdf](https://arxiv.org/pdf/2502.03349)]
> **Authors**: Marco Cusumano-Towner,David Hafner,Alex Hertzberg,Brody Huval,Aleksei Petrenko,Eugene Vinitsky,Erik Wijmans,Taylor Killian,Stuart Bowers,Ozan Sener,Philipp Krähenbühl,Vladlen Koltun
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,机器人技术
- **Abstract**: Self-play has powered breakthroughs in two-player and multi-player games. Here we show that self-play is a surprisingly effective strategy in another domain. We show that robust and naturalistic driving emerges entirely from self-play in simulation at unprecedented scale -- 1.6~billion~km of driving. This is enabled by Gigaflow, a batched simulator that can synthesize and train on 42 years of subjective driving experience per hour on a single 8-GPU node. The resulting policy achieves state-of-the-art performance on three independent autonomous driving benchmarks. The policy outperforms the prior state of the art when tested on recorded real-world scenarios, amidst human drivers, without ever seeing human data during training. The policy is realistic when assessed against human references and achieves unprecedented robustness, averaging 17.5 years of continuous driving between incidents in simulation.

### Interaction-Aware Gaussian Weighting for Clustered Federated Learning 
[[arxiv](https://arxiv.org/abs/2502.03340)] [[cool](https://papers.cool/arxiv/2502.03340)] [[pdf](https://arxiv.org/pdf/2502.03340)]
> **Authors**: Alessandro Licciardi,Davide Leo,Eros Faní,Barbara Caputo,Marco Ciccone
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Federated Learning (FL) emerged as a decentralized paradigm to train models while preserving privacy. However, conventional FL struggles with data heterogeneity and class imbalance, which degrade model performance. Clustered FL balances personalization and decentralized training by grouping clients with analogous data distributions, enabling improved accuracy while adhering to privacy constraints. This approach effectively mitigates the adverse impact of heterogeneity in FL. In this work, we propose a novel clustered FL method, FedGWC (Federated Gaussian Weighting Clustering), which groups clients based on their data distribution, allowing training of a more robust and personalized model on the identified clusters. FedGWC identifies homogeneous clusters by transforming individual empirical losses to model client interactions with a Gaussian reward mechanism. Additionally, we introduce the Wasserstein Adjusted Score, a new clustering metric for FL to evaluate cluster cohesion with respect to the individual class distribution. Our experiments on benchmark datasets show that FedGWC outperforms existing FL algorithms in cluster quality and classification accuracy, validating the efficacy of our approach.

### Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning 
[[arxiv](https://arxiv.org/abs/2502.03304)] [[cool](https://papers.cool/arxiv/2502.03304)] [[pdf](https://arxiv.org/pdf/2502.03304)]
> **Authors**: Qitao Tan,Jun Liu,Zheng Zhan,Caiwei Ding,Yanzhi Wang,Jin Lu,Geng Yuan
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,计算语言学
- **Abstract**: Large language models (LLMs) excel across various tasks, but standard first-order (FO) fine-tuning demands considerable memory, significantly limiting real-world deployment. Recently, zeroth-order (ZO) optimization stood out as a promising memory-efficient training paradigm, avoiding backward passes and relying solely on forward passes for gradient estimation, making it attractive for resource-constrained scenarios. However, ZO method lags far behind FO method in both convergence speed and accuracy. To bridge the gap, we introduce a novel layer-wise divergence analysis that uncovers the distinct update pattern of FO and ZO optimization. Aiming to resemble the learning capacity of FO method from the findings, we propose \textbf{Di}vergence-driven \textbf{Z}eroth-\textbf{O}rder (\textbf{DiZO}) optimization. DiZO conducts divergence-driven layer adaptation by incorporating projections to ZO updates, generating diverse-magnitude updates precisely scaled to layer-wise individual optimization needs. Our results demonstrate that DiZO significantly reduces the needed iterations for convergence without sacrificing throughput, cutting training GPU hours by up to 48\% on various datasets. Moreover, DiZO consistently outperforms the representative ZO baselines in fine-tuning RoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some cases, even surpasses memory-intensive FO fine-tuning.

### MAP Image Recovery with Guarantees using Locally Convex Multi-Scale Energy (LC-MUSE) Model 
[[arxiv](https://arxiv.org/abs/2502.03302)] [[cool](https://papers.cool/arxiv/2502.03302)] [[pdf](https://arxiv.org/pdf/2502.03302)]
> **Authors**: Jyothi Rikhab Chand,Mathews Jacob
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,计算机视觉和模式识别,图像和视频处理
- **Abstract**: We propose a multi-scale deep energy model that is strongly convex in the local neighbourhood around the data manifold to represent its probability density, with application in inverse problems. In particular, we represent the negative log-prior as a multi-scale energy model parameterized by a Convolutional Neural Network (CNN). We restrict the gradient of the CNN to be locally monotone, which constrains the model as a Locally Convex Multi-Scale Energy (LC-MuSE). We use the learned energy model in image-based inverse problems, where the formulation offers several desirable properties: i) uniqueness of the solution, ii) convergence guarantees to a minimum of the inverse problem, and iii) robustness to input perturbations. In the context of parallel Magnetic Resonance (MR) image reconstruction, we show that the proposed method performs better than the state-of-the-art convex regularizers, while the performance is comparable to plug-and-play regularizers and end-to-end trained methods.

### General Time-series Model for Universal Knowledge Representation of Multivariate Time-Series data 
[[arxiv](https://arxiv.org/abs/2502.03264)] [[cool](https://papers.cool/arxiv/2502.03264)] [[pdf](https://arxiv.org/pdf/2502.03264)]
> **Authors**: Cheng He,Xu Huang,Gangwei Jiang,Zhaoyi Li,Defu Lian,Hong Xie,Enhong Chen,Xijie Liang,Zengrong Zheng
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Universal knowledge representation is a central problem for multivariate time series(MTS) foundation models and yet remains open. This paper investigates this problem from the first principle and it makes four folds of contributions. First, a new empirical finding is revealed: time series with different time granularities (or corresponding frequency resolutions) exhibit distinct joint distributions in the frequency domain. This implies a crucial aspect of learning universal knowledge, one that has been overlooked by previous studies. Second, a novel Fourier knowledge attention mechanism is proposed to enable learning time granularity-aware representations from both the temporal and frequency domains. Third, an autoregressive blank infilling pre-training framework is incorporated to time series analysis for the first time, leading to a generative tasks agnostic pre-training strategy. To this end, we develop the General Time-series Model (GTM), a unified MTS foundation model that addresses the limitation of contemporary time series models, which often require token, pre-training, or model-level customizations for downstream tasks adaption. Fourth, extensive experiments show that GTM outperforms state-of-the-art (SOTA) methods across all generative tasks, including long-term forecasting, anomaly detection, and imputation.

### RiemannGFM: Learning a Graph Foundation Model from Riemannian Geometry 
[[arxiv](https://arxiv.org/abs/2502.03251)] [[cool](https://papers.cool/arxiv/2502.03251)] [[pdf](https://arxiv.org/pdf/2502.03251)]
> **Authors**: Li Sun,Zhenhao Huang,Suyang Zhou,Qiqi Wan,Hao Peng,Philip Yu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by WWW25
- **标题**: None
- **领域**: 机器学习
- **Abstract**: The foundation model has heralded a new era in artificial intelligence, pretraining a single model to offer cross-domain transferability on different datasets. Graph neural networks excel at learning graph data, the omnipresent non-Euclidean structure, but often lack the generalization capacity. Hence, graph foundation model is drawing increasing attention, and recent efforts have been made to leverage Large Language Models. On the one hand, existing studies primarily focus on text-attributed graphs, while a wider range of real graphs do not contain fruitful textual attributes. On the other hand, the sequential graph description tailored for the Large Language Model neglects the structural complexity, which is a predominant characteristic of the graph. Such limitations motivate an important question: Can we go beyond Large Language Models, and pretrain a universal model to learn the structural knowledge for any graph? The answer in the language or vision domain is a shared vocabulary. We observe the fact that there also exist shared substructures underlying graph domain, and thereby open a new opportunity of graph foundation model with structural vocabulary. The key innovation is the discovery of a simple yet effective structural vocabulary of trees and cycles, and we explore its inherent connection to Riemannian geometry. Herein, we present a universal pretraining model, RiemannGFM. Concretely, we first construct a novel product bundle to incorporate the diverse geometries of the vocabulary. Then, on this constructed space, we stack Riemannian layers where the structural vocabulary, regardless of specific graph, is learned in Riemannian manifold offering cross-domain transferability. Extensive experiments show the effectiveness of RiemannGFM on a diversity of real graphs.

### Calibrated Unsupervised Anomaly Detection in Multivariate Time-series using Reinforcement Learning 
[[arxiv](https://arxiv.org/abs/2502.03245)] [[cool](https://papers.cool/arxiv/2502.03245)] [[pdf](https://arxiv.org/pdf/2502.03245)]
> **Authors**: Saba Sanami,Amir G. Aghdam
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This paper has been accepted for publication and presentation at the 2025 IEEE International systems Conference (SysCon)
- **标题**: None
- **领域**: 机器学习,信号处理,系统与控制
- **Abstract**: This paper investigates unsupervised anomaly detection in multivariate time-series data using reinforcement learning (RL) in the latent space of an autoencoder. A significant challenge is the limited availability of anomalous data, often leading to misclassifying anomalies as normal events, thus raising false negatives. RL can help overcome this limitation by promoting exploration and balancing exploitation during training, effectively preventing overfitting. Wavelet analysis is also utilized to enhance anomaly detection, enabling time-series data decomposition into both time and frequency domains. This approach captures anomalies at multiple resolutions, with wavelet coefficients extracted to detect both sudden and subtle shifts in the data, thereby refining the anomaly detection process. We calibrate the decision boundary by generating synthetic anomalies and embedding a supervised framework within the model. This supervised element aids the unsupervised learning process by fine-tuning the decision boundary and increasing the model's capacity to distinguish between normal and anomalous patterns effectively.

### Analysis of Value Iteration Through Absolute Probability Sequences 
[[arxiv](https://arxiv.org/abs/2502.03244)] [[cool](https://papers.cool/arxiv/2502.03244)] [[pdf](https://arxiv.org/pdf/2502.03244)]
> **Authors**: Arsenii Mustafin,Sebastien Colla,Alex Olshevsky,Ioannis Ch. Paschalidis
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Value Iteration is a widely used algorithm for solving Markov Decision Processes (MDPs). While previous studies have extensively analyzed its convergence properties, they primarily focus on convergence with respect to the infinity norm. In this work, we use absolute probability sequences to develop a new line of analysis and examine the algorithm's convergence in terms of the $L^2$ norm, offering a new perspective on its behavior and performance.

### Pioneer: Physics-informed Riemannian Graph ODE for Entropy-increasing Dynamics 
[[arxiv](https://arxiv.org/abs/2502.03236)] [[cool](https://papers.cool/arxiv/2502.03236)] [[pdf](https://arxiv.org/pdf/2502.03236)]
> **Authors**: Li Sun,Ziheng Zhang,Zixi Wang,Yujie Wang,Qiqi Wan,Hao Li,Hao Peng,Philip S. Yu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by AAAI25
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Dynamic interacting system modeling is important for understanding and simulating real world systems. The system is typically described as a graph, where multiple objects dynamically interact with each other and evolve over time. In recent years, graph Ordinary Differential Equations (ODE) receive increasing research attentions. While achieving encouraging results, existing solutions prioritize the traditional Euclidean space, and neglect the intrinsic geometry of the system and physics laws, e.g., the principle of entropy increasing. The limitations above motivate us to rethink the system dynamics from a fresh perspective of Riemannian geometry, and pose a more realistic problem of physics-informed dynamic system modeling, considering the underlying geometry and physics law for the first time. In this paper, we present a novel physics-informed Riemannian graph ODE for a wide range of entropy-increasing dynamic systems (termed as Pioneer). In particular, we formulate a differential system on the Riemannian manifold, where a manifold-valued graph ODE is governed by the proposed constrained Ricci flow, and a manifold preserving Gyro-transform aware of system geometry. Theoretically, we report the provable entropy non-decreasing of our formulation, obeying the physics laws. Empirical results show the superiority of Pioneer on real datasets.

### The Other Side of the Coin: Unveiling the Downsides of Model Aggregation in Federated Learning from a Layer-peeled Perspective 
[[arxiv](https://arxiv.org/abs/2502.03231)] [[cool](https://papers.cool/arxiv/2502.03231)] [[pdf](https://arxiv.org/pdf/2502.03231)]
> **Authors**: Guogang Zhu,Xuefeng Liu,Jianwei Niu,Shaojie Tang,Xinghao Wu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: In federated learning (FL), model aggregation is a critical step by which multiple clients share their knowledge with one another. However, it is also widely recognized that the aggregated model, when sent back to each client, performs poorly on local data until after several rounds of local training. This temporary performance drop can potentially slow down the convergence of the FL model. Most research in FL regards this performance drop as an inherent cost of knowledge sharing among clients and does not give it special attention. While some studies directly focus on designing techniques to alleviate the issue, an in-depth investigation of the reasons behind this performance drop has yet to be conducted.To address this gap, we conduct a layer-peeled analysis of model aggregation across various datasets and model architectures. Our findings reveal that the performance drop can be attributed to two major consequences of the aggregation process: (1) it disrupts feature variability suppression in deep neural networks (DNNs), and (2) it weakens the coupling between features and subsequent parameters.Based on these findings, we propose several simple yet effective strategies to mitigate the negative impacts of model aggregation while still enjoying the benefit it brings. To the best of our knowledge, our work is the first to conduct a layer-peeled analysis of model aggregation, potentially paving the way for the development of more effective FL algorithms.

### Adversarial Dependence Minimization 
[[arxiv](https://arxiv.org/abs/2502.03227)] [[cool](https://papers.cool/arxiv/2502.03227)] [[pdf](https://arxiv.org/pdf/2502.03227)]
> **Authors**: Pierre-François De Plaen,Tinne Tuytelaars,Marc Proesmans,Luc Van Gool
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Many machine learning techniques rely on minimizing the covariance between output feature dimensions to extract minimally redundant representations from data. However, these methods do not eliminate all dependencies/redundancies, as linearly uncorrelated variables can still exhibit nonlinear relationships. This work provides a differentiable and scalable algorithm for dependence minimization that goes beyond linear pairwise decorrelation. Our method employs an adversarial game where small networks identify dependencies among feature dimensions, while the encoder exploits this information to reduce dependencies. We provide empirical evidence of the algorithm's convergence and demonstrate its utility in three applications: extending PCA to nonlinear decorrelation, improving the generalization of image classification methods, and preventing dimensional collapse in self-supervised representation learning.

### SpaceGNN: Multi-Space Graph Neural Network for Node Anomaly Detection with Extremely Limited Labels 
[[arxiv](https://arxiv.org/abs/2502.03201)] [[cool](https://papers.cool/arxiv/2502.03201)] [[pdf](https://arxiv.org/pdf/2502.03201)]
> **Authors**: Xiangyu Dong,Xingyi Zhang,Lei Chen,Mingxuan Yuan,Sibo Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Node Anomaly Detection (NAD) has gained significant attention in the deep learning community due to its diverse applications in real-world scenarios. Existing NAD methods primarily embed graphs within a single Euclidean space, while overlooking the potential of non-Euclidean spaces. Besides, to address the prevalent issue of limited supervision in real NAD tasks, previous methods tend to leverage synthetic data to collect auxiliary information, which is not an effective solution as shown in our experiments. To overcome these challenges, we introduce a novel SpaceGNN model designed for NAD tasks with extremely limited labels. Specifically, we provide deeper insights into a task-relevant framework by empirically analyzing the benefits of different spaces for node representations, based on which, we design a Learnable Space Projection function that effectively encodes nodes into suitable spaces. Besides, we introduce the concept of weighted homogeneity, which we empirically and theoretically validate as an effective coefficient during information propagation. This concept inspires the design of the Distance Aware Propagation module. Furthermore, we propose the Multiple Space Ensemble module, which extracts comprehensive information for NAD under conditions of extremely limited supervision. Our findings indicate that this module is more beneficial than data augmentation techniques for NAD. Extensive experiments conducted on 9 real datasets confirm the superiority of SpaceGNN, which outperforms the best rival by an average of 8.55% in AUC and 4.31% in F1 scores. Our code is available at https://github.com/xydong127/SpaceGNN.

### PICBench: Benchmarking LLMs for Photonic Integrated Circuits Design 
[[arxiv](https://arxiv.org/abs/2502.03159)] [[cool](https://papers.cool/arxiv/2502.03159)] [[pdf](https://arxiv.org/pdf/2502.03159)]
> **Authors**: Yuchao Wu,Xiaofei Yu,Hao Chen,Yang Luo,Yeyu Tong,Yuzhe Ma
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,硬件架构
- **Abstract**: While large language models (LLMs) have shown remarkable potential in automating various tasks in digital chip design, the field of Photonic Integrated Circuits (PICs)-a promising solution to advanced chip designs-remains relatively unexplored in this context. The design of PICs is time-consuming and prone to errors due to the extensive and repetitive nature of code involved in photonic chip design. In this paper, we introduce PICBench, the first benchmarking and evaluation framework specifically designed to automate PIC design generation using LLMs, where the generated output takes the form of a netlist. Our benchmark consists of dozens of meticulously crafted PIC design problems, spanning from fundamental device designs to more complex circuit-level designs. It automatically evaluates both the syntax and functionality of generated PIC designs by comparing simulation outputs with expert-written solutions, leveraging an open-source simulator. We evaluate a range of existing LLMs, while also conducting comparative tests on various prompt engineering techniques to enhance LLM performance in automated PIC design. The results reveal the challenges and potential of LLMs in the PIC design domain, offering insights into the key areas that require further research and development to optimize automation in this field. Our benchmark and evaluation code is available at https://github.com/PICDA/PICBench.

### Symmetry-Aware Bayesian Flow Networks for Crystal Generation 
[[arxiv](https://arxiv.org/abs/2502.03146)] [[cool](https://papers.cool/arxiv/2502.03146)] [[pdf](https://arxiv.org/pdf/2502.03146)]
> **Authors**: Laura Ruple,Luca Torresi,Henrik Schopmans,Pascal Friederich
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,材料科学
- **Abstract**: The discovery of new crystalline materials is essential to scientific and technological progress. However, traditional trial-and-error approaches are inefficient due to the vast search space. Recent advancements in machine learning have enabled generative models to predict new stable materials by incorporating structural symmetries and to condition the generation on desired properties. In this work, we introduce SymmBFN, a novel symmetry-aware Bayesian Flow Network (BFN) for crystalline material generation that accurately reproduces the distribution of space groups found in experimentally observed crystals. SymmBFN substantially improves efficiency, generating stable structures at least 50 times faster than the next-best method. Furthermore, we demonstrate its capability for property-conditioned generation, enabling the design of materials with tailored properties. Our findings establish BFNs as an effective tool for accelerating the discovery of crystalline materials.

### Machine Learning-Driven Student Performance Prediction for Enhancing Tiered Instruction 
[[arxiv](https://arxiv.org/abs/2502.03143)] [[cool](https://papers.cool/arxiv/2502.03143)] [[pdf](https://arxiv.org/pdf/2502.03143)]
> **Authors**: Yawen Chen,Jiande Sun,Jinhui Wang,Liang Zhao,Xinmin Song,Linbo Zhai
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,计算机与社会
- **Abstract**: Student performance prediction is one of the most important subjects in educational data mining. As a modern technology, machine learning offers powerful capabilities in feature extraction and data modeling, providing essential support for diverse application scenarios, as evidenced by recent studies confirming its effectiveness in educational data mining. However, despite extensive prediction experiments, machine learning methods have not been effectively integrated into practical teaching strategies, hindering their application in modern education. In addition, massive features as input variables for machine learning algorithms often leads to information redundancy, which can negatively impact prediction accuracy. Therefore, how to effectively use machine learning methods to predict student performance and integrate the prediction results with actual teaching scenarios is a worthy research subject. To this end, this study integrates the results of machine learning-based student performance prediction with tiered instruction, aiming to enhance student outcomes in target course, which is significant for the application of educational data mining in contemporary teaching scenarios. Specifically, we collect original educational data and perform feature selection to reduce information redundancy. Then, the performance of five representative machine learning methods is analyzed and discussed with Random Forest showing the best performance. Furthermore, based on the results of the classification of students, tiered instruction is applied accordingly, and different teaching objectives and contents are set for all levels of students. The comparison of teaching outcomes between the control and experimental classes, along with the analysis of questionnaire results, demonstrates the effectiveness of the proposed framework.

### Disentanglement in Difference: Directly Learning Semantically Disentangled Representations by Maximizing Inter-Factor Differences 
[[arxiv](https://arxiv.org/abs/2502.03123)] [[cool](https://papers.cool/arxiv/2502.03123)] [[pdf](https://arxiv.org/pdf/2502.03123)]
> **Authors**: Xingshen Zhang,Shuangrong Liu,Xintao Lu,Chaoran Pang,Lin Wang,Bo Yang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: In this study, Disentanglement in Difference(DiD) is proposed to address the inherent inconsistency between the statistical independence of latent variables and the goal of semantic disentanglement in disentanglement representation learning. Conventional disentanglement methods achieve disentanglement representation by improving statistical independence among latent variables. However, the statistical independence of latent variables does not necessarily imply that they are semantically unrelated, thus, improving statistical independence does not always enhance disentanglement performance. To address the above issue, DiD is proposed to directly learn semantic differences rather than the statistical independence of latent variables. In the DiD, a Difference Encoder is designed to measure the semantic differences; a contrastive loss function is established to facilitate inter-dimensional comparison. Both of them allow the model to directly differentiate and disentangle distinct semantic factors, thereby resolving the inconsistency between statistical independence and semantic disentanglement. Experimental results on the dSprites and 3DShapes datasets demonstrate that the proposed DiD outperforms existing mainstream methods across various disentanglement metrics.

### At the Mahakumbh, Faith Met Tragedy: Computational Analysis of Stampede Patterns Using Machine Learning and NLP 
[[arxiv](https://arxiv.org/abs/2502.03120)] [[cool](https://papers.cool/arxiv/2502.03120)] [[pdf](https://arxiv.org/pdf/2502.03120)]
> **Authors**: Abhinav Pratap
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 6 pages, 4 figures, 3 tables
- **标题**: None
- **领域**: 机器学习,人工智能,计算机与社会,社交和信息网络
- **Abstract**: This study employs machine learning, historical analysis, and natural language processing (NLP) to examine recurring lethal stampedes at Indias mass religious gatherings, focusing on the 2025 Mahakumbh tragedy in Prayagraj (48+ deaths) and its 1954 predecessor (700+ casualties). Through computational modeling of crowd dynamics and administrative records, it investigates how systemic vulnerabilities contribute to these disasters. Temporal trend analysis identifies persistent choke points, with narrow riverbank access routes linked to 92% of past stampede sites and lethal crowd densities recurring during spiritually significant moments like Mauni Amavasya. NLP analysis of seven decades of inquiry reports reveals cyclical administrative failures, where VIP route prioritization diverted safety resources in both 1954 and 2025, exacerbating fatalities. Statistical modeling demonstrates how ritual urgency overrides risk perception, leading to panic propagation patterns that mirror historical incidents. Findings support the Institutional Amnesia Theory, highlighting how disaster responses remain reactionary rather than preventive. By correlating archival patterns with computational crowd behavior analysis, this study frames stampedes as a collision of infrastructure limitations, socio spiritual urgency, and governance inertia, challenging disaster discourse to address how spiritual economies normalize preventable mortality.

### Multi-objective methods in Federated Learning: A survey and taxonomy 
[[arxiv](https://arxiv.org/abs/2502.03108)] [[cool](https://papers.cool/arxiv/2502.03108)] [[pdf](https://arxiv.org/pdf/2502.03108)]
> **Authors**: Maria Hartmann,Grégoire Danoy,Pascal Bouvry
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,分布式、并行和集群计算
- **Abstract**: The Federated Learning paradigm facilitates effective distributed machine learning in settings where training data is decentralized across multiple clients. As the popularity of the strategy grows, increasingly complex real-world problems emerge, many of which require balancing conflicting demands such as fairness, utility, and resource consumption. Recent works have begun to recognise the use of a multi-objective perspective in answer to this challenge. However, this novel approach of combining federated methods with multi-objective optimisation has never been discussed in the broader context of both fields. In this work, we offer a first clear and systematic overview of the different ways the two fields can be integrated. We propose a first taxonomy on the use of multi-objective methods in connection with Federated Learning, providing a targeted survey of the state-of-the-art and proposing unambiguous labels to categorise contributions. Given the developing nature of this field, our taxonomy is designed to provide a solid basis for further research, capturing existing works while anticipating future additions. Finally, we outline open challenges and possible directions for further research.

### Bellman Error Centering 
[[arxiv](https://arxiv.org/abs/2502.03104)] [[cool](https://papers.cool/arxiv/2502.03104)] [[pdf](https://arxiv.org/pdf/2502.03104)]
> **Authors**: Xingguo Chen,Yu Gong,Shangdong Yang,Wenhao Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: This paper revisits the recently proposed reward centering algorithms including simple reward centering (SRC) and value-based reward centering (VRC), and points out that SRC is indeed the reward centering, while VRC is essentially Bellman error centering (BEC). Based on BEC, we provide the centered fixpoint for tabular value functions, as well as the centered TD fixpoint for linear value function approximation. We design the on-policy CTD algorithm and the off-policy CTDC algorithm, and prove the convergence of both algorithms. Finally, we experimentally validate the stability of our proposed algorithms. Bellman error centering facilitates the extension to various reinforcement learning algorithms.

### Reveal the Mystery of DPO: The Connection between DPO and RL Algorithms 
[[arxiv](https://arxiv.org/abs/2502.03095)] [[cool](https://papers.cool/arxiv/2502.03095)] [[pdf](https://arxiv.org/pdf/2502.03095)]
> **Authors**: Xuerui Su,Yue Wang,Jinhua Zhu,Mingyang Yi,Feng Xu,Zhiming Ma,Yuting Liu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: With the rapid development of Large Language Models (LLMs), numerous Reinforcement Learning from Human Feedback (RLHF) algorithms have been introduced to improve model safety and alignment with human preferences. These algorithms can be divided into two main frameworks based on whether they require an explicit reward (or value) function for training: actor-critic-based Proximal Policy Optimization (PPO) and alignment-based Direct Preference Optimization (DPO). The mismatch between DPO and PPO, such as DPO's use of a classification loss driven by human-preferred data, has raised confusion about whether DPO should be classified as a Reinforcement Learning (RL) algorithm. To address these ambiguities, we focus on three key aspects related to DPO, RL, and other RLHF algorithms: (1) the construction of the loss function; (2) the target distribution at which the algorithm converges; (3) the impact of key components within the loss function. Specifically, we first establish a unified framework named UDRRA connecting these algorithms based on the construction of their loss functions. Next, we uncover their target policy distributions within this framework. Finally, we investigate the critical components of DPO to understand their impact on the convergence rate. Our work provides a deeper understanding of the relationship between DPO, RL, and other RLHF algorithms, offering new insights for improving existing algorithms.

### E-3SFC: Communication-Efficient Federated Learning with Double-way Features Synthesizing 
[[arxiv](https://arxiv.org/abs/2502.03092)] [[cool](https://papers.cool/arxiv/2502.03092)] [[pdf](https://arxiv.org/pdf/2502.03092)]
> **Authors**: Yuhao Zhou,Yuxin Tian,Mingjia Shi,Yuanxi Li,Yanan Sun,Qing Ye,Jiancheng Lv
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by TNNLS. arXiv admin note: text overlap with arXiv:2302.13562
- **标题**: None
- **领域**: 机器学习,人工智能,分布式、并行和集群计算
- **Abstract**: The exponential growth in model sizes has significantly increased the communication burden in Federated Learning (FL). Existing methods to alleviate this burden by transmitting compressed gradients often face high compression errors, which slow down the model's convergence. To simultaneously achieve high compression effectiveness and lower compression errors, we study the gradient compression problem from a novel perspective. Specifically, we propose a systematical algorithm termed Extended Single-Step Synthetic Features Compressing (E-3SFC), which consists of three sub-components, i.e., the Single-Step Synthetic Features Compressor (3SFC), a double-way compression algorithm, and a communication budget scheduler. First, we regard the process of gradient computation of a model as decompressing gradients from corresponding inputs, while the inverse process is considered as compressing the gradients. Based on this, we introduce a novel gradient compression method termed 3SFC, which utilizes the model itself as a decompressor, leveraging training priors such as model weights and objective functions. 3SFC compresses raw gradients into tiny synthetic features in a single-step simulation, incorporating error feedback to minimize overall compression errors. To further reduce communication overhead, 3SFC is extended to E-3SFC, allowing double-way compression and dynamic communication budget scheduling. Our theoretical analysis under both strongly convex and non-convex conditions demonstrates that 3SFC achieves linear and sub-linear convergence rates with aggregation noise. Extensive experiments across six datasets and six models reveal that 3SFC outperforms state-of-the-art methods by up to 13.4% while reducing communication costs by 111.6 times. These findings suggest that 3SFC can significantly enhance communication efficiency in FL without compromising model performance.

### Optimal Best Arm Identification with Post-Action Context 
[[arxiv](https://arxiv.org/abs/2502.03061)] [[cool](https://papers.cool/arxiv/2502.03061)] [[pdf](https://arxiv.org/pdf/2502.03061)]
> **Authors**: Mohammad Shahverdikondori,Amir Mohammad Abouei,Alireza Rezaeimoghadam,Negar Kiyavash
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 37 pages, 7 figures
- **标题**: None
- **领域**: 机器学习
- **Abstract**: We introduce the problem of best arm identification (BAI) with post-action context, a new BAI problem in a stochastic multi-armed bandit environment and the fixed-confidence setting. The problem addresses the scenarios in which the learner receives a $\textit{post-action context}$ in addition to the reward after playing each action. This post-action context provides additional information that can significantly facilitate the decision process. We analyze two different types of the post-action context: (i) $\textit{non-separator}$, where the reward depends on both the action and the context, and (ii) $\textit{separator}$, where the reward depends solely on the context. For both cases, we derive instance-dependent lower bounds on the sample complexity and propose algorithms that asymptotically achieve the optimal sample complexity. For the non-separator setting, we do so by demonstrating that the Track-and-Stop algorithm can be extended to this setting. For the separator setting, we propose a novel sampling rule called $\textit{G-tracking}$, which uses the geometry of the context space to directly track the contexts rather than the actions. Finally, our empirical results showcase the advantage of our approaches compared to the state of the art.

### Understanding and Enhancing the Transferability of Jailbreaking Attacks 
[[arxiv](https://arxiv.org/abs/2502.03052)] [[cool](https://papers.cool/arxiv/2502.03052)] [[pdf](https://arxiv.org/pdf/2502.03052)]
> **Authors**: Runqi Lin,Bo Han,Fengwang Li,Tongling Liu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by ICLR 2025
- **标题**: None
- **领域**: 机器学习,密码学和安全
- **Abstract**: Jailbreaking attacks can effectively manipulate open-source large language models (LLMs) to produce harmful responses. However, these attacks exhibit limited transferability, failing to disrupt proprietary LLMs consistently. To reliably identify vulnerabilities in proprietary LLMs, this work investigates the transferability of jailbreaking attacks by analysing their impact on the model's intent perception. By incorporating adversarial sequences, these attacks can redirect the source LLM's focus away from malicious-intent tokens in the original input, thereby obstructing the model's intent recognition and eliciting harmful responses. Nevertheless, these adversarial sequences fail to mislead the target LLM's intent perception, allowing the target LLM to refocus on malicious-intent tokens and abstain from responding. Our analysis further reveals the inherent distributional dependency within the generated adversarial sequences, whose effectiveness stems from overfitting the source LLM's parameters, resulting in limited transferability to target LLMs. To this end, we propose the Perceived-importance Flatten (PiF) method, which uniformly disperses the model's focus across neutral-intent tokens in the original input, thus obscuring malicious-intent tokens without relying on overfitted adversarial sequences. Extensive experiments demonstrate that PiF provides an effective and efficient red-teaming evaluation for proprietary LLMs.

### The Ensemble Kalman Update is an Empirical Matheron Update 
[[arxiv](https://arxiv.org/abs/2502.03048)] [[cool](https://papers.cool/arxiv/2502.03048)] [[pdf](https://arxiv.org/pdf/2502.03048)]
> **Authors**: Dan MacKinlay
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: :93E11 (Primary) 65C20 62M20 (Secondary)
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: The Ensemble Kalman Filter (EnKF) is a widely used method for data assimilation in high-dimensional systems. In this paper, we show that the ensemble update step of the EnKF is equivalent to an empirical version of the Matheron update popular in the study of Gaussian process regression. While this connection is simple, it seems not to be widely known, the literature about each technique seems distinct, and connections between the methods are not exploited. This paper exists to provide an informal introduction to the connection, with the necessary definitions so that it is intelligible to as broad an audience as possible.

### RepLoRA: Reparameterizing Low-Rank Adaptation via the Perspective of Mixture of Experts 
[[arxiv](https://arxiv.org/abs/2502.03044)] [[cool](https://papers.cool/arxiv/2502.03044)] [[pdf](https://arxiv.org/pdf/2502.03044)]
> **Authors**: Tuan Truong,Chau Nguyen,Huy Nguyen,Minh Le,Trung Le,Nhat Ho
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Low-rank adaptation (LoRA) has emerged as a powerful method for fine-tuning large-scale foundation models. Despite its popularity, the theoretical understanding of LoRA has remained limited. This paper presents a theoretical analysis of LoRA by examining its connection to the Mixture of Experts models. Under this framework, we show that simple reparameterizations of the LoRA matrices can notably accelerate the low-rank matrix estimation process. In particular, we prove that reparameterization can reduce the data needed to achieve a desired estimation error from an exponential to a polynomial scale. Motivated by this insight, we propose Reparameterized Low-rank Adaptation (RepLoRA), which incorporates lightweight MLPs to reparameterize the LoRA matrices. Extensive experiments across multiple domains demonstrate that RepLoRA consistently outperforms vanilla LoRA. Notably, with limited data, RepLoRA surpasses LoRA by a margin of up to 40.0% and achieves LoRA's performance with only 30.0% of the training data, highlighting both the theoretical and empirical robustness of our PEFT method.

### Aggregate to Adapt: Node-Centric Aggregation for Multi-Source-Free Graph Domain Adaptation 
[[arxiv](https://arxiv.org/abs/2502.03033)] [[cool](https://papers.cool/arxiv/2502.03033)] [[pdf](https://arxiv.org/pdf/2502.03033)]
> **Authors**: Zhen Zhang,Bingsheng He
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by WWW-2025
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Unsupervised graph domain adaptation (UGDA) focuses on transferring knowledge from labeled source graph to unlabeled target graph under domain discrepancies. Most existing UGDA methods are designed to adapt information from a single source domain, which cannot effectively exploit the complementary knowledge from multiple source domains. Furthermore, their assumptions that the labeled source graphs are accessible throughout the training procedure might not be practical due to privacy, regulation, and storage concerns. In this paper, we investigate multi-source-free unsupervised graph domain adaptation, i.e., adapting knowledge from multiple source domains to an unlabeled target domain without utilizing labeled source graphs but relying solely on source pre-trained models. Unlike previous multi-source domain adaptation approaches that aggregate predictions at model level, we introduce a novel model named GraphATA which conducts adaptation at node granularity. Specifically, we parameterize each node with its own graph convolutional matrix by automatically aggregating weight matrices from multiple source models according to its local context, thus realizing dynamic adaptation over graph structured data. We also demonstrate the capability of GraphATA to generalize to both model-centric and layer-centric methods. Comprehensive experiments on various public datasets show that our GraphATA can consistently surpass recent state-of-the-art baselines with different gains.

### Analyze Feature Flow to Enhance Interpretation and Steering in Language Models 
[[arxiv](https://arxiv.org/abs/2502.03032)] [[cool](https://papers.cool/arxiv/2502.03032)] [[pdf](https://arxiv.org/pdf/2502.03032)]
> **Authors**: Daniil Laptev,Nikita Balagansky,Yaroslav Aksenov,Daniil Gavrilov
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,计算语言学
- **Abstract**: We introduce a new approach to systematically map features discovered by sparse autoencoder across consecutive layers of large language models, extending earlier work that examined inter-layer feature links. By using a data-free cosine similarity technique, we trace how specific features persist, transform, or first appear at each stage. This method yields granular flow graphs of feature evolution, enabling fine-grained interpretability and mechanistic insights into model computations. Crucially, we demonstrate how these cross-layer feature maps facilitate direct steering of model behavior by amplifying or suppressing chosen features, achieving targeted thematic control in text generation. Together, our findings highlight the utility of a causal, cross-layer interpretability framework that not only clarifies how features develop through forward passes but also provides new means for transparent manipulation of large language models.

### On Zero-Initialized Attention: Optimal Prompt and Gating Factor Estimation 
[[arxiv](https://arxiv.org/abs/2502.03029)] [[cool](https://papers.cool/arxiv/2502.03029)] [[pdf](https://arxiv.org/pdf/2502.03029)]
> **Authors**: Nghiem T. Diep,Huy Nguyen,Chau Nguyen,Minh Le,Duy M. H. Nguyen,Daniel Sonntag,Mathias Niepert,Nhat Ho
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 43 pages, 5 tables, 6 figures
- **标题**: None
- **领域**: 机器学习
- **Abstract**: The LLaMA-Adapter has recently emerged as an efficient fine-tuning technique for LLaMA models, leveraging zero-initialized attention to stabilize training and enhance performance. However, despite its empirical success, the theoretical foundations of zero-initialized attention remain largely unexplored. In this paper, we provide a rigorous theoretical analysis, establishing a connection between zero-initialized attention and mixture-of-expert models. We prove that both linear and non-linear prompts, along with gating functions, can be optimally estimated, with non-linear prompts offering greater flexibility for future applications. Empirically, we validate our findings on the open LLM benchmarks, demonstrating that non-linear prompts outperform linear ones. Notably, even with limited training data, both prompt types consistently surpass vanilla attention, highlighting the robustness and adaptability of zero-initialized attention.

### Parametric Scaling Law of Tuning Bias in Conformal Prediction 
[[arxiv](https://arxiv.org/abs/2502.03023)] [[cool](https://papers.cool/arxiv/2502.03023)] [[pdf](https://arxiv.org/pdf/2502.03023)]
> **Authors**: Hao Zeng,Kangdao Liu,Bingyi Jing,Hongxin Wei
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,统计理论,方法论
- **Abstract**: Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional holdout set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed.

### xai_evals : A Framework for Evaluating Post-Hoc Local Explanation Methods 
[[arxiv](https://arxiv.org/abs/2502.03014)] [[cool](https://papers.cool/arxiv/2502.03014)] [[pdf](https://arxiv.org/pdf/2502.03014)]
> **Authors**: Pratinav Seth,Yashwardhan Rathore,Neeraj Kumar Singh,Chintan Chitroda,Vinay Kumar Sankarapu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,新兴技术
- **Abstract**: The growing complexity of machine learning and deep learning models has led to an increased reliance on opaque "black box" systems, making it difficult to understand the rationale behind predictions. This lack of transparency is particularly challenging in high-stakes applications where interpretability is as important as accuracy. Post-hoc explanation methods are commonly used to interpret these models, but they are seldom rigorously evaluated, raising concerns about their reliability. The Python package xai_evals addresses this by providing a comprehensive framework for generating, benchmarking, and evaluating explanation methods across both tabular and image data modalities. It integrates popular techniques like SHAP, LIME, Grad-CAM, Integrated Gradients (IG), and Backtrace, while supporting evaluation metrics such as faithfulness, sensitivity, and robustness. xai_evals enhances the interpretability of machine learning models, fostering transparency and trust in AI systems. The library is open-sourced at https://pypi.org/project/xai-evals/ .

### Scaling Laws for Upcycling Mixture-of-Experts Language Models 
[[arxiv](https://arxiv.org/abs/2502.03009)] [[cool](https://papers.cool/arxiv/2502.03009)] [[pdf](https://arxiv.org/pdf/2502.03009)]
> **Authors**: Seng Pei Liew,Takuya Kato,Sho Takase
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 15 figures, 8 tables
- **标题**: None
- **领域**: 机器学习,计算语言学
- **Abstract**: Pretraining large language models (LLMs) is resource-intensive, often requiring months of training time even with high-end GPU clusters. There are two approaches of mitigating such computational demands: reusing smaller models to train larger ones (upcycling), and training computationally efficient models like mixture-of-experts (MoE). In this paper, we study the upcycling of LLMs to MoE models, of which the scaling behavior remains underexplored. Through extensive experiments, we identify empirical scaling laws that describe how performance depends on dataset size and model configuration. Particularly, we show that, while scaling these factors improves performance, there is a novel interaction term between the dense and upcycled training dataset that limits the efficiency of upcycling at large computational budgets. Based on these findings, we provide guidance to scale upcycling, and establish conditions under which upcycling outperforms from-scratch trainings within budget constraints.

### Conformal Uncertainty Indicator for Continual Test-Time Adaptation 
[[arxiv](https://arxiv.org/abs/2502.02998)] [[cool](https://papers.cool/arxiv/2502.02998)] [[pdf](https://arxiv.org/pdf/2502.02998)]
> **Authors**: Fan Lyu,Hanyu Zhao,Ziqi Shi,Ye Liu,Fuyuan Hu,Zhang Zhang,Liang Wang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Continual Test-Time Adaptation (CTTA) aims to adapt models to sequentially changing domains during testing, relying on pseudo-labels for self-adaptation. However, incorrect pseudo-labels can accumulate, leading to performance degradation. To address this, we propose a Conformal Uncertainty Indicator (CUI) for CTTA, leveraging Conformal Prediction (CP) to generate prediction sets that include the true label with a specified coverage probability. Since domain shifts can lower the coverage than expected, making CP unreliable, we dynamically compensate for the coverage by measuring both domain and data differences. Reliable pseudo-labels from CP are then selectively utilized to enhance adaptation. Experiments confirm that CUI effectively estimates uncertainty and improves adaptation performance across various existing CTTA methods.

### TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics 
[[arxiv](https://arxiv.org/abs/2502.02975)] [[cool](https://papers.cool/arxiv/2502.02975)] [[pdf](https://arxiv.org/pdf/2502.02975)]
> **Authors**: Lu Yi,Jie Peng,Yanping Zheng,Fengran Mo,Zhewei Wei,Yuhang Ye,Yue Zixuan,Zengfeng Huang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: published at ICLR 2025
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Future link prediction is a fundamental challenge in various real-world dynamic systems. To address this, numerous temporal graph neural networks (temporal GNNs) and benchmark datasets have been developed. However, these datasets often feature excessive repeated edges and lack complex sequential dynamics, a key characteristic inherent in many real-world applications such as recommender systems and ``Who-To-Follow'' on social networks. This oversight has led existing methods to inadvertently downplay the importance of learning sequential dynamics, focusing primarily on predicting repeated edges. In this study, we demonstrate that existing methods, such as GraphMixer and DyGFormer, are inherently incapable of learning simple sequential dynamics, such as ``a user who has followed OpenAI and Anthropic is more likely to follow AI at Meta next.'' Motivated by this issue, we introduce the Temporal Graph Benchmark with Sequential Dynamics (TGB-Seq), a new benchmark carefully curated to minimize repeated edges, challenging models to learn sequential dynamics and generalize to unseen edges. TGB-Seq comprises large real-world datasets spanning diverse domains, including e-commerce interactions, movie ratings, business reviews, social networks, citation networks and web link networks. Benchmarking experiments reveal that current methods usually suffer significant performance degradation and incur substantial training costs on TGB-Seq, posing new challenges and opportunities for future research. TGB-Seq datasets, leaderboards, and example codes are available at https://tgb-seq.github.io/.

### Membership Inference Attack Should Move On to Distributional Statistics for Distilled Generative Models 
[[arxiv](https://arxiv.org/abs/2502.02970)] [[cool](https://papers.cool/arxiv/2502.02970)] [[pdf](https://arxiv.org/pdf/2502.02970)]
> **Authors**: Muxing Li,Zesheng Ye,Yixuan Li,Andy Song,Guangquan Zhang,Feng Liu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Membership inference attacks (MIAs) determine whether certain data instances were used to train a model by exploiting the differences in how the model responds to seen versus unseen instances. This capability makes MIAs important in assessing privacy leakage within modern generative AI systems. However, this paper reveals an oversight in existing MIAs against \emph{distilled generative models}: attackers can no longer detect a teacher model's training instances individually when targeting the distilled student model, as the student learns from the teacher-generated data rather than its original member data, preventing direct instance-level memorization. Nevertheless, we find that student-generated samples exhibit a significantly stronger distributional alignment with teacher's member data than non-member data. This leads us to posit that MIAs \emph{on distilled generative models should shift from instance-level to distribution-level statistics}. We thereby introduce a \emph{set-based} MIA framework that measures \emph{relative} distributional discrepancies between student-generated data\emph{sets} and potential member/non-member data\emph{sets}, Empirically, distributional statistics reliably distinguish a teacher's member data from non-member data through the distilled model. Finally, we discuss scenarios in which our setup faces limitations.

### Direct Distributional Optimization for Provable Alignment of Diffusion Models 
[[arxiv](https://arxiv.org/abs/2502.02954)] [[cool](https://papers.cool/arxiv/2502.02954)] [[pdf](https://arxiv.org/pdf/2502.02954)]
> **Authors**: Ryotaro Kawata,Kazusato Oko,Atsushi Nitanda,Taiji Suzuki
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: We introduce a novel alignment method for diffusion models from distribution optimization perspectives while providing rigorous convergence guarantees. We first formulate the problem as a generic regularized loss minimization over probability distributions and directly optimize the distribution using the Dual Averaging method. Next, we enable sampling from the learned distribution by approximating its score function via Doob's $h$-transform technique. The proposed framework is supported by rigorous convergence guarantees and an end-to-end bound on the sampling error, which imply that when the original distribution's score is known accurately, the complexity of sampling from shifted distributions is independent of isoperimetric conditions. This framework is broadly applicable to general distribution optimization problems, including alignment tasks in Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO). We empirically validate its performance on synthetic and image datasets using the DPO objective.

### Fast T2T: Optimization Consistency Speeds Up Diffusion-Based Training-to-Testing Solving for Combinatorial Optimization 
[[arxiv](https://arxiv.org/abs/2502.02941)] [[cool](https://papers.cool/arxiv/2502.02941)] [[pdf](https://arxiv.org/pdf/2502.02941)]
> **Authors**: Yang Li,Jinpei Guo,Runzhong Wang,Hongyuan Zha,Junchi Yan
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Published at NeurIPS 2024, the implementation code is available at https://github.com/Thinklab-SJTU/Fast-T2T
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Diffusion models have recently advanced Combinatorial Optimization (CO) as a powerful backbone for neural solvers. However, their iterative sampling process requiring denoising across multiple noise levels incurs substantial overhead. We propose to learn direct mappings from different noise levels to the optimal solution for a given instance, facilitating high-quality generation with minimal shots. This is achieved through an optimization consistency training protocol, which, for a given instance, minimizes the difference among samples originating from varying generative trajectories and time steps relative to the optimal solution. The proposed model enables fast single-step solution generation while retaining the option of multi-step sampling to trade for sampling quality, which offers a more effective and efficient alternative backbone for neural solvers. In addition, within the training-to-testing (T2T) framework, to bridge the gap between training on historical instances and solving new instances, we introduce a novel consistency-based gradient search scheme during the test stage, enabling more effective exploration of the solution space learned during training. It is achieved by updating the latent solution probabilities under objective gradient guidance during the alternation of noise injection and denoising steps. We refer to this model as Fast T2T. Extensive experiments on two popular tasks, the Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS), demonstrate the superiority of Fast T2T regarding both solution quality and efficiency, even outperforming LKH given limited time budgets. Notably, Fast T2T with merely one-step generation and one-step gradient search can mostly outperform the SOTA diffusion-based counterparts that require hundreds of steps, while achieving tens of times speedup.

### TopoCL: Topological Contrastive Learning for Time Series 
[[arxiv](https://arxiv.org/abs/2502.02924)] [[cool](https://papers.cool/arxiv/2502.02924)] [[pdf](https://arxiv.org/pdf/2502.02924)]
> **Authors**: Namwoo Kim,Hyungryul Baik,Yoonjin Yoon
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Submitted to TNNLS (under review)
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Universal time series representation learning is challenging but valuable in real-world applications such as classification, anomaly detection, and forecasting. Recently, contrastive learning (CL) has been actively explored to tackle time series representation. However, a key challenge is that the data augmentation process in CL can distort seasonal patterns or temporal dependencies, inevitably leading to a loss of semantic information. To address this challenge, we propose Topological Contrastive Learning for time series (TopoCL). TopoCL mitigates such information loss by incorporating persistent homology, which captures the topological characteristics of data that remain invariant under transformations. In this paper, we treat the temporal and topological properties of time series data as distinct modalities. Specifically, we compute persistent homology to construct topological features of time series data, representing them in persistence diagrams. We then design a neural network to encode these persistent diagrams. Our approach jointly optimizes CL within the time modality and time-topology correspondence, promoting a comprehensive understanding of both temporal semantics and topological properties of time series. We conduct extensive experiments on four downstream tasks-classification, anomaly detection, forecasting, and transfer learning. The results demonstrate that TopoCL achieves state-of-the-art performance.

### Elucidating the Preconditioning in Consistency Distillation 
[[arxiv](https://arxiv.org/abs/2502.02922)] [[cool](https://papers.cool/arxiv/2502.02922)] [[pdf](https://arxiv.org/pdf/2502.02922)]
> **Authors**: Kaiwen Zheng,Guande He,Jianfei Chen,Fan Bao,Jun Zhu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted at ICLR 2025
- **标题**: None
- **领域**: 机器学习,计算机视觉和模式识别
- **Abstract**: Consistency distillation is a prevalent way for accelerating diffusion models adopted in consistency (trajectory) models, in which a student model is trained to traverse backward on the probability flow (PF) ordinary differential equation (ODE) trajectory determined by the teacher model. Preconditioning is a vital technique for stabilizing consistency distillation, by linear combining the input data and the network output with pre-defined coefficients as the consistency function. It imposes the boundary condition of consistency functions without restricting the form and expressiveness of the neural network. However, previous preconditionings are hand-crafted and may be suboptimal choices. In this work, we offer the first theoretical insights into the preconditioning in consistency distillation, by elucidating its design criteria and the connection to the teacher ODE trajectory. Based on these analyses, we further propose a principled way dubbed \textit{Analytic-Precond} to analytically optimize the preconditioning according to the consistency gap (defined as the gap between the teacher denoiser and the optimal student denoiser) on a generalized teacher ODE. We demonstrate that Analytic-Precond can facilitate the learning of trajectory jumpers, enhance the alignment of the student trajectory with the teacher's, and achieve $2\times$ to $3\times$ training acceleration of consistency trajectory models in multi-step generation across various datasets.

### Robust Reward Alignment via Hypothesis Space Batch Cutting 
[[arxiv](https://arxiv.org/abs/2502.02921)] [[cool](https://papers.cool/arxiv/2502.02921)] [[pdf](https://arxiv.org/pdf/2502.02921)]
> **Authors**: Zhixian Xie,Haode Zhang,Yizhe Feng,Wanxin Jin
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 17 pages, including appendix
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Reward design for reinforcement learning and optimal control agents is challenging. Preference-based alignment addresses this by enabling agents to learn rewards from ranked trajectory pairs provided by humans. However, existing methods often struggle from poor robustness to unknown false human preferences. In this work, we propose a robust and efficient reward alignment method based on a novel and geometrically interpretable perspective: hypothesis space batched cutting. Our method iteratively refines the reward hypothesis space through "cuts" based on batches of human preferences. Within each batch, human preferences, queried based on disagreement, are grouped using a voting function to determine the appropriate cut, ensuring a bounded human query complexity. To handle unknown erroneous preferences, we introduce a conservative cutting method within each batch, preventing erroneous human preferences from making overly aggressive cuts to the hypothesis space. This guarantees provable robustness against false preferences. We evaluate our method in a model predictive control setting across diverse tasks, including DM-Control, dexterous in-hand manipulation, and locomotion. The results demonstrate that our framework achieves comparable or superior performance to state-of-the-art methods in error-free settings while significantly outperforming existing method when handling high percentage of erroneous human preferences.

### Adaptive Budget Optimization for Multichannel Advertising Using Combinatorial Bandits 
[[arxiv](https://arxiv.org/abs/2502.02920)] [[cool](https://papers.cool/arxiv/2502.02920)] [[pdf](https://arxiv.org/pdf/2502.02920)]
> **Authors**: Briti Gangopadhyay,Zhao Wang,Alberto Silvio Chiappa,Shingo Takamatsu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Effective budget allocation is crucial for optimizing the performance of digital advertising campaigns. However, the development of practical budget allocation algorithms remain limited, primarily due to the lack of public datasets and comprehensive simulation environments capable of verifying the intricacies of real-world advertising. While multi-armed bandit (MAB) algorithms have been extensively studied, their efficacy diminishes in non-stationary environments where quick adaptation to changing market dynamics is essential. In this paper, we advance the field of budget allocation in digital advertising by introducing three key contributions. First, we develop a simulation environment designed to mimic multichannel advertising campaigns over extended time horizons, incorporating logged real-world data. Second, we propose an enhanced combinatorial bandit budget allocation strategy that leverages a saturating mean function and a targeted exploration mechanism with change-point detection. This approach dynamically adapts to changing market conditions, improving allocation efficiency by filtering target regions based on domain knowledge. Finally, we present both theoretical analysis and empirical results, demonstrating that our method consistently outperforms baseline strategies, achieving higher rewards and lower regret across multiple real-world campaigns.

### Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework 
[[arxiv](https://arxiv.org/abs/2502.02917)] [[cool](https://papers.cool/arxiv/2502.02917)] [[pdf](https://arxiv.org/pdf/2502.02917)]
> **Authors**: Yuan Tian,Wenqi Zhou,Michele Viscione,Hao Dong,David Kammer,Olga Fink
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This work should not be a new submission but instead should be an update to my existing article, arXiv:2402.05306
- **标题**: None
- **领域**: 机器学习,人工智能,符号计算
- **Abstract**: Symbolic Regression (SR) holds great potential for uncovering underlying mathematical and physical relationships from observed data. However, the vast combinatorial space of possible expressions poses significant challenges for both online search methods and pre-trained transformer models. Additionally, current state-of-the-art approaches typically do not consider the integration of domain experts' prior knowledge and do not support iterative interactions with the model during the equation discovery process. To address these challenges, we propose the Symbolic Q-network (Sym-Q), an advanced interactive framework for large-scale symbolic regression. Unlike previous large-scale transformer-based SR approaches, Sym-Q leverages reinforcement learning without relying on a transformer-based decoder. This formulation allows the agent to learn through offline reinforcement learning using any type of tree encoder, enabling more efficient training and inference. Furthermore, we propose a co-design mechanism, where the reinforcement learning-based Sym-Q facilitates effective interaction with domain experts at any stage of the equation discovery process. Users can dynamically modify generated nodes of the expression, collaborating with the agent to tailor the mathematical expression to best fit the problem and align with the assumed physical laws, particularly when there is prior partial knowledge of the expected behavior. Our experiments demonstrate that the pre-trained Sym-Q surpasses existing SR algorithms on the challenging SSDNC benchmark. Moreover, we experimentally show on real-world cases that its performance can be further enhanced by the interactive co-design mechanism, with Sym-Q achieving greater performance gains than other state-of-the-art models. Our reproducible code is available at https://github.com/EPFL-IMOS/Sym-Q.

### Real-Time Privacy Risk Measurement with Privacy Tokens for Gradient Leakage 
[[arxiv](https://arxiv.org/abs/2502.02913)] [[cool](https://papers.cool/arxiv/2502.02913)] [[pdf](https://arxiv.org/pdf/2502.02913)]
> **Authors**: Jiayang Meng,Tao Huang,Hong Chen,Xin Shi,Qingyu Huang,Chen Hou
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,密码学和安全
- **Abstract**: The widespread deployment of deep learning models in privacy-sensitive domains has amplified concerns regarding privacy risks, particularly those stemming from gradient leakage during training. Current privacy assessments primarily rely on post-training attack simulations. However, these methods are inherently reactive, unable to encompass all potential attack scenarios, and often based on idealized adversarial assumptions. These limitations underscore the need for proactive approaches to privacy risk assessment during the training process. To address this gap, we propose the concept of privacy tokens, which are derived directly from private gradients during training. Privacy tokens encapsulate gradient features and, when combined with data features, offer valuable insights into the extent of private information leakage from training data, enabling real-time measurement of privacy risks without relying on adversarial attack simulations. Additionally, we employ Mutual Information (MI) as a robust metric to quantify the relationship between training data and gradients, providing precise and continuous assessments of privacy leakage throughout the training process. Extensive experiments validate our framework, demonstrating the effectiveness of privacy tokens and MI in identifying and quantifying privacy risks. This proactive approach marks a significant advancement in privacy monitoring, promoting the safer deployment of deep learning models in sensitive applications.

### MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations 
[[arxiv](https://arxiv.org/abs/2502.02912)] [[cool](https://papers.cool/arxiv/2502.02912)] [[pdf](https://arxiv.org/pdf/2502.02912)]
> **Authors**: Namwoo Kim,Takahiro Yabe,Chanyoung Park,Yoonjin Yoon
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Submitted to Information Sciences (under review)
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Recently, learning effective representations of urban regions has gained significant attention as a key approach to understanding urban dynamics and advancing smarter cities. Existing approaches have demonstrated the potential of leveraging mobility data to generate latent representations, providing valuable insights into the intrinsic characteristics of urban areas. However, incorporating the temporal dynamics and detailed semantics inherent in human mobility patterns remains underexplored. To address this gap, we propose a novel urban region representation learning model, Mobility Time Series Contrastive Learning for Urban Region Representations (MobiCLR), designed to capture semantically meaningful embeddings from inflow and outflow mobility patterns. MobiCLR uses contrastive learning to enhance the discriminative power of its representations, applying an instance-wise contrastive loss to capture distinct flow-specific characteristics. Additionally, we develop a regularizer to align output features with these flow-specific representations, enabling a more comprehensive understanding of mobility dynamics. To validate our model, we conduct extensive experiments in Chicago, New York, and Washington, D.C. to predict income, educational attainment, and social vulnerability. The results demonstrate that our model outperforms state-of-the-art models.

### SPARC: Subspace-Aware Prompt Adaptation for Robust Continual Learning in LLMs 
[[arxiv](https://arxiv.org/abs/2502.02909)] [[cool](https://papers.cool/arxiv/2502.02909)] [[pdf](https://arxiv.org/pdf/2502.02909)]
> **Authors**: Dinithi Jayasuriya,Sina Tayebati,Davide Ettori,Ranganath Krishnan,Amit Ranjan Trivedi
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,计算语言学
- **Abstract**: We propose SPARC, a lightweight continual learning framework for large language models (LLMs) that enables efficient task adaptation through prompt tuning in a lower-dimensional space. By leveraging principal component analysis (PCA), we identify a compact subspace of the training data. Optimizing prompts in this lower-dimensional space enhances training efficiency, as it focuses updates on the most relevant features while reducing computational overhead. Furthermore, since the model's internal structure remains unaltered, the extensive knowledge gained from pretraining is fully preserved, ensuring that previously learned information is not compromised during adaptation. Our method achieves high knowledge retention in both task-incremental and domain-incremental continual learning setups while fine-tuning only 0.04% of the model's parameters. Additionally, by integrating LoRA, we enhance adaptability to computational constraints, allowing for a tradeoff between accuracy and training cost. Experiments on the SuperGLUE benchmark demonstrate that our PCA-based prompt tuning combined with LoRA maintains full knowledge retention while improving accuracy, utilizing only 1% of the model's parameters. These results establish our approach as a scalable and resource-efficient solution for continual learning in LLMs.

## 计算机科学中的逻辑(cs.LO:Logic in Computer Science)

### Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques 
[[arxiv](https://arxiv.org/abs/2502.03321)] [[cool](https://papers.cool/arxiv/2502.03321)] [[pdf](https://arxiv.org/pdf/2502.03321)]
> **Authors**: Sangjun Han,Taeil Hur,Youngmi Hur,Kathy Sangkyung Lee,Myungyoon Lee,Hyojae Lim
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This manuscript was accepted for publication in the proceedings of the Computing Conference 2025 (Springer LNNS). The Version of Record (VoR) has not yet been published. This Accepted Manuscript does not reflect any post-acceptance improvements or corrections. Use of this version is subject to Springer Nature's Accepted Manuscript terms of use
- **标题**: None
- **领域**: 计算机科学中的逻辑,人工智能
- **Abstract**: The challenge of formal proof generation has a rich history, but with modern techniques, we may finally be at the stage of making actual progress in real-life mathematical problems. This paper explores the integration of ChatGPT and basic searching techniques to simplify generating formal proofs, with a particular focus on the miniF2F dataset. We demonstrate how combining a large language model like ChatGPT with a formal language such as Lean, which has the added advantage of being verifiable, enhances the efficiency and accessibility of formal proof generation. Despite its simplicity, our best-performing Lean-based model surpasses all known benchmarks with a 31.15% pass rate. We extend our experiments to include other datasets and employ alternative language models, showcasing our models' comparable performance in diverse settings and allowing for a more nuanced analysis of our results. Our findings offer insights into AI-assisted formal proof generation, suggesting a promising direction for future research in formal mathematical proof.

## 多代理系统(cs.MA:Multiagent Systems)

### Optimistic ε-Greedy Exploration for Cooperative Multi-Agent Reinforcement Learning 
[[arxiv](https://arxiv.org/abs/2502.03506)] [[cool](https://papers.cool/arxiv/2502.03506)] [[pdf](https://arxiv.org/pdf/2502.03506)]
> **Authors**: Ruoning Zhang,Siying Wang,Wenyu Chen,Yang Zhou,Zhitong Zhao,Zixuan Zhang,Ruijie Zhang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 多代理系统,机器学习
- **Abstract**: The Centralized Training with Decentralized Execution (CTDE) paradigm is widely used in cooperative multi-agent reinforcement learning. However, due to the representational limitations of traditional monotonic value decomposition methods, algorithms can underestimate optimal actions, leading policies to suboptimal solutions. To address this challenge, we propose Optimistic $ε$-Greedy Exploration, focusing on enhancing exploration to correct value estimations. The underestimation arises from insufficient sampling of optimal actions during exploration, as our analysis indicated. We introduce an optimistic updating network to identify optimal actions and sample actions from its distribution with a probability of $ε$ during exploration, increasing the selection frequency of optimal actions. Experimental results in various environments reveal that the Optimistic $ε$-Greedy Exploration effectively prevents the algorithm from suboptimal solutions and significantly improves its performance compared to other algorithms.

### Double Distillation Network for Multi-Agent Reinforcement Learning 
[[arxiv](https://arxiv.org/abs/2502.03125)] [[cool](https://papers.cool/arxiv/2502.03125)] [[pdf](https://arxiv.org/pdf/2502.03125)]
> **Authors**: Yang Zhou,Siying Wang,Wenyu Chen,Ruoning Zhang,Zhitong Zhao,Zixuan Zhang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 多代理系统,机器学习
- **Abstract**: Multi-agent reinforcement learning typically employs a centralized training-decentralized execution (CTDE) framework to alleviate the non-stationarity in environment. However, the partial observability during execution may lead to cumulative gap errors gathered by agents, impairing the training of effective collaborative policies. To overcome this challenge, we introduce the Double Distillation Network (DDN), which incorporates two distillation modules aimed at enhancing robust coordination and facilitating the collaboration process under constrained information. The external distillation module uses a global guiding network and a local policy network, employing distillation to reconcile the gap between global training and local execution. In addition, the internal distillation module introduces intrinsic rewards, drawn from state information, to enhance the exploration capabilities of agents. Extensive experiments demonstrate that DDN significantly improves performance across multiple scenarios.

## 神经和进化计算(cs.NE:Neural and Evolutionary Computing)

### STEMS: Spatial-Temporal Mapping Tool For Spiking Neural Networks 
[[arxiv](https://arxiv.org/abs/2502.03287)] [[cool](https://papers.cool/arxiv/2502.03287)] [[pdf](https://arxiv.org/pdf/2502.03287)]
> **Authors**: Sherif Eissa,Sander Stuijk,Floran De Putter,Andrea Nardi-Dei,Federico Corradi,Henk Corporaal
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 24 pages, 23 figures, under review at IEEE TC
- **标题**: None
- **领域**: 神经和进化计算,人工智能,硬件架构,分布式、并行和集群计算
- **Abstract**: Spiking Neural Networks (SNNs) are promising bio-inspired third-generation neural networks. Recent research has trained deep SNN models with accuracy on par with Artificial Neural Networks (ANNs). Although the event-driven and sparse nature of SNNs show potential for more energy efficient computation than ANNs, SNN neurons have internal states which evolve over time. Keeping track of SNN states can significantly increase data movement and storage requirements, potentially losing its advantages with respect to ANNs. This paper investigates the energy effects of having neuron states, and how it is influenced by the chosen mapping to realistic hardware architectures with advanced memory hierarchies. Therefore, we develop STEMS, a mapping design space exploration tool for SNNs. STEMS models SNN's stateful behavior and explores intra-layer and inter-layer mapping optimizations to minimize data movement, considering both spatial and temporal SNN dimensions. Using STEMS, we show up to 12x reduction in off-chip data movement and 5x reduction in energy (on top of intra-layer optimizations), on two event-based vision SNN benchmarks. Finally, neuron states may not be needed for all SNN layers. By optimizing neuron states for one of our benchmarks, we show 20x reduction in neuron states and 1.4x better performance without accuracy loss.

### Kozax: Flexible and Scalable Genetic Programming in JAX 
[[arxiv](https://arxiv.org/abs/2502.03047)] [[cool](https://papers.cool/arxiv/2502.03047)] [[pdf](https://arxiv.org/pdf/2502.03047)]
> **Authors**: Sigur de Vries,Sander W. Keemink,Marcel A. J. van Gerven
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 5 figures, 3 tables, 1 algorithm, 10 pages
- **标题**: None
- **领域**: 神经和进化计算,人工智能
- **Abstract**: Genetic programming is an optimization algorithm inspired by natural selection which automatically evolves the structure of computer programs. The resulting computer programs are interpretable and efficient compared to black-box models with fixed structure. The fitness evaluation in genetic programming suffers from high computational requirements, limiting the performance on difficult problems. To reduce the runtime, many implementations of genetic programming require a specific data format, making the applicability limited to specific problem classes. Consequently, there is no efficient genetic programming framework that is usable for a wide range of tasks. To this end, we developed Kozax, a genetic programming framework that evolves symbolic expressions for arbitrary problems. We implemented Kozax using JAX, a framework for high-performance and scalable machine learning, which allows the fitness evaluation to scale efficiently to large populations or datasets on GPU. Furthermore, Kozax offers constant optimization, custom operator definition and simultaneous evolution of multiple trees. We demonstrate successful applications of Kozax to discover equations of natural laws, recover equations of hidden dynamic variables and evolve a control policy. Overall, Kozax provides a general, fast, and scalable library to optimize white-box solutions in the realm of scientific computing.

## 网络和互联网架构(cs.NI:Networking and Internet Architecture)

### Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach 
[[arxiv](https://arxiv.org/abs/2502.03377)] [[cool](https://papers.cool/arxiv/2502.03377)] [[pdf](https://arxiv.org/pdf/2502.03377)]
> **Authors**: Abdullahi Isa Ahmed,El Mehdi Amhoud
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 6 pages, 6 figures
- **标题**: None
- **领域**: 网络和互联网架构,机器学习
- **Abstract**: With the rapid development of next-generation Internet of Things (NG-IoT) networks, the increasing number of connected devices has led to a surge in power consumption. This rise in energy demand poses significant challenges to resource availability and raises sustainability concerns for large-scale IoT deployments. Efficient energy utilization in communication networks, particularly for power-constrained IoT devices, has thus become a critical area of research. In this paper, we deployed flying LoRa gateways (GWs) mounted on unmanned aerial vehicles (UAVs) to collect data from LoRa end devices (EDs) and transmit it to a central server. Our primary objective is to maximize the global system energy efficiency (EE) of wireless LoRa networks by joint optimization of transmission power (TP), spreading factor (SF), bandwidth (W), and ED association. To solve this challenging problem, we model the problem as a partially observable Markov decision process (POMDP), where each flying LoRa GW acts as a learning agent using a cooperative Multi-Agent Reinforcement Learning (MARL) approach under centralized training and decentralized execution (CTDE). Simulation results demonstrate that our proposed method, based on the multi-agent proximal policy optimization (MAPPO) algorithm, significantly improves the global system EE and surpasses the conventional MARL schemes.

## 机器人技术(cs.RO:Robotics)

### Action-Free Reasoning for Policy Generalization 
[[arxiv](https://arxiv.org/abs/2502.03729)] [[cool](https://papers.cool/arxiv/2502.03729)] [[pdf](https://arxiv.org/pdf/2502.03729)]
> **Authors**: Jaden Clark,Suvir Mirchandani,Dorsa Sadigh,Suneel Belkhale
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 13 pages, 10 figures
- **标题**: None
- **领域**: 机器人技术,人工智能
- **Abstract**: End-to-end imitation learning offers a promising approach for training robot policies. However, generalizing to new settings remains a significant challenge. Although large-scale robot demonstration datasets have shown potential for inducing generalization, they are resource-intensive to scale. In contrast, human video data is abundant and diverse, presenting an attractive alternative. Yet, these human-video datasets lack action labels, complicating their use in imitation learning. Existing methods attempt to extract grounded action representations (e.g., hand poses), but resulting policies struggle to bridge the embodiment gap between human and robot actions. We propose an alternative approach: leveraging language-based reasoning from human videos-essential for guiding robot actions-to train generalizable robot policies. Building on recent advances in reasoning-based policy architectures, we introduce Reasoning through Action-free Data (RAD). RAD learns from both robot demonstration data (with reasoning and action labels) and action-free human video data (with only reasoning labels). The robot data teaches the model to map reasoning to low-level actions, while the action-free data enhances reasoning capabilities. Additionally, we will release a new dataset of 3,377 human-hand demonstrations with reasoning annotations compatible with the Bridge V2 benchmark and aimed at facilitating future research on reasoning-driven robot learning. Our experiments show that RAD enables effective transfer across the embodiment gap, allowing robots to perform tasks seen only in action-free data. Furthermore, scaling up action-free reasoning data significantly improves policy performance and generalization to novel tasks. These results highlight the promise of reasoning-driven learning from action-free datasets for advancing generalizable robot control. Project page: https://rad-generalization.github.io

### Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning 
[[arxiv](https://arxiv.org/abs/2502.03717)] [[cool](https://papers.cool/arxiv/2502.03717)] [[pdf](https://arxiv.org/pdf/2502.03717)]
> **Authors**: Jaden Clark,Joey Hejna,Dorsa Sadigh
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 8 pages 5 figures
- **标题**: None
- **领域**: 机器人技术,人工智能
- **Abstract**: Expressive robotic behavior is essential for the widespread acceptance of robots in social environments. Recent advancements in learned legged locomotion controllers have enabled more dynamic and versatile robot behaviors. However, determining the optimal behavior for interactions with different users across varied scenarios remains a challenge. Current methods either rely on natural language input, which is efficient but low-resolution, or learn from human preferences, which, although high-resolution, is sample inefficient. This paper introduces a novel approach that leverages priors generated by pre-trained LLMs alongside the precision of preference learning. Our method, termed Language-Guided Preference Learning (LGPL), uses LLMs to generate initial behavior samples, which are then refined through preference-based feedback to learn behaviors that closely align with human expectations. Our core insight is that LLMs can guide the sampling process for preference learning, leading to a substantial improvement in sample efficiency. We demonstrate that LGPL can quickly learn accurate and expressive behaviors with as few as four queries, outperforming both purely language-parameterized models and traditional preference learning approaches. Website with videos: https://lgpl-gaits.github.io/

### Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal Control 
[[arxiv](https://arxiv.org/abs/2502.03640)] [[cool](https://papers.cool/arxiv/2502.03640)] [[pdf](https://arxiv.org/pdf/2502.03640)]
> **Authors**: Songyuan Zhang,Oswin So,Mitchell Black,Chuchu Fan
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 31 pages, 15 figures, accepted by the thirteenth International Conference onLearningRepresentations (ICLR 2025)
- **标题**: None
- **领域**: 机器人技术,机器学习,多代理系统,优化与控制
- **Abstract**: Control policies that can achieve high task performance and satisfy safety constraints are desirable for any system, including multi-agent systems (MAS). One promising technique for ensuring the safety of MAS is distributed control barrier functions (CBF). However, it is difficult to design distributed CBF-based policies for MAS that can tackle unknown discrete-time dynamics, partial observability, changing neighborhoods, and input constraints, especially when a distributed high-performance nominal policy that can achieve the task is unavailable. To tackle these challenges, we propose DGPPO, a new framework that simultaneously learns both a discrete graph CBF which handles neighborhood changes and input constraints, and a distributed high-performance safe policy for MAS with unknown discrete-time dynamics. We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that, compared with existing methods, our DGPPO framework obtains policies that achieve high task performance (matching baselines that ignore the safety constraints), and high safety rates (matching the most conservative baselines), with a constant set of hyperparameters across all environments.

### Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models 
[[arxiv](https://arxiv.org/abs/2502.03607)] [[cool](https://papers.cool/arxiv/2502.03607)] [[pdf](https://arxiv.org/pdf/2502.03607)]
> **Authors**: Jinhao Liang,Jacob K Christopher,Sven Koenig,Ferdinando Fioretto
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器人技术,人工智能,机器学习
- **Abstract**: Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address this challenge, this work proposes Simultaneous MRMP Diffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments.

### IRIS: An Immersive Robot Interaction System 
[[arxiv](https://arxiv.org/abs/2502.03297)] [[cool](https://papers.cool/arxiv/2502.03297)] [[pdf](https://arxiv.org/pdf/2502.03297)]
> **Authors**: Xinkai Jiang,Qihao Yuan,Enes Ulas Dincer,Hongyi Zhou,Ge Li,Xueyin Li,Julius Haag,Nicolas Schreiber,Kailai Li,Gerhard Neumann,Rudolf Lioutikov
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器人技术,机器学习
- **Abstract**: This paper introduces IRIS, an immersive Robot Interaction System leveraging Extended Reality (XR), designed for robot data collection and interaction across multiple simulators, benchmarks, and real-world scenarios. While existing XR-based data collection systems provide efficient and intuitive solutions for large-scale data collection, they are often challenging to reproduce and reuse. This limitation arises because current systems are highly tailored to simulator-specific use cases and environments. IRIS is a novel, easily extendable framework that already supports multiple simulators, benchmarks, and even headsets. Furthermore, IRIS is able to include additional information from real-world sensors, such as point clouds captured through depth cameras. A unified scene specification is generated directly from simulators or real-world sensors and transmitted to XR headsets, creating identical scenes in XR. This specification allows IRIS to support any of the objects, assets, and robots provided by the simulators. In addition, IRIS introduces shared spatial anchors and a robust communication protocol that links simulations between multiple XR headsets. This feature enables multiple XR headsets to share a synchronized scene, facilitating collaborative and multi-user data collection. IRIS can be deployed on any device that supports the Unity Framework, encompassing the vast majority of commercially available headsets. In this work, IRIS was deployed and tested on the Meta Quest 3 and the HoloLens 2. IRIS showcased its versatility across a wide range of real-world and simulated scenarios, using current popular robot simulators such as MuJoCo, IsaacSim, CoppeliaSim, and Genesis. In addition, a user study evaluates IRIS on a data collection task for the LIBERO benchmark. The study shows that IRIS significantly outperforms the baseline in both objective and subjective metrics.

### When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning 
[[arxiv](https://arxiv.org/abs/2502.03270)] [[cool](https://papers.cool/arxiv/2502.03270)] [[pdf](https://arxiv.org/pdf/2502.03270)]
> **Authors**: Nikolaos Tsagkas,Andreas Sochopoulos,Duolikun Danier,Chris Xiaoxuan Lu,Oisin Mac Aodha
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器人技术,人工智能,计算机视觉和模式识别,机器学习
- **Abstract**: The integration of pre-trained visual representations (PVRs) into visuo-motor robot learning has emerged as a promising alternative to training visual encoders from scratch. However, PVRs face critical challenges in the context of policy learning, including temporal entanglement and an inability to generalise even in the presence of minor scene perturbations. These limitations hinder performance in tasks requiring temporal awareness and robustness to scene changes. This work identifies these shortcomings and proposes solutions to address them. First, we augment PVR features with temporal perception and a sense of task completion, effectively disentangling them in time. Second, we introduce a module that learns to selectively attend to task-relevant local features, enhancing robustness when evaluated on out-of-distribution scenes. Our experiments demonstrate significant performance improvements, particularly in PVRs trained with masking objectives, and validate the effectiveness of our enhancements in addressing PVR-specific limitations.

### Underwater Soft Fin Flapping Motion with Deep Neural Network Based Surrogate Model 
[[arxiv](https://arxiv.org/abs/2502.03135)] [[cool](https://papers.cool/arxiv/2502.03135)] [[pdf](https://arxiv.org/pdf/2502.03135)]
> **Authors**: Yuya Hamamatsu,Pavlo Kupyn,Roza Gkliva,Asko Ristolainen,Maarja Kruusmaa
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted in IEEE International Conference on Soft Robotics 2025 (Robosoft)
- **标题**: None
- **领域**: 机器人技术,机器学习
- **Abstract**: This study presents a novel framework for precise force control of fin-actuated underwater robots by integrating a deep neural network (DNN)-based surrogate model with reinforcement learning (RL). To address the complex interactions with the underwater environment and the high experimental costs, a DNN surrogate model acts as a simulator for enabling efficient training for the RL agent. Additionally, grid-switching control is applied to select optimized models for specific force reference ranges, improving control accuracy and stability. Experimental results show that the RL agent, trained in the surrogate simulation, generates complex thrust motions and achieves precise control of a real soft fin actuator. This approach provides an efficient control solution for fin-actuated robots in challenging underwater environments.

### Learning Efficient Flocking Control based on Gibbs Random Fields 
[[arxiv](https://arxiv.org/abs/2502.02984)] [[cool](https://papers.cool/arxiv/2502.02984)] [[pdf](https://arxiv.org/pdf/2502.02984)]
> **Authors**: Dengyu Zhang,Chenghao,Feng Xue,Qingrui Zhang
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 9 pages, 10 figures
- **标题**: None
- **领域**: 机器人技术,机器学习,系统与控制
- **Abstract**: Flocking control is essential for multi-robot systems in diverse applications, yet achieving efficient flocking in congested environments poses challenges regarding computation burdens, performance optimality, and motion safety. This paper addresses these challenges through a multi-agent reinforcement learning (MARL) framework built on Gibbs Random Fields (GRFs). With GRFs, a multi-robot system is represented by a set of random variables conforming to a joint probability distribution, thus offering a fresh perspective on flocking reward design. A decentralized training and execution mechanism, which enhances the scalability of MARL concerning robot quantity, is realized using a GRF-based credit assignment method. An action attention module is introduced to implicitly anticipate the motion intentions of neighboring robots, consequently mitigating potential non-stationarity issues in MARL. The proposed framework enables learning an efficient distributed control policy for multi-robot systems in challenging environments with success rate around $99\%$, as demonstrated through thorough comparisons with state-of-the-art solutions in simulations and experiments. Ablation studies are also performed to validate the efficiency of different framework modules.

### Label Anything: An Interpretable, High-Fidelity and Prompt-Free Annotator 
[[arxiv](https://arxiv.org/abs/2502.02972)] [[cool](https://papers.cool/arxiv/2502.02972)] [[pdf](https://arxiv.org/pdf/2502.02972)]
> **Authors**: Wei-Bin Kou,Guangxu Zhu,Rongguang Ye,Shuai Wang,Ming Tang,Yik-Chung Wu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: Accepted by ICRA 2025
- **标题**: None
- **领域**: 机器人技术,机器学习
- **Abstract**: Learning-based street scene semantic understanding in autonomous driving (AD) has advanced significantly recently, but the performance of the AD model is heavily dependent on the quantity and quality of the annotated training data. However, traditional manual labeling involves high cost to annotate the vast amount of required data for training robust model. To mitigate this cost of manual labeling, we propose a Label Anything Model (denoted as LAM), serving as an interpretable, high-fidelity, and prompt-free data annotator. Specifically, we firstly incorporate a pretrained Vision Transformer (ViT) to extract the latent features. On top of ViT, we propose a semantic class adapter (SCA) and an optimization-oriented unrolling algorithm (OptOU), both with a quite small number of trainable parameters. SCA is proposed to fuse ViT-extracted features to consolidate the basis of the subsequent automatic annotation. OptOU consists of multiple cascading layers and each layer contains an optimization formulation to align its output with the ground truth as closely as possible, though which OptOU acts as being interpretable rather than learning-based blackbox nature. In addition, training SCA and OptOU requires only a single pre-annotated RGB seed image, owing to their small volume of learnable parameters. Extensive experiments clearly demonstrate that the proposed LAM can generate high-fidelity annotations (almost 100% in mIoU) for multiple real-world datasets (i.e., Camvid, Cityscapes, and Apolloscapes) and CARLA simulation dataset.

## 声音(cs.SD:Sound)

### Metis: A Foundation Speech Generation Model with Masked Generative Pre-training 
[[arxiv](https://arxiv.org/abs/2502.03128)] [[cool](https://papers.cool/arxiv/2502.03128)] [[pdf](https://arxiv.org/pdf/2502.03128)]
> **Authors**: Yuancheng Wang,Jiachen Zheng,Junan Zhang,Xueyao Zhang,Huan Liao,Zhizheng Wu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 声音,人工智能,机器学习,音频和语音处理,信号处理
- **Abstract**: We introduce Metis, a foundation model for unified speech generation. Unlike previous task-specific or multi-task models, Metis follows a pre-training and fine-tuning paradigm. It is pre-trained on large-scale unlabeled speech data using masked generative modeling and then fine-tuned to adapt to diverse speech generation tasks. Specifically, 1) Metis utilizes two discrete speech representations: SSL tokens derived from speech self-supervised learning (SSL) features, and acoustic tokens directly quantized from waveforms. 2) Metis performs masked generative pre-training on SSL tokens, utilizing 300K hours of diverse speech data, without any additional condition. 3) Through fine-tuning with task-specific conditions, Metis achieves efficient adaptation to various speech generation tasks while supporting multimodal input, even when using limited data and trainable parameters. Experiments demonstrate that Metis can serve as a foundation model for unified speech generation: Metis outperforms state-of-the-art task-specific or multi-task systems across five speech generation tasks, including zero-shot text-to-speech, voice conversion, target speaker extraction, speech enhancement, and lip-to-speech, even with fewer than 20M trainable parameters or 300 times less training data. Audio samples are are available at https://metis-demo.github.io/.

## 软件工程(cs.SE:Software Engineering)

### An Empirical Exploration of ChatGPT's Ability to Support Problem Formulation Tasks for Mission Engineering and a Documentation of its Performance Variability 
[[arxiv](https://arxiv.org/abs/2502.03511)] [[cool](https://papers.cool/arxiv/2502.03511)] [[pdf](https://arxiv.org/pdf/2502.03511)]
> **Authors**: Max Ofsa,Taylan G. Topcu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 10 pages, 3 figures, submitted to Conference on Systems Engineering Research (CSER)
- **标题**: None
- **领域**: 软件工程,人工智能,计算语言学
- **Abstract**: Systems engineering (SE) is evolving with the availability of generative artificial intelligence (AI) and the demand for a systems-of-systems perspective, formalized under the purview of mission engineering (ME) in the US Department of Defense. Formulating ME problems is challenging because they are open-ended exercises that involve translation of ill-defined problems into well-defined ones that are amenable for engineering development. It remains to be seen to which extent AI could assist problem formulation objectives. To that end, this paper explores the quality and consistency of multi-purpose Large Language Models (LLM) in supporting ME problem formulation tasks, specifically focusing on stakeholder identification. We identify a relevant reference problem, a NASA space mission design challenge, and document ChatGPT-3.5's ability to perform stakeholder identification tasks. We execute multiple parallel attempts and qualitatively evaluate LLM outputs, focusing on both their quality and variability. Our findings portray a nuanced picture. We find that the LLM performs well in identifying human-focused stakeholders but poorly in recognizing external systems and environmental factors, despite explicit efforts to account for these. Additionally, LLMs struggle with preserving the desired level of abstraction and exhibit a tendency to produce solution specific outputs that are inappropriate for problem formulation. More importantly, we document great variability among parallel threads, highlighting that LLM outputs should be used with caution, ideally by adopting a stochastic view of their abilities. Overall, our findings suggest that, while ChatGPT could reduce some expert workload, its lack of consistency and domain understanding may limit its reliability for problem formulation tasks.

### A Match Made in Heaven? Matching Test Cases and Vulnerabilities With the VUTECO Approach 
[[arxiv](https://arxiv.org/abs/2502.03365)] [[cool](https://papers.cool/arxiv/2502.03365)] [[pdf](https://arxiv.org/pdf/2502.03365)]
> **Authors**: Emanuele Iannone,Quang-Cuong Bui,Riccardo Scandariato
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This work was partially supported by EU-funded project Sec4AI4Sec (grant no. 101120393)
- **标题**: None
- **领域**: 软件工程,密码学和安全,机器学习
- **Abstract**: Software vulnerabilities are commonly detected via static analysis, penetration testing, and fuzzing. They can also be found by running unit tests - so-called vulnerability-witnessing tests - that stimulate the security-sensitive behavior with crafted inputs. Developing such tests is difficult and time-consuming; thus, automated data-driven approaches could help developers intercept vulnerabilities earlier. However, training and validating such approaches require a lot of data, which is currently scarce. This paper introduces VUTECO, a deep learning-based approach for collecting instances of vulnerability-witnessing tests from Java repositories. VUTECO carries out two tasks: (1) the "Finding" task to determine whether a test case is security-related, and (2) the "Matching" task to relate a test case to the exact vulnerability it is witnessing. VUTECO successfully addresses the Finding task, achieving perfect precision and 0.83 F0.5 score on validated test cases in VUL4J and returning 102 out of 145 (70%) correct security-related test cases from 244 open-source Java projects. Despite showing sufficiently good performance for the Matching task - i.e., 0.86 precision and 0.68 F0.5 score - VUTECO failed to retrieve any valid match in the wild. Nevertheless, we observed that in almost all of the matches, the test case was still security-related despite being matched to the wrong vulnerability. In the end, VUTECO can help find vulnerability-witnessing tests, though the matching with the right vulnerability is yet to be solved; the findings obtained lay the stepping stone for future research on the matter.

### Large Language Model Guided Self-Debugging Code Generation 
[[arxiv](https://arxiv.org/abs/2502.02928)] [[cool](https://papers.cool/arxiv/2502.02928)] [[pdf](https://arxiv.org/pdf/2502.02928)]
> **Authors**: Muntasir Adnan,Zhiwei Xu,Carlos C. N. Kuhn
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 软件工程,人工智能
- **Abstract**: Automated code generation is gaining significant importance in intelligent computer programming and system deployment. However, current approaches often face challenges in computational efficiency and lack robust mechanisms for code parsing and error correction. In this work, we propose a novel framework, PyCapsule, with a simple yet effective two-agent pipeline and efficient self-debugging modules for Python code generation. PyCapsule features sophisticated prompt inference, iterative error handling, and case testing, ensuring high generation stability, safety, and correctness. Empirically, PyCapsule achieves up to 5.7% improvement of success rate on HumanEval, 10.3% on HumanEval-ET, and 24.4% on BigCodeBench compared to the state-of-art methods. We also observe a decrease in normalized success rate given more self-debugging attempts, potentially affected by limited and noisy error feedback in retention. PyCapsule demonstrates broader impacts on advancing lightweight and efficient code generation for artificial intelligence systems.

### DANDI: Diffusion as Normative Distribution for Deep Neural Network Input 
[[arxiv](https://arxiv.org/abs/2502.02910)] [[cool](https://papers.cool/arxiv/2502.02910)] [[pdf](https://arxiv.org/pdf/2502.02910)]
> **Authors**: Somin Kim,Shin Yoo
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: DeepTest 2025 Workshop
- **标题**: None
- **领域**: 软件工程,机器学习
- **Abstract**: Surprise Adequacy (SA) has been widely studied as a test adequacy metric that can effectively guide software engineers towards inputs that are more likely to reveal unexpected behaviour of Deep Neural Networks (DNNs). Intuitively, SA is an out-of-distribution metric that quantifies the dissimilarity between the given input and the training data: if a new input is very different from those seen during training, the DNN is more likely to behave unexpectedly against the input. While SA has been widely adopted as a test prioritization method, its major weakness is the fact that the computation of the metric requires access to the training dataset, which is often not allowed in real-world use cases. We present DANDI, a technique that generates a surrogate input distribution using Stable Diffusion to compute SA values without requiring the original training data. An empirical evaluation of DANDI applied to image classifiers for CIFAR10 and ImageNet-1K shows that SA values computed against synthetic data are highly correlated with the values computed against the training data, with Spearman Rank correlation value of 0.852 for ImageNet-1K and 0.881 for CIFAR-10. Further, we show that SA value computed by DANDI achieves can prioritize inputs as effectively as those computed using the training data, when testing DNN models mutated by DeepMutation. We believe that DANDI can significantly improve the usability of SA for practical DNN testing.

### COSMosFL: Ensemble of Small Language Models for Fault Localisation 
[[arxiv](https://arxiv.org/abs/2502.02908)] [[cool](https://papers.cool/arxiv/2502.02908)] [[pdf](https://arxiv.org/pdf/2502.02908)]
> **Authors**: Hyunjoon Cho,Sungmin Kang,Gabin An,Shin Yoo
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: LLM4Code 2025 Workshop
- **标题**: None
- **领域**: 软件工程,机器学习
- **Abstract**: LLMs are rapidly being adopted to build powerful tools and agents for software engineering, but most of them rely heavily on extremely large closed-source models. This, in turn, can hinder wider adoption due to security issues as well as financial cost and environmental impact. Recently, a number of open source Small Language Models (SLMs) are being released and gaining traction. While SLMs are smaller, more energy-efficient, and therefore easier to locally deploy, they tend to show worse performance when compared to larger closed LLMs. We present COSMos, a task-level LLM ensemble technique that uses voting mechanism, to provide a broader range of choice between SLMs and LLMs. We instantiate COSMos with an LLM-based Fault Localisation technique, AutoFL, and report the cost-benefit trade-off between LLM accuracy and various costs such as energy consumption, inference time, and the number of tokens used. An empirical evaluation using Defects4J shows that COSMos can build effective ensembles that can achieve Pareto-optimality in terms of FL accuracy and inference cost, when compared to individual models.

## 社交和信息网络(cs.SI:Social and Information Networks)

### Behavioral Homophily in Social Media via Inverse Reinforcement Learning: A Reddit Case Study 
[[arxiv](https://arxiv.org/abs/2502.02943)] [[cool](https://papers.cool/arxiv/2502.02943)] [[pdf](https://arxiv.org/pdf/2502.02943)]
> **Authors**: Lanqin Yuan,Philipp J. Schneider,Marian-Andrei Rizoiu
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 社交和信息网络,机器学习
- **Abstract**: Online communities play a critical role in shaping societal discourse and influencing collective behavior in the real world. The tendency for people to connect with others who share similar characteristics and views, known as homophily, plays a key role in the formation of echo chambers which further amplify polarization and division. Existing works examining homophily in online communities traditionally infer it using content- or adjacency-based approaches, such as constructing explicit interaction networks or performing topic analysis. These methods fall short for platforms where interaction networks cannot be easily constructed and fail to capture the complex nature of user interactions across the platform. This work introduces a novel approach for quantifying user homophily. We first use an Inverse Reinforcement Learning (IRL) framework to infer users' policies, then use these policies as a measure of behavioral homophily. We apply our method to Reddit, conducting a case study across 5.9 million interactions over six years, demonstrating how this approach uncovers distinct behavioral patterns and user roles that vary across different communities. We further validate our behavioral homophily measure against traditional content-based homophily, offering a powerful method for analyzing social media dynamics and their broader societal implications. We find, among others, that users can behave very similarly (high behavioral homophily) when discussing entirely different topics like soccer vs e-sports (low topical homophily), and that there is an entire class of users on Reddit whose purpose seems to be to disagree with others.

## 音频和语音处理(eess.AS:Audio and Speech Processing)

### Dementia Classification Using Acoustic Speech and Feature Selection 
[[arxiv](https://arxiv.org/abs/2502.03484)] [[cool](https://papers.cool/arxiv/2502.03484)] [[pdf](https://arxiv.org/pdf/2502.03484)]
> **Authors**: Marko Niemelä,Mikaela von Bonsdorff,Sami Äyrämö,Tommi Kärkkäinen
> **First submission**: 2025-02-04
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 音频和语音处理,机器学习,声音
- **Abstract**: Dementia is a general term for a group of syndromes that affect cognitive functions such as memory, thinking, reasoning, and the ability to perform daily tasks. The number of dementia patients is increasing as the population ages, and it is estimated that over 10 million people develop dementia each year. Dementia progresses gradually, and the sooner a patient receives help and support, the better their chances of maintaining their functional abilities. For this reason, early diagnosis of dementia is important. In recent years, machine learning models based on naturally spoken language have been developed for the early diagnosis of dementia. These methods have proven to be user-friendly, cost-effective, scalable, and capable of providing extremely fast diagnoses. This study utilizes the well-known ADReSS challenge dataset for classifying healthy controls and Alzheimer's patients. The dataset contains speech recordings from a picture description task featuring a kitchen scene, collected from both healthy controls and dementia patients. Unlike most studies, this research does not segment the audio recordings into active speech segments; instead, acoustic features are extracted from entire recordings. The study employs Ridge linear regression, Extreme Minimal Learning Machine, and Linear Support Vector Machine machine learning models to compute feature importance scores based on model outputs. The Ridge model performed best in Leave-One-Subject-Out cross-validation, achieving a classification accuracy of 87.8%. The EMLM model, proved to be effective in both cross-validation and the classification of a separate test dataset, with accuracies of 85.3% and 79.2%, respectively. The study's results rank among the top compared to other studies using the same dataset and acoustic feature extraction for dementia diagnosis.

## 图像和视频处理(eess.IV:Image and Video Processing)

### Enhancing Free-hand 3D Photoacoustic and Ultrasound Reconstruction using Deep Learning 
[[arxiv](https://arxiv.org/abs/2502.03505)] [[cool](https://papers.cool/arxiv/2502.03505)] [[pdf](https://arxiv.org/pdf/2502.03505)]
> **Authors**: SiYeoul Lee,SeonHo Kim,Minkyung Seo,SeongKyu Park,Salehin Imrus,Kambaluru Ashok,DongEon Lee,Chunsu Park,SeonYeong Lee,Jiye Kim,Jae-Heung Yoo,MinWoo Kim
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 图像和视频处理,人工智能,机器学习
- **Abstract**: This study introduces a motion-based learning network with a global-local self-attention module (MoGLo-Net) to enhance 3D reconstruction in handheld photoacoustic and ultrasound (PAUS) imaging. Standard PAUS imaging is often limited by a narrow field of view and the inability to effectively visualize complex 3D structures. The 3D freehand technique, which aligns sequential 2D images for 3D reconstruction, faces significant challenges in accurate motion estimation without relying on external positional sensors. MoGLo-Net addresses these limitations through an innovative adaptation of the self-attention mechanism, which effectively exploits the critical regions, such as fully-developed speckle area or high-echogenic tissue area within successive ultrasound images to accurately estimate motion parameters. This facilitates the extraction of intricate features from individual frames. Additionally, we designed a patch-wise correlation operation to generate a correlation volume that is highly correlated with the scanning motion. A custom loss function was also developed to ensure robust learning with minimized bias, leveraging the characteristics of the motion parameters. Experimental evaluations demonstrated that MoGLo-Net surpasses current state-of-the-art methods in both quantitative and qualitative performance metrics. Furthermore, we expanded the application of 3D reconstruction technology beyond simple B-mode ultrasound volumes to incorporate Doppler ultrasound and photoacoustic imaging, enabling 3D visualization of vasculature. The source code for this study is publicly available at: https://github.com/guhong3648/US3D

### Proxy Prompt: Endowing SAM and SAM 2 with Auto-Interactive-Prompt for Medical Segmentation 
[[arxiv](https://arxiv.org/abs/2502.03501)] [[cool](https://papers.cool/arxiv/2502.03501)] [[pdf](https://arxiv.org/pdf/2502.03501)]
> **Authors**: Wang Xinyi,Kang Hongyu,Wei Peishan,Shuai Li,Yu Sun,Sai Kit Lam,Yongping Zheng
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 图像和视频处理,机器学习
- **Abstract**: In this paper, we aim to address the unmet demand for automated prompting and enhanced human-model interactions of SAM and SAM2 for the sake of promoting their widespread clinical adoption. Specifically, we propose Proxy Prompt (PP), auto-generated by leveraging non-target data with a pre-annotated mask. We devise a novel 3-step context-selection strategy for adaptively selecting the most representative contextual information from non-target data via vision mamba and selective maps, empowering the guiding capability of non-target image-mask pairs for segmentation on target image/video data. To reinforce human-model interactions in PP, we further propose a contextual colorization module via a dual-reverse cross-attention to enhance interactions between target features and contextual-embedding with amplifying distinctive features of user-defined object(s). Via extensive evaluations, our method achieves state-of-the-art performance on four public datasets and yields comparable results with fully-trained models, even when trained with only 16 image masks.

### MetaFE-DE: Learning Meta Feature Embedding for Depth Estimation from Monocular Endoscopic Images 
[[arxiv](https://arxiv.org/abs/2502.03493)] [[cool](https://papers.cool/arxiv/2502.03493)] [[pdf](https://arxiv.org/pdf/2502.03493)]
> **Authors**: Dawei Lu,Deqiang Xiao,Danni Ai,Jingfan Fan,Tianyu Fu,Yucong Lin,Hong Song,Xujiong Ye,Lei Zhang,Jian Yang
> **First submission**: 2025-02-04
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 图像和视频处理,计算机视觉和模式识别
- **Abstract**: Depth estimation from monocular endoscopic images presents significant challenges due to the complexity of endoscopic surgery, such as irregular shapes of human soft tissues, as well as variations in lighting conditions. Existing methods primarily estimate the depth information from RGB images directly, and often surffer the limited interpretability and accuracy. Given that RGB and depth images are two views of the same endoscopic surgery scene, in this paper, we introduce a novel concept referred as ``meta feature embedding (MetaFE)", in which the physical entities (e.g., tissues and surgical instruments) of endoscopic surgery are represented using the shared features that can be alternatively decoded into RGB or depth image. With this concept, we propose a two-stage self-supervised learning paradigm for the monocular endoscopic depth estimation. In the first stage, we propose a temporal representation learner using diffusion models, which are aligned with the spatial information through the cross normalization to construct the MetaFE. In the second stage, self-supervised monocular depth estimation with the brightness calibration is applied to decode the meta features into the depth image. Extensive evaluation on diverse endoscopic datasets demonstrates that our approach outperforms the state-of-the-art method in depth estimation, achieving superior accuracy and generalization. The source code will be publicly available.

### Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis 
[[arxiv](https://arxiv.org/abs/2502.03482)] [[cool](https://papers.cool/arxiv/2502.03482)] [[pdf](https://arxiv.org/pdf/2502.03482)]
> **Authors**: Chacha Chen,Han Liu,Jiamin Yang,Benjamin M. Mervak,Bora Kalaycioglu,Grace Lee,Emre Cakmakli,Matteo Bonatti,Sridhar Pudu,Osman Kahraman,Gul Gizem Pamuk,Aytekin Oto,Aritrick Chatterjee,Chenhao Tan
> **First submission**: 2025-02-03
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 图像和视频处理,人工智能,计算机视觉和模式识别,计算机与社会,人机交互,机器学习
- **Abstract**: Despite the growing interest in human-AI decision making, experimental studies with domain experts remain rare, largely due to the complexity of working with domain experts and the challenges in setting up realistic experiments. In this work, we conduct an in-depth collaboration with radiologists in prostate cancer diagnosis based on MRI images. Building on existing tools for teaching prostate cancer diagnosis, we develop an interface and conduct two experiments to study how AI assistance and performance feedback shape the decision making of domain experts. In Study 1, clinicians were asked to provide an initial diagnosis (human), then view the AI's prediction, and subsequently finalize their decision (human-AI team). In Study 2 (after a memory wash-out period), the same participants first received aggregated performance statistics from Study 1, specifically their own performance, the AI's performance, and their human-AI team performance, and then directly viewed the AI's prediction before making their diagnosis (i.e., no independent initial diagnosis). These two workflows represent realistic ways that clinical AI tools might be used in practice, where the second study simulates a scenario where doctors can adjust their reliance and trust on AI based on prior performance feedback. Our findings show that, while human-AI teams consistently outperform humans alone, they still underperform the AI due to under-reliance, similar to prior studies with crowdworkers. Providing clinicians with performance feedback did not significantly improve the performance of human-AI teams, although showing AI decisions in advance nudges people to follow AI more. Meanwhile, we observe that the ensemble of human-AI teams can outperform AI alone, suggesting promising directions for human-AI collaboration.

### A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT Radiotherapy Planning 
[[arxiv](https://arxiv.org/abs/2502.03360)] [[cool](https://papers.cool/arxiv/2502.03360)] [[pdf](https://arxiv.org/pdf/2502.03360)]
> **Authors**: Simon Arberet,Florin C. Ghesu,Riqiang Gao,Martin Kraus,Jonathan Sackett,Esa Kuusela,Ali Kamen
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 图像和视频处理,人工智能,医学物理
- **Abstract**: Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment by precisely delivering radiation while sparing healthy tissues. Fluence maps generation, crucial in VMAT planning, traditionally involves complex and iterative, and thus time consuming processes. These fluence maps are subsequently leveraged for leaf-sequence. The deep-learning approach presented in this article aims to expedite this by directly predicting fluence maps from patient data. We developed a 3D network which we trained in a supervised way using a combination of L1 and L2 losses, and RT plans generated by Eclipse and from the REQUITE dataset, taking the RT dose map as input and the fluence maps computed from the corresponding RT plans as target. Our network predicts jointly the 180 fluence maps corresponding to the 180 control points (CP) of single arc VMAT plans. In order to help the network, we pre-process the input dose by computing the projections of the 3D dose map to the beam's eye view (BEV) of the 180 CPs, in the same coordinate system as the fluence maps. We generated over 2000 VMAT plans using Eclipse to scale up the dataset size. Additionally, we evaluated various network architectures and analyzed the impact of increasing the dataset size. We are measuring the performance in the 2D fluence maps domain using image metrics (PSNR, SSIM), as well as in the 3D dose domain using the dose-volume histogram (DVH) on a validation dataset. The network inference, which does not include the data loading and processing, is less than 20ms. Using our proposed 3D network architecture as well as increasing the dataset size using Eclipse improved the fluence map reconstruction performance by approximately 8 dB in PSNR compared to a U-Net architecture trained on the original REQUITE dataset. The resulting DVHs are very close to the one of the input target dose.

### Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans 
[[arxiv](https://arxiv.org/abs/2502.03272)] [[cool](https://papers.cool/arxiv/2502.03272)] [[pdf](https://arxiv.org/pdf/2502.03272)]
> **Authors**: Matthias Schwab,Mathias Pamminger,Christian Kremser,Agnes Mayr
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 图像和视频处理,人工智能,计算机视觉和模式识别
- **Abstract**: Purpose: To develop and evaluate a deep learning-based method that allows to perform myocardial infarct segmentation in a fully-automated way. Materials and Methods: For this retrospective study, a cascaded framework of two and three-dimensional convolutional neural networks (CNNs), specialized on identifying ischemic myocardial scars on late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) images, was trained on an in-house training dataset consisting of 144 examinations. On a separate test dataset from the same institution, including images from 152 examinations obtained between 2021 and 2023, a quantitative comparison between artificial intelligence (AI)-based segmentations and manual segmentations was performed. Further, qualitative assessment of segmentation accuracy was evaluated for both human and AI-generated contours by two CMR experts in a blinded experiment. Results: Excellent agreement could be found between manually and automatically calculated infarct volumes ($ρ_c$ = 0.9). The qualitative evaluation showed that compared to human-based measurements, the experts rated the AI-based segmentations to better represent the actual extent of infarction significantly (p < 0.001) more often (33.4% AI, 25.1% human, 41.5% equal). On the contrary, for segmentation of microvascular obstruction (MVO), manual measurements were still preferred (11.3% AI, 55.6% human, 33.1% equal). Conclusion: This fully-automated segmentation pipeline enables CMR infarct size to be calculated in a very short time and without requiring any pre-processing of the input images while matching the segmentation quality of trained human observers. In a blinded experiment, experts preferred automated infarct segmentations more often than manual segmentations, paving the way for a potential clinical application.

## 系统与控制(eess.SY:Systems and Control)

### Deep Reinforcement Learning-Based Optimization of Second-Life Battery Utilization in Electric Vehicles Charging Stations 
[[arxiv](https://arxiv.org/abs/2502.03412)] [[cool](https://papers.cool/arxiv/2502.03412)] [[pdf](https://arxiv.org/pdf/2502.03412)]
> **Authors**: Rouzbeh Haghighi,Ali Hassan,Van-Hai Bui,Akhtar Hussain,Wencong Su
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 5 pages, 6 figures, Accepted, 2025 IEEE Power and Energy Society General Meeting (PESGM 2025), Austin, TX, USA
- **标题**: None
- **领域**: 系统与控制,机器学习
- **Abstract**: The rapid rise in electric vehicle (EV) adoption presents significant challenges in managing the vast number of retired EV batteries. Research indicates that second-life batteries (SLBs) from EVs typically retain considerable residual capacity, offering extended utility. These batteries can be effectively repurposed for use in EV charging stations (EVCS), providing a cost-effective alternative to new batteries and reducing overall planning costs. Integrating battery energy storage systems (BESS) with SLBs into EVCS is a promising strategy to alleviate system overload. However, efficient operation of EVCS with integrated BESS is hindered by uncertainties such as fluctuating EV arrival and departure times and variable power prices from the grid. This paper presents a deep reinforcement learning-based (DRL) planning framework for EV charging stations with BESS, leveraging SLBs. We employ the advanced soft actor-critic (SAC) approach, training the model on a year's worth of data to account for seasonal variations, including weekdays and holidays. A tailored reward function enables effective offline training, allowing real-time optimization of EVCS operations under uncertainty.

### Optimizing Electric Vehicles Charging using Large Language Models and Graph Neural Networks 
[[arxiv](https://arxiv.org/abs/2502.03067)] [[cool](https://papers.cool/arxiv/2502.03067)] [[pdf](https://arxiv.org/pdf/2502.03067)]
> **Authors**: Stavros Orfanoudakis,Peter Palensky,Pedro P. Vergara
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 系统与控制,机器学习
- **Abstract**: Maintaining grid stability amid widespread electric vehicle (EV) adoption is vital for sustainable transportation. Traditional optimization methods and Reinforcement Learning (RL) approaches often struggle with the high dimensionality and dynamic nature of real-time EV charging, leading to sub-optimal solutions. To address these challenges, this study demonstrates that combining Large Language Models (LLMs), for sequence modeling, with Graph Neural Networks (GNNs), for relational information extraction, not only outperforms conventional EV smart charging methods, but also paves the way for entirely new research directions and innovative solutions.

## 经典分析和常微分方程(math.CA:Classical Analysis and ODEs)

### Signature Reconstruction from Randomized Signatures 
[[arxiv](https://arxiv.org/abs/2502.03163)] [[cool](https://papers.cool/arxiv/2502.03163)] [[pdf](https://arxiv.org/pdf/2502.03163)]
> **Authors**: Mie Glückstad,Nicola Muca Cirone,Josef Teichmann
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 37 pages, 7 figures
- **标题**: None
- **领域**: 经典分析和常微分方程,机器学习,可能性,机器学习
- **Abstract**: Controlled ordinary differential equations driven by continuous bounded variation curves can be considered a continuous time analogue of recurrent neural networks for the construction of expressive features of the input curves. We ask up to which extent well known signature features of such curves can be reconstructed from controlled ordinary differential equations with (untrained) random vector fields. The answer turns out to be algebraically involved, but essentially the number of signature features, which can be reconstructed from the non-linear flow of the controlled ordinary differential equation, is exponential in its hidden dimension, when the vector fields are chosen to be neural with depth two. Moreover, we characterize a general linear independence condition on arbitrary vector fields, under which the signature features up to some fixed order can always be reconstructed. Algebraically speaking this complements in a quantitative manner several well known results from the theory of Lie algebras of vector fields and puts them in a context of machine learning.

## 数值分析(math.NA:Numerical Analysis)

### An Augmented Backward-Corrected Projector Splitting Integrator for Dynamical Low-Rank Training 
[[arxiv](https://arxiv.org/abs/2502.03006)] [[cool](https://papers.cool/arxiv/2502.03006)] [[pdf](https://arxiv.org/pdf/2502.03006)]
> **Authors**: Jonas Kusch,Steffen Schotthöfer,Alexandra Walter
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 数值分析,机器学习
- **Abstract**: Layer factorization has emerged as a widely used technique for training memory-efficient neural networks. However, layer factorization methods face several challenges, particularly a lack of robustness during the training process. To overcome this limitation, dynamical low-rank training methods have been developed, utilizing robust time integration techniques for low-rank matrix differential equations. Although these approaches facilitate efficient training, they still depend on computationally intensive QR and singular value decompositions of matrices with small rank. In this work, we introduce a novel low-rank training method that reduces the number of required QR decompositions. Our approach integrates an augmentation step into a projector-splitting scheme, ensuring convergence to a locally optimal solution. We provide a rigorous theoretical analysis of the proposed method and demonstrate its effectiveness across multiple benchmarks.

## 优化与控制(math.OC:Optimization and Control)

### First-ish Order Methods: Hessian-aware Scalings of Gradient Descent 
[[arxiv](https://arxiv.org/abs/2502.03701)] [[cool](https://papers.cool/arxiv/2502.03701)] [[pdf](https://arxiv.org/pdf/2502.03701)]
> **Authors**: Oscar Smee,Fred Roosta,Stephen J. Wright
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: :49
- **标题**: None
- **领域**: 优化与控制,机器学习
- **Abstract**: Gradient descent is the primary workhorse for optimizing large-scale problems in machine learning. However, its performance is highly sensitive to the choice of the learning rate. A key limitation of gradient descent is its lack of natural scaling, which often necessitates expensive line searches or heuristic tuning to determine an appropriate step size. In this paper, we address this limitation by incorporating Hessian information to scale the gradient direction. By accounting for the curvature of the function along the gradient, our adaptive, Hessian-aware scaling method ensures a local unit step size guarantee, even in nonconvex settings. Near a local minimum that satisfies the second-order sufficient conditions, our approach achieves linear convergence with a unit step size. We show that our method converges globally under a significantly weaker version of the standard Lipschitz gradient smoothness assumption. Even when Hessian information is inexact, the local unit step size guarantee and global convergence properties remain valid under mild conditions. Finally, we validate our theoretical results empirically on a range of convex and nonconvex machine learning tasks, showcasing the effectiveness of the approach.

### An analysis of optimization problems involving ReLU neural networks 
[[arxiv](https://arxiv.org/abs/2502.03016)] [[cool](https://papers.cool/arxiv/2502.03016)] [[pdf](https://arxiv.org/pdf/2502.03016)]
> **Authors**: Christoph Plate,Mirko Hahn,Alexander Klimek,Caroline Ganzer,Kai Sundmacher,Sebastian Sager
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 优化与控制,机器学习
- **Abstract**: Solving mixed-integer optimization problems with embedded neural networks with ReLU activation functions is challenging. Big-M coefficients that arise in relaxing binary decisions related to these functions grow exponentially with the number of layers. We survey and propose different approaches to analyze and improve the run time behavior of mixed-integer programming solvers in this context. Among them are clipped variants and regularization techniques applied during training as well as optimization-based bound tightening and a novel scaling for given ReLU networks. We numerically compare these approaches for three benchmark problems from the literature. We use the number of linear regions, the percentage of stable neurons, and overall computational effort as indicators. As a major takeaway we observe and quantify a trade-off between the often desired redundancy of neural network models versus the computational costs for solving related optimization problems.

## 计算物理(physics.comp-ph:Computational Physics)

### Physically consistent predictive reduced-order modeling by enhancing Operator Inference with state constraints 
[[arxiv](https://arxiv.org/abs/2502.03672)] [[cool](https://papers.cool/arxiv/2502.03672)] [[pdf](https://arxiv.org/pdf/2502.03672)]
> **Authors**: Hyeonghun Kim,Boris Kramer
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 27 pages, 10 figures
- **标题**: None
- **领域**: 计算物理,机器学习,数值分析
- **Abstract**: Numerical simulations of complex multiphysics systems, such as char combustion considered herein, yield numerous state variables that inherently exhibit physical constraints. This paper presents a new approach to augment Operator Inference -- a methodology within scientific machine learning that enables learning from data a low-dimensional representation of a high-dimensional system governed by nonlinear partial differential equations -- by embedding such state constraints in the reduced-order model predictions. In the model learning process, we propose a new way to choose regularization hyperparameters based on a key performance indicator. Since embedding state constraints improves the stability of the Operator Inference reduced-order model, we compare the proposed state constraints-embedded Operator Inference with the standard Operator Inference and other stability-enhancing approaches. For an application to char combustion, we demonstrate that the proposed approach yields state predictions superior to the other methods regarding stability and accuracy. It extrapolates over 200\% past the training regime while being computationally efficient and physically consistent.

## 光学(physics.optics:Optics)

### A Bayesian perspective on single-shot laser characterization 
[[arxiv](https://arxiv.org/abs/2502.03100)] [[cool](https://papers.cool/arxiv/2502.03100)] [[pdf](https://arxiv.org/pdf/2502.03100)]
> **Authors**: J. Esslinger,N. Weisse,C. Eberle,J. Schroeder,S. Howard,P. Norreys,S. Karsch,A. Döpp
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 光学,机器学习,仪器仪表和探测器
- **Abstract**: We introduce a Bayesian framework for measuring spatio-temporal couplings (STCs) in ultra-intense lasers that reconceptualizes what constitutes a 'single-shot' measurement. Moving beyond traditional distinctions between single- and multi-shot devices, our approach provides rigorous criteria for determining when measurements can truly resolve individual laser shots rather than statistical averages. This framework shows that single-shot capability is not an intrinsic device property but emerges from the relationship between measurement precision and inherent parameter variability. Implementing this approach with a new measurement device at the ATLAS-3000 petawatt laser, we provide the first quantitative uncertainty bounds on pulse front tilt and curvature. Notably, we observe that our Bayesian method reduces uncertainty by up to 60% compared to traditional approaches. Through this analysis, we reveal how the interplay between measurement precision and intrinsic system variability defines achievable resolution -- insights that have direct implications for applications where precise control of laser-matter interaction is critical.

## 基因组学(q-bio.GN:Genomics)

### Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning 
[[arxiv](https://arxiv.org/abs/2502.03499)] [[cool](https://papers.cool/arxiv/2502.03499)] [[pdf](https://arxiv.org/pdf/2502.03499)]
> **Authors**: Zehui Li,Vallijah Subasri,Yifei Shen,Dongsheng Li,Yiren Zhao,Guy-Bart Stan,Caihua Shan
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 基因组学,人工智能,机器学习
- **Abstract**: Large Language Models (LLMs) demonstrate remarkable generalizability across diverse tasks, yet genomic foundation models (GFMs) still require separate finetuning for each downstream application, creating significant overhead as model sizes grow. Moreover, existing GFMs are constrained by rigid output formats, limiting their applicability to various genomic tasks. In this work, we revisit the transformer-based auto-regressive models and introduce Omni-DNA, a family of cross-modal multi-task models ranging from 20 million to 1 billion parameters. Our approach consists of two stages: (i) pretraining on DNA sequences with next token prediction objective, and (ii) expanding the multi-modal task-specific tokens and finetuning for multiple downstream tasks simultaneously. When evaluated on the Nucleotide Transformer and GB benchmarks, Omni-DNA achieves state-of-the-art performance on 18 out of 26 tasks. Through multi-task finetuning, Omni-DNA addresses 10 acetylation and methylation tasks at once, surpassing models trained on each task individually. Finally, we design two complex genomic tasks, DNA2Function and Needle-in-DNA, which map DNA sequences to textual functional descriptions and images, respectively, indicating Omni-DNA's cross-modal capabilities to broaden the scope of genomic applications. All the models are available through https://huggingface.co/collections/zehui127

## 神经元和认知(q-bio.NC:Neurons and Cognition)

### Immersion for AI: Immersive Learning with Artificial Intelligence 
[[arxiv](https://arxiv.org/abs/2502.03504)] [[cool](https://papers.cool/arxiv/2502.03504)] [[pdf](https://arxiv.org/pdf/2502.03504)]
> **Authors**: Leonel Morgado
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: 16 pages. To be published in the Proceedings of the 11th Annual International Conference of the ImmersiveLearningResearchNetwork(iLRN2025)
- **标题**: None
- **领域**: 神经元和认知,人工智能,人机交互
- **Abstract**: This work reflects upon what Immersion can mean from the perspective of an Artificial Intelligence (AI). Applying the lens of immersive learning theory, it seeks to understand whether this new perspective supports ways for AI participation in cognitive ecologies. By treating AI as a participant rather than a tool, it explores what other participants (humans and other AIs) need to consider in environments where AI can meaningfully engage and contribute to the cognitive ecology, and what the implications are for designing such learning environments. Drawing from the three conceptual dimensions of immersion - System, Narrative, and Agency - this work reinterprets AIs in immersive learning contexts. It outlines practical implications for designing learning environments where AIs are surrounded by external digital services, can interpret a narrative of origins, changes, and structural developments in data, and dynamically respond, making operational and tactical decisions that shape human-AI collaboration. Finally, this work suggests how these insights might influence the future of AI training, proposing that immersive learning theory can inform the development of AIs capable of evolving beyond static models. This paper paves the way for understanding AI as an immersive learner and participant in evolving human-AI cognitive ecosystems.

### SimSort: A Powerful Framework for Spike Sorting by Large-Scale Electrophysiology Simulation 
[[arxiv](https://arxiv.org/abs/2502.03198)] [[cool](https://papers.cool/arxiv/2502.03198)] [[pdf](https://arxiv.org/pdf/2502.03198)]
> **Authors**: Yimu Zhang,Dongqi Han,Yansen Wang,Yu Gu,Dongsheng Li
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 神经元和认知,机器学习
- **Abstract**: Spike sorting is an essential process in neural recording, which identifies and separates electrical signals from individual neurons recorded by electrodes in the brain, enabling researchers to study how specific neurons communicate and process information. Although there exist a number of spike sorting methods which have contributed to significant neuroscientific breakthroughs, many are heuristically designed, making it challenging to verify their correctness due to the difficulty of obtaining ground truth labels from real-world neural recordings. In this work, we explore a data-driven, deep learning-based approach. We begin by creating a large-scale dataset through electrophysiology simulations using biologically realistic computational models. We then present \textbf{SimSort}, a pretraining framework for spike sorting. Remarkably, when trained on our simulated dataset, SimSort demonstrates strong zero-shot generalization to real-world spike sorting tasks, significantly outperforming existing methods. Our findings underscore the potential of data-driven techniques to enhance the reliability and scalability of spike sorting in experimental neuroscience.

## 应用领域(stat.AP:Applications)

### Foundation for unbiased cross-validation of spatio-temporal models for species distribution modeling 
[[arxiv](https://arxiv.org/abs/2502.03480)] [[cool](https://papers.cool/arxiv/2502.03480)] [[pdf](https://arxiv.org/pdf/2502.03480)]
> **Authors**: Diana Koldasbayeva,Alexey Zaytsev
> **First submission**: 2025-01-27
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 应用领域,机器学习
- **Abstract**: Species Distribution Models (SDMs) often suffer from spatial autocorrelation (SAC), leading to biased performance estimates. We tested cross-validation (CV) strategies - random splits, spatial blocking with varied distances, environmental (ENV) clustering, and a novel spatio-temporal method - under two proposed training schemes: LAST FOLD, widely used in spatial CV at the cost of data loss, and RETRAIN, which maximizes data usage but risks reintroducing SAC. LAST FOLD consistently yielded lower errors and stronger correlations. Spatial blocking at an optimal distance (SP 422) and ENV performed best, achieving Spearman and Pearson correlations of 0.485 and 0.548, respectively, although ENV may be unsuitable for long-term forecasts involving major environmental shifts. A spatio-temporal approach yielded modest benefits in our moderately variable dataset, but may excel with stronger temporal changes. These findings highlight the need to align CV approaches with the spatial and temporal structure of SDM data, ensuring rigorous validation and reliable predictive outcomes.

## 方法论(stat.ME:Methodology)

### Data denoising with self consistency, variance maximization, and the Kantorovich dominance 
[[arxiv](https://arxiv.org/abs/2502.02925)] [[cool](https://papers.cool/arxiv/2502.02925)] [[pdf](https://arxiv.org/pdf/2502.02925)]
> **Authors**: Joshua Zoen-Git Hiew,Tongseok Lim,Brendan Pass,Marcelo Cruz de Souza
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 方法论,机器学习,可能性,统计理论
- **Abstract**: We introduce a new framework for data denoising, partially inspired by martingale optimal transport. For a given noisy distribution (the data), our approach involves finding the closest distribution to it among all distributions which 1) have a particular prescribed structure (expressed by requiring they lie in a particular domain), and 2) are self-consistent with the data. We show that this amounts to maximizing the variance among measures in the domain which are dominated in convex order by the data. For particular choices of the domain, this problem and a relaxed version of it, in which the self-consistency condition is removed, are intimately related to various classical approaches to denoising. We prove that our general problem has certain desirable features: solutions exist under mild assumptions, have certain robustness properties, and, for very simple domains, coincide with solutions to the relaxed problem. We also introduce a novel relationship between distributions, termed Kantorovich dominance, which retains certain aspects of the convex order while being a weaker, more robust, and easier-to-verify condition. Building on this, we propose and analyze a new denoising problem by substituting the convex order in the previously described framework with Kantorovich dominance. We demonstrate that this revised problem shares some characteristics with the full convex order problem but offers enhanced stability, greater computational efficiency, and, in specific domains, more meaningful solutions. Finally, we present simple numerical examples illustrating solutions for both the full convex order problem and the Kantorovich dominance problem.

## 机器学习(stat.ML:Machine Learning)

### Rule-based Evolving Fuzzy System for Time Series Forecasting: New Perspectives Based on Type-2 Fuzzy Sets Measures Approach 
[[arxiv](https://arxiv.org/abs/2502.03650)] [[cool](https://papers.cool/arxiv/2502.03650)] [[pdf](https://arxiv.org/pdf/2502.03650)]
> **Authors**: Eduardo Santos de Oliveira Marques,Arthur Caio Vargas Pinto,Kaike Sa Teles Rocha Alves,Eduardo Pestana de Aguiar
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Real-world data contain uncertainty and variations that can be correlated to external variables, known as randomness. An alternative cause of randomness is chaos, which can be an important component of chaotic time series. One of the existing methods to deal with this type of data is the use of the evolving Fuzzy Systems (eFSs), which have been proven to be a powerful class of models for time series forecasting, due to their autonomy to handle the data and highly complex problems in real-world applications. However, due to its working structure, type-2 fuzzy sets can outperform type-1 fuzzy sets for highly uncertain scenarios. We then propose ePL-KRLS-FSM+, an enhanced class of evolving fuzzy modeling approach that combines participatory learning (PL), a kernel recursive least squares method (KRLS), type-2 fuzzy logic and data transformation into fuzzy sets (FSs). This improvement allows to create and measure type-2 fuzzy sets for better handling uncertainties in the data, generating a model that can predict chaotic data with increased accuracy. The model is evaluated using two complex datasets: the chaotic time series Mackey-Glass delay differential equation with different degrees of chaos, and the main stock index of the Taiwan Capitalization Weighted Stock Index - TAIEX. Model performance is compared to related state-of-the-art rule-based eFS models and classical approaches and is analyzed in terms of error metrics, runtime and the number of final rules. Forecasting results show that the proposed model is competitive and performs consistently compared with type-1 models, also outperforming other forecasting methods by showing the lowest error metrics and number of final rules.

### Multivariate Conformal Prediction using Optimal Transport 
[[arxiv](https://arxiv.org/abs/2502.03609)] [[cool](https://papers.cool/arxiv/2502.03609)] [[pdf](https://arxiv.org/pdf/2502.03609)]
> **Authors**: Michal Klein,Louis Bethune,Eugene Ndiaye,Marco Cuturi
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Conformal prediction (CP) quantifies the uncertainty of machine learning models by constructing sets of plausible outputs. These sets are constructed by leveraging a so-called conformity score, a quantity computed using the input point of interest, a prediction model, and past observations. CP sets are then obtained by evaluating the conformity score of all possible outputs, and selecting them according to the rank of their scores. Due to this ranking step, most CP approaches rely on a score functions that are univariate. The challenge in extending these scores to multivariate spaces lies in the fact that no canonical order for vectors exists. To address this, we leverage a natural extension of multivariate score ranking based on optimal transport (OT). Our method, OTCP, offers a principled framework for constructing conformal prediction sets in multidimensional settings, preserving distribution-free coverage guarantees with finite data samples. We demonstrate tangible gains in a benchmark dataset of multivariate regression problems and address computational \& statistical trade-offs that arise when estimating conformity scores through OT maps.

### Online Learning Algorithms in Hilbert Spaces with $β-$ and $φ-$Mixing Sequences 
[[arxiv](https://arxiv.org/abs/2502.03551)] [[cool](https://papers.cool/arxiv/2502.03551)] [[pdf](https://arxiv.org/pdf/2502.03551)]
> **Authors**: Priyanka Roy,Susanne Saminger-Platz
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: :60J20; 68T05; 68Q32; 62L20
- **标题**: None
- **领域**: 机器学习,机器学习,泛函分析
- **Abstract**: In this paper, we study an online algorithm in a reproducing kernel Hilbert spaces (RKHS) based on a class of dependent processes, called the mixing process. For such a process, the degree of dependence is measured by various mixing coefficients. As a representative example, we analyze a strictly stationary Markov chain, where the dependence structure is characterized by the \(β-\) and \(φ-\)mixing coefficients. For these dependent samples, we derive nearly optimal convergence rates. Our findings extend existing error bounds for i.i.d. observations, demonstrating that the i.i.d. case is a special instance of our framework. Moreover, we explicitly account for an additional factor introduced by the dependence structure in the Markov chain.

### Two in context learning tasks with complex functions 
[[arxiv](https://arxiv.org/abs/2502.03503)] [[cool](https://papers.cool/arxiv/2502.03503)] [[pdf](https://arxiv.org/pdf/2502.03503)]
> **Authors**: Omar Naim,Nicholas Asher
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,机器学习
- **Abstract**: We examine two in context learning (ICL) tasks with mathematical functions in several train and test settings for transformer models. Our study generalizes work on linear functions by showing that small transformers, even models with attention layers only, can approximate arbitrary polynomial functions and hence continuous functions under certain conditions. Our models also can approximate previously unseen classes of polynomial functions, as well as the zeros of complex functions. Our models perform far better on this task than LLMs like GPT4 and involve complex reasoning when provided with suitable training data and methods. Our models also have important limitations; they fail to generalize outside of training distributions and so don't learn class forms of functions. We explain why this is so.

### Linearized Optimal Transport pyLOT Library: A Toolkit for Machine Learning on Point Clouds 
[[arxiv](https://arxiv.org/abs/2502.03439)] [[cool](https://papers.cool/arxiv/2502.03439)] [[pdf](https://arxiv.org/pdf/2502.03439)]
> **Authors**: Jun Linwu,Varun Khurana,Nicholas Karris,Alexander Cloninger
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习,数学软件,计算
- **Abstract**: The pyLOT library offers a Python implementation of linearized optimal transport (LOT) techniques and methods to use in downstream tasks. The pipeline embeds probability distributions into a Hilbert space via the Optimal Transport maps from a fixed reference distribution, and this linearization allows downstream tasks to be completed using off the shelf (linear) machine learning algorithms. We provide a case study of performing ML on 3D scans of lemur teeth, where the original questions of classification, clustering, dimension reduction, and data generation reduce to simple linear operations performed on the LOT embedded representations.

### Taking a Big Step: Large Learning Rates in Denoising Score Matching Prevent Memorization 
[[arxiv](https://arxiv.org/abs/2502.03435)] [[cool](https://papers.cool/arxiv/2502.03435)] [[pdf](https://arxiv.org/pdf/2502.03435)]
> **Authors**: Yu-Han Wu,Pierre Marion,Gérard Biau,Claire Boyer
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Denoising score matching plays a pivotal role in the performance of diffusion-based generative models. However, the empirical optimal score--the exact solution to the denoising score matching--leads to memorization, where generated samples replicate the training data. Yet, in practice, only a moderate degree of memorization is observed, even without explicit regularization. In this paper, we investigate this phenomenon by uncovering an implicit regularization mechanism driven by large learning rates. Specifically, we show that in the small-noise regime, the empirical optimal score exhibits high irregularity. We then prove that, when trained by stochastic gradient descent with a large enough learning rate, neural networks cannot stably converge to a local minimum with arbitrarily small excess risk. Consequently, the learned score cannot be arbitrarily close to the empirical optimal score, thereby mitigating memorization. To make the analysis tractable, we consider one-dimensional data and two-layer neural networks. Experiments validate the crucial role of the learning rate in preventing memorization, even beyond the one-dimensional setting.

### Optimal Task Order for Continual Learning of Multiple Tasks 
[[arxiv](https://arxiv.org/abs/2502.03350)] [[cool](https://papers.cool/arxiv/2502.03350)] [[pdf](https://arxiv.org/pdf/2502.03350)]
> **Authors**: Ziyan Li,Naoki Hiratani
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Continual learning of multiple tasks remains a major challenge for neural networks. Here, we investigate how task order influences continual learning and propose a strategy for optimizing it. Leveraging a linear teacher-student model with latent factors, we derive an analytical expression relating task similarity and ordering to learning performance. Our analysis reveals two principles that hold under a wide parameter range: (1) tasks should be arranged from the least representative to the most typical, and (2) adjacent tasks should be dissimilar. We validate these rules on both synthetic data and real-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100), demonstrating consistent performance improvements in both multilayer perceptrons and convolutional neural networks. Our work thus presents a generalizable framework for task-order optimization in task-incremental continual learning.

### Adaptive Variational Inference in Probabilistic Graphical Models: Beyond Bethe, Tree-Reweighted, and Convex Free Energies 
[[arxiv](https://arxiv.org/abs/2502.03341)] [[cool](https://papers.cool/arxiv/2502.03341)] [[pdf](https://arxiv.org/pdf/2502.03341)]
> **Authors**: Harald Leisenberger,Franz Pernkopf
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: This work has been submitted to the Conference on Uncertainty in Artificial Intelligence (UAI) 2025 for possible publication
- **标题**: None
- **领域**: 机器学习,人工智能,机器学习
- **Abstract**: Variational inference in probabilistic graphical models aims to approximate fundamental quantities such as marginal distributions and the partition function. Popular approaches are the Bethe approximation, tree-reweighted, and other types of convex free energies. These approximations are efficient but can fail if the model is complex and highly interactive. In this work, we analyze two classes of approximations that include the above methods as special cases: first, if the model parameters are changed; and second, if the entropy approximation is changed. We discuss benefits and drawbacks of either approach, and deduce from this analysis how a free energy approximation should ideally be constructed. Based on our observations, we propose approximations that automatically adapt to a given model and demonstrate their effectiveness for a range of difficult problems.

### A Mixture-Based Framework for Guiding Diffusion Models 
[[arxiv](https://arxiv.org/abs/2502.03332)] [[cool](https://papers.cool/arxiv/2502.03332)] [[pdf](https://arxiv.org/pdf/2502.03332)]
> **Authors**: Yazid Janati,Badr Moufad,Mehdi Abou El Qassime,Alain Durmus,Eric Moulines,Jimmy Olsson
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Denoising diffusion models have driven significant progress in the field of Bayesian inverse problems. Recent approaches use pre-trained diffusion models as priors to solve a wide range of such problems, only leveraging inference-time compute and thereby eliminating the need to retrain task-specific models on the same dataset. To approximate the posterior of a Bayesian inverse problem, a diffusion model samples from a sequence of intermediate posterior distributions, each with an intractable likelihood function. This work proposes a novel mixture approximation of these intermediate distributions. Since direct gradient-based sampling of these mixtures is infeasible due to intractable terms, we propose a practical method based on Gibbs sampling. We validate our approach through extensive experiments on image inverse problems, utilizing both pixel- and latent-space diffusion priors, as well as on source separation with an audio diffusion model. The code is available at https://www.github.com/badr-moufad/mgdm

### Is In-Context Universality Enough? MLPs are Also Universal In-Context 
[[arxiv](https://arxiv.org/abs/2502.03327)] [[cool](https://papers.cool/arxiv/2502.03327)] [[pdf](https://arxiv.org/pdf/2502.03327)]
> **Authors**: Anastasis Kratsios,Takashi Furuya
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习,神经和进化计算,数值分析,可能性
- **Abstract**: The success of transformers is often linked to their ability to perform in-context learning. Recent work shows that transformers are universal in context, capable of approximating any real-valued continuous function of a context (a probability measure over $\mathcal{X}\subseteq \mathbb{R}^d$) and a query $x\in \mathcal{X}$. This raises the question: Does in-context universality explain their advantage over classical models? We answer this in the negative by proving that MLPs with trainable activation functions are also universal in-context. This suggests the transformer's success is likely due to other factors like inductive bias or training stability.

### CARROT: A Cost Aware Rate Optimal Router 
[[arxiv](https://arxiv.org/abs/2502.03261)] [[cool](https://papers.cool/arxiv/2502.03261)] [[pdf](https://arxiv.org/pdf/2502.03261)]
> **Authors**: Seamus Somerstep,Felipe Maia Polo,Allysson Flavio Melo de Oliveira,Prattyush Mangal,Mírian Silva,Onkar Bhardwaj,Mikhail Yurochkin,Subha Maity
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习,网络和互联网架构,统计理论
- **Abstract**: With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in LLM routing, or directing queries to the cheapest LLM that can deliver a suitable response. Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates of models' cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce the Smart Price-aware Routing (SPROUT) dataset to facilitate routing on a wide spectrum of queries with the latest state-of-the-art LLMs. Using SPROUT and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers.

### Comparison of the Cox proportional hazards model and Random Survival Forest algorithm for predicting patient-specific survival probabilities in clinical trial data 
[[arxiv](https://arxiv.org/abs/2502.03119)] [[cool](https://papers.cool/arxiv/2502.03119)] [[pdf](https://arxiv.org/pdf/2502.03119)]
> **Authors**: Ricarda Graf,Susan Todd,M. Fazil Baksh
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: The Cox proportional hazards model is often used for model development in data from randomized controlled trials (RCT) with time-to-event outcomes. Random survival forests (RSF) is a machine-learning algorithm known for its high predictive performance. We conduct a comprehensive neutral comparison study to compare the predictive performance of Cox regression and RSF in real-world as well as simulated data. Performance is compared using multiple performance measures according to recommendations for the comparison of prognostic prediction models. We found that while the RSF usually outperforms the Cox model when using the $C$ index, Cox model predictions may be better calibrated. With respect to overall performance, the Cox model often exceeds the RSF in nonproportional hazards settings, while otherwise the RSF typically performs better especially for smaller sample sizes. Overall performance of the RSF is more affected by higher censoring rates, while overall performance of the Cox model suffers more from smaller sample sizes.

### Time Series Anomaly Detection in the Frequency Domain with Statistical Reliability 
[[arxiv](https://arxiv.org/abs/2502.03062)] [[cool](https://papers.cool/arxiv/2502.03062)] [[pdf](https://arxiv.org/pdf/2502.03062)]
> **Authors**: Akifumi Yamada,Tomohiro Shiraishi,Shuichi Nishino,Teruyuki Katsuoka,Kouichi Taji,Ichiro Takeuchi
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Effective anomaly detection in complex systems requires identifying change points (CPs) in the frequency domain, as abnormalities often arise across multiple frequencies. This paper extends recent advancements in statistically significant CP detection, based on Selective Inference (SI), to the frequency domain. The proposed SI method quantifies the statistical significance of detected CPs in the frequency domain using $p$-values, ensuring that the detected changes reflect genuine structural shifts in the target system. We address two major technical challenges to achieve this. First, we extend the existing SI framework to the frequency domain by appropriately utilizing the properties of discrete Fourier transform (DFT). Second, we develop an SI method that provides valid $p$-values for CPs where changes occur across multiple frequencies. Experimental results demonstrate that the proposed method reliably identifies genuine CPs with strong statistical guarantees, enabling more accurate root-cause analysis in the frequency domain of complex systems.

### Building Bridges between Regression, Clustering, and Classification 
[[arxiv](https://arxiv.org/abs/2502.02996)] [[cool](https://papers.cool/arxiv/2502.02996)] [[pdf](https://arxiv.org/pdf/2502.02996)]
> **Authors**: Lawrence Stewart,Francis Bach,Quentin Berthet
> **First submission**: 2025-02-05
> **First announcement**: 2025-02-06
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Regression, the task of predicting a continuous scalar target y based on some features x is one of the most fundamental tasks in machine learning and statistics. It has been observed and theoretically analyzed that the classical approach, meansquared error minimization, can lead to suboptimal results when training neural networks. In this work, we propose a new method to improve the training of these models on regression tasks, with continuous scalar targets. Our method is based on casting this task in a different fashion, using a target encoder, and a prediction decoder, inspired by approaches in classification and clustering. We showcase the performance of our method on a wide range of real-world datasets.

## 其他论文

- [Systolic Sparse Tensor Slices: FPGA Building Blocks for Sparse and Dense AI Acceleration](https://arxiv.org/abs/2502.03763)
  - **标题**: None
  - **Filtered Reason**: none of cs.AR in whitelist
- [More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients](https://arxiv.org/abs/2502.03732)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [Speaking the Language of Teamwork: LLM-Guided Credit Assignment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.03723)
  - **标题**: None
  - **Filtered Reason**: none of cs.MA in whitelist
- [Code Shaping: Iterative Code Editing with Free-form AI-Interpreted Sketching](https://arxiv.org/abs/2502.03719)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [Stop treating `AGI' as the north-star goal of AI research](https://arxiv.org/abs/2502.03689)
  - **标题**: None
  - **Filtered Reason**: none of cs.CY in whitelist
- [Beyond Diagonal RIS: A New Frontier for 6G Internet of Things Networks](https://arxiv.org/abs/2502.03637)
  - **标题**: None
  - **Filtered Reason**: none of cs.ET,eess.SP,cs.NI in whitelist
- [UX Challenges in Implementing an Interactive B2B Customer Segmentation Tool](https://arxiv.org/abs/2502.03635)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [Resource-Efficient & Effective Code Summarization](https://arxiv.org/abs/2502.03617)
  - **标题**: None
  - **Filtered Reason**: none of cs.SE in whitelist
- [Accelerating OTA Circuit Design: Transistor Sizing Based on a Transformer Model and Precomputed Lookup Tables](https://arxiv.org/abs/2502.03605)
  - **标题**: None
  - **Filtered Reason**: none of cs.AR in whitelist
- [A Mixed-Methods Evaluation of LLM-Based Chatbots for Menopause](https://arxiv.org/abs/2502.03579)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC,cs.CY in whitelist
- [Chartist: Task-driven Eye Movement Control for Chart Reading](https://arxiv.org/abs/2502.03575)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [EnVisionVR: A Scene Interpretation Tool for Visual Accessibility in Virtual Reality](https://arxiv.org/abs/2502.03564)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [Comprehensive Layer-wise Analysis of SSL Models for Audio Deepfake Detection](https://arxiv.org/abs/2502.03559)
  - **标题**: None
  - **Filtered Reason**: none of cs.SD,eess.AS in whitelist
- [FreqPrior: Improving Video Diffusion Models with Frequency Filtering Gaussian Noise](https://arxiv.org/abs/2502.03496)
  - **标题**: None
  - **Filtered Reason**: none of eess.IV,cs.GR in whitelist
- [Powering LLM Regulation through Data: Bridging the Gap from Compute Thresholds to Customer Experiences](https://arxiv.org/abs/2502.03472)
  - **标题**: None
  - **Filtered Reason**: none of cs.CY in whitelist
- [Responsible Artificial Intelligence (RAI) in U.S. Federal Government : Principles, Policies, and Practices](https://arxiv.org/abs/2502.03470)
  - **标题**: None
  - **Filtered Reason**: none of cs.CY in whitelist
- [AI Governance in the Context of the EU AI Act: A Bibliometric and Literature Review Approach](https://arxiv.org/abs/2502.03468)
  - **标题**: None
  - **Filtered Reason**: none of cs.CY,cs.DL in whitelist
- [Designing LLM-simulated Immersive Spaces to Enhance Autistic Children's Social Affordances Understanding](https://arxiv.org/abs/2502.03447)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [Harnessing Large Language Models for Curated Code Reviews](https://arxiv.org/abs/2502.03425)
  - **标题**: None
  - **Filtered Reason**: none of cs.SE in whitelist
- [Dynamic Cybersickness Mitigation via Adaptive FFR and FoV adjustments](https://arxiv.org/abs/2502.03419)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [Tensor Evolution: A Framework for Fast Evaluation of Tensor Computations using Recurrences](https://arxiv.org/abs/2502.03402)
  - **标题**: None
  - **Filtered Reason**: none of cs.PL,cs.MS in whitelist
- [Intent Alignment between Interaction and Language Spaces for Recommendation](https://arxiv.org/abs/2502.03307)
  - **标题**: None
  - **Filtered Reason**: none of cs.IR in whitelist
- [What is Human-Centeredness in Human-Centered AI? Development of Human-Centeredness Framework and AI Practitioners' Perspectives](https://arxiv.org/abs/2502.03293)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [Exploring the Security Threats of Knowledge Base Poisoning in Retrieval-Augmented Code Generation](https://arxiv.org/abs/2502.03233)
  - **标题**: None
  - **Filtered Reason**: none of cs.CR,cs.SE in whitelist
- [Leveraging Broadcast Media Subtitle Transcripts for Automatic Speech Recognition and Subtitling](https://arxiv.org/abs/2502.03212)
  - **标题**: None
  - **Filtered Reason**: none of cs.SD,eess.AS in whitelist
- [FSLH: Flexible Mechanized Speculative Load Hardening](https://arxiv.org/abs/2502.03203)
  - **标题**: None
  - **Filtered Reason**: none of cs.CR,cs.PL in whitelist
- [AL-Bench: A Benchmark for Automatic Logging](https://arxiv.org/abs/2502.03160)
  - **标题**: None
  - **Filtered Reason**: none of cs.SE in whitelist
- [HiLo: Learning Whole-Body Human-like Locomotion with Motion Tracking Controller](https://arxiv.org/abs/2502.03122)
  - **标题**: None
  - **Filtered Reason**: none of cs.RO in whitelist
- [The Role of Mobile and Social Media Services in Enhancing Freedom of Expression: Opportunities, Challenges, and Prospects for Local Platform Development in Uganda's Digital Ecosystem](https://arxiv.org/abs/2502.03083)
  - **标题**: None
  - **Filtered Reason**: none of cs.CY in whitelist
- [CreepyCoCreator? Investigating AI Representation Modes for 3D Object Co-Creation in Virtual Reality](https://arxiv.org/abs/2502.03069)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [A Framework for IoT-Enabled Smart Manufacturing for Energy and Resource Optimization](https://arxiv.org/abs/2502.03040)
  - **标题**: None
  - **Filtered Reason**: none of cs.NI in whitelist
- [FuXi-$α$: Scaling Recommendation Model with Feature Interaction Enhanced Transformer](https://arxiv.org/abs/2502.03036)
  - **标题**: None
  - **Filtered Reason**: none of cs.IR in whitelist
- [UMC: Unified Resilient Controller for Legged Robots with Joint Malfunctions](https://arxiv.org/abs/2502.03035)
  - **标题**: None
  - **Filtered Reason**: none of cs.RO in whitelist
- [Armadillo: An Efficient Framework for Numerical Linear Algebra](https://arxiv.org/abs/2502.03000)
  - **标题**: None
  - **Filtered Reason**: none of cs.MS in whitelist
- [Large Language Model Adversarial Landscape Through the Lens of Attack Objectives](https://arxiv.org/abs/2502.02960)
  - **标题**: None
  - **Filtered Reason**: none of cs.CR in whitelist
- [Control Search Rankings, Control the World: What is a Good Search Engine?](https://arxiv.org/abs/2502.02957)
  - **标题**: None
  - **Filtered Reason**: none of cs.IR,cs.CY in whitelist
- [Fine-grained Preference Optimization Improves Zero-shot Text-to-Speech](https://arxiv.org/abs/2502.02950)
  - **标题**: None
  - **Filtered Reason**: none of cs.SD,eess.AS in whitelist
- [GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling](https://arxiv.org/abs/2502.02942)
  - **标题**: None
  - **Filtered Reason**: none of cs.SD,eess.AS in whitelist
- [The Benefits of Prosociality towards AI Agents: Examining the Effects of Helping AI Agents on Human Well-Being](https://arxiv.org/abs/2502.02911)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
- [From DeepSense to Open RAN: AI/ML Advancements in Dynamic Spectrum Sensing and Their Applications](https://arxiv.org/abs/2502.02889)
  - **标题**: None
  - **Filtered Reason**: none of eess.SP,cs.NI in whitelist
