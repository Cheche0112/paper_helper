> 本文由 [https://github.com/huiyeruzhou/arxiv_crawler](https://github.com/huiyeruzhou/arxiv_crawler) 自动生成
>
> 领域白名单：cs.AI,cs.CL,cs.LG,cs.CV
> 关键词： LLM, GPT, AI, language+model, deep+learning, transformer, neural+network, machine+learning

# 论文全览：2025-02-18

共有50篇相关领域论文, 另有3篇其他

## 人工智能(cs.AI:Artificial Intelligence)

### A Survey of Personalized Large Language Models: Progress and Future Directions 
[[arxiv](https://arxiv.org/abs/2502.11528)] [[cool](https://papers.cool/arxiv/2502.11528)] [[pdf](https://arxiv.org/pdf/2502.11528)]
> **Authors**: Jiahong Liu,Zexuan Qiu,Zhongyang Li,Quanyu Dai,Jieming Zhu,Minda Hu,Menglin Yang,Irwin King
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 7pages, 5 figures, Under Review
- **标题**: None
- **领域**: 人工智能
- **Abstract**: Large Language Models (LLMs) excel in handling general knowledge tasks, yet they struggle with user-specific personalization, such as understanding individual emotions, writing styles, and preferences. Personalized Large Language Models (PLLMs) tackle these challenges by leveraging individual user data, such as user profiles, historical dialogues, content, and interactions, to deliver responses that are contextually relevant and tailored to each user's specific needs. This is a highly valuable research topic, as PLLMs can significantly enhance user satisfaction and have broad applications in conversational agents, recommendation systems, emotion recognition, medical assistants, and more. This survey reviews recent advancements in PLLMs from three technical perspectives: prompting for personalized context (input level), finetuning for personalized adapters (model level), and alignment for personalized preferences (objective level). To provide deeper insights, we also discuss current limitations and outline several promising directions for future research. Updated information about this survey can be found at the https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.

### Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding 
[[arxiv](https://arxiv.org/abs/2502.11492)] [[cool](https://papers.cool/arxiv/2502.11492)] [[pdf](https://arxiv.org/pdf/2502.11492)]
> **Authors**: Kung-Hsiang Huang,Can Qin,Haoyi Qiu,Philippe Laban,Shafiq Joty,Caiming Xiong,Chien-Sheng Wu
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能,计算语言学,计算机视觉和模式识别
- **Abstract**: Vision Language Models (VLMs) have achieved remarkable progress in multimodal tasks, yet they often struggle with visual arithmetic, seemingly simple capabilities like object counting or length comparison, which are essential for relevant complex tasks like chart understanding and geometric reasoning. In this work, we first investigate the root causes of this deficiency through a suite of probing tasks focusing on basic visual arithmetic. Our analysis reveals that while pre-trained vision encoders typically capture sufficient information, the text decoder often fails to decode it correctly for arithmetic reasoning. To address this, we propose CogAlign, a novel post-training strategy inspired by Piaget's theory of cognitive development. CogAlign trains VLMs to recognize invariant properties under visual transformations. We demonstrate that this approach significantly improves the performance of three diverse VLMs on our proposed probing tasks. Furthermore, CogAlign enhances performance by an average of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching supervised fine-tuning methods while requiring only 60% less training data. These results highlight the effectiveness and generalizability of CogAlign in improving fundamental visual arithmetic capabilities and their transfer to downstream tasks.

### AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection 
[[arxiv](https://arxiv.org/abs/2502.11448)] [[cool](https://papers.cool/arxiv/2502.11448)] [[pdf](https://arxiv.org/pdf/2502.11448)]
> **Authors**: Weidi Luo,Shenghong Dai,Xiaogeng Liu,Suman Banerjee,Huan Sun,Muhao Chen,Chaowei Xiao
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 人工智能
- **Abstract**: The rapid advancements in Large Language Models (LLMs) have enabled their deployment as autonomous agents for handling complex tasks in dynamic environments. These LLMs demonstrate strong problem-solving capabilities and adaptability to multifaceted scenarios. However, their use as agents also introduces significant risks, including task-specific risks, which are identified by the agent administrator based on the specific task requirements and constraints, and systemic risks, which stem from vulnerabilities in their design or interactions, potentially compromising confidentiality, integrity, or availability (CIA) of information and triggering security risks. Existing defense agencies fail to adaptively and effectively mitigate these risks. In this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent safety, which features adaptive safety check generation, effective safety check optimization, and tool compatibility and flexibility. Extensive experiments demonstrate that AGrail not only achieves strong performance against task-specific and system risks but also exhibits transferability across different LLM agents' tasks.

## 计算语言学(cs.CL:Computation and Language)

### DCAD-2000: A Multilingual Dataset across 2000+ Languages with Data Cleaning as Anomaly Detection 
[[arxiv](https://arxiv.org/abs/2502.11546)] [[cool](https://papers.cool/arxiv/2502.11546)] [[pdf](https://arxiv.org/pdf/2502.11546)]
> **Authors**: Yingli Shen,Wen Lai,Shuo Wang,Xueren Zhang,Kangyang Luo,Alexander Fraser,Maosong Sun
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: The rapid development of multilingual large language models (LLMs) highlights the need for high-quality, diverse, and clean multilingual datasets. In this paper, we introduce DCAD-2000 (Data Cleaning as Anomaly Detection), a large-scale multilingual corpus built using newly extracted Common Crawl data and existing multilingual datasets. DCAD-2000 includes over 2,282 languages, 46.72TB of data, and 8.63 billion documents, spanning 155 high- and medium-resource languages and 159 writing scripts. To overcome the limitations of current data cleaning methods, which rely on manual heuristic thresholds, we propose reframing data cleaning as an anomaly detection task. This dynamic filtering approach significantly enhances data quality by identifying and removing noisy or anomalous content. We evaluate the quality of DCAD-2000 on the FineTask benchmark, demonstrating substantial improvements in multilingual dataset quality and task performance.

### Evaluating o1-Like LLMs: Unlocking Reasoning for Translation through Comprehensive Analysis 
[[arxiv](https://arxiv.org/abs/2502.11544)] [[cool](https://papers.cool/arxiv/2502.11544)] [[pdf](https://arxiv.org/pdf/2502.11544)]
> **Authors**: Andong Chen,Yuchen Song,Wenxin Zhu,Kehai Chen,Muyun Yang,Tiejun Zhao,Min zhang
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: The o1-Like LLMs are transforming AI by simulating human cognitive processes, but their performance in multilingual machine translation (MMT) remains underexplored. This study examines: (1) how o1-Like LLMs perform in MMT tasks and (2) what factors influence their translation quality. We evaluate multiple o1-Like LLMs and compare them with traditional models like ChatGPT and GPT-4o. Results show that o1-Like LLMs establish new multilingual translation benchmarks, with DeepSeek-R1 surpassing GPT-4o in contextless tasks. They demonstrate strengths in historical and cultural translation but exhibit a tendency for rambling issues in Chinese-centric outputs. Further analysis reveals three key insights: (1) High inference costs and slower processing speeds make complex translation tasks more resource-intensive. (2) Translation quality improves with model size, enhancing commonsense reasoning and cultural translation. (3) The temperature parameter significantly impacts output quality-lower temperatures yield more stable and accurate translations, while higher temperatures reduce coherence and precision.

### MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training 
[[arxiv](https://arxiv.org/abs/2502.11541)] [[cool](https://papers.cool/arxiv/2502.11541)] [[pdf](https://arxiv.org/pdf/2502.11541)]
> **Authors**: Hui Huang,Jiaheng Liu,Yancheng He,Shilong Li,Bing Xu,Conghui Zhu,Muyun Yang,Tiejun Zhao
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Complex instruction-following with elaborate constraints is imperative for Large Language Models (LLMs). While existing methods have constructed data for complex instruction alignment, they all rely on a more advanced model, especially GPT-4, limiting their application. In this paper, we propose a Multi-granularity Self-Contrastive Training (MuSC) framework, to improve the complex instruction alignment without relying on a stronger model. Our method is conducted on both coarse and fine granularity. On coarse-granularity, we construct constraint-aware preference data based on instruction decomposition and recombination. On fine-granularity, we perform token-aware preference optimization with dynamic token-level supervision. Our method is evaluated on open-sourced models, and experiment results show our method achieves significant improvement on both complex and general instruction-following benchmarks, surpassing previous self-alignment methods.

### Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy 
[[arxiv](https://arxiv.org/abs/2502.11533)] [[cool](https://papers.cool/arxiv/2502.11533)] [[pdf](https://arxiv.org/pdf/2502.11533)]
> **Authors**: Zhenyuan Guo,Yi Shi,Wenlong Meng,Chen Gong,Chengkun Wei,Wenzhi Chen
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Model merging is a widespread technology in large language models (LLMs) that integrates multiple task-specific LLMs into a unified one, enabling the merged model to inherit the specialized capabilities of these LLMs. Most task-specific LLMs are sourced from open-source communities and have not undergone rigorous auditing, potentially imposing risks in model merging. This paper highlights an overlooked privacy risk: \textit{an unsafe model could compromise the privacy of other LLMs involved in the model merging.} Specifically, we propose PhiMM, a privacy attack approach that trains a phishing model capable of stealing privacy using a crafted privacy phishing instruction dataset. Furthermore, we introduce a novel model cloaking method that mimics a specialized capability to conceal attack intent, luring users into merging the phishing model. Once victims merge the phishing model, the attacker can extract personally identifiable information (PII) or infer membership information (MI) by querying the merged model with the phishing instruction. Experimental results show that merging a phishing model increases the risk of privacy breaches. Compared to the results before merging, PII leakage increased by 3.9\% and MI leakage increased by 17.4\% on average. We release the code of PhiMM through a link.

### Training Large Language Models to be Better Rule Followers 
[[arxiv](https://arxiv.org/abs/2502.11525)] [[cool](https://papers.cool/arxiv/2502.11525)] [[pdf](https://arxiv.org/pdf/2502.11525)]
> **Authors**: Yi Hu,Shijia Kang,Haotong Yang,Haotian Xu,Muhan Zhang
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Large language models (LLMs) have shown impressive performance across a wide range of tasks. However, they often exhibit unexpected failures in seemingly straightforward tasks, suggesting a reliance on case-based reasoning rather than rule-based reasoning. While the vast training corpus of LLMs contains numerous textual "rules", current training methods fail to leverage these rules effectively. Crucially, the relationships between these "rules" and their corresponding "instances" are not explicitly modeled. As a result, while LLMs can often recall rules with ease, they fail to apply these rules strictly and consistently in relevant reasoning scenarios. In this paper, we investigate the rule-following capabilities of LLMs and propose Meta Rule-Following Fine-Tuning (Meta-RFFT) to enhance the cross-task transferability of rule-following abilities. We first construct a dataset of 88 tasks requiring following rules, encompassing diverse reasoning domains. We demonstrate through extensive experiments that models trained on large-scale rule-following tasks are better rule followers, outperforming the baselines in both downstream fine-tuning and few-shot prompting scenarios. This highlights the cross-task transferability of models with the aid of Meta-RFFT. Furthermore, we examine the influence of factors such as dataset size, rule formulation, and in-context learning.

### AURORA:Automated Training Framework of Universal Process Reward Models via Ensemble Prompting and Reverse Verification 
[[arxiv](https://arxiv.org/abs/2502.11520)] [[cool](https://papers.cool/arxiv/2502.11520)] [[pdf](https://arxiv.org/pdf/2502.11520)]
> **Authors**: Xiaoyu Tan,Tianchu Yao,Chao Qu,Bin Li,Minghao Yang,Dakuan Lu,Haozhe Wang,Xihe Qiu,Wei Chu,Yinghui Xu,Yuan Qi
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: Under Review
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: The reasoning capabilities of advanced large language models (LLMs) like o1 have revolutionized artificial intelligence applications. Nevertheless, evaluating and optimizing complex reasoning processes remain significant challenges due to diverse policy distributions and the inherent limitations of human effort and accuracy. In this paper, we present AURORA, a novel automated framework for training universal process reward models (PRMs) using ensemble prompting and reverse verification. The framework employs a two-phase approach: First, it uses diverse prompting strategies and ensemble methods to perform automated annotation and evaluation of processes, ensuring robust assessments for reward learning. Second, it leverages practical reference answers for reverse verification, enhancing the model's ability to validate outputs and improving training accuracy. To assess the framework's performance, we extend beyond the existing ProcessBench benchmark by introducing UniversalBench, which evaluates reward predictions across full trajectories under diverse policy distribtion with long Chain-of-Thought (CoT) outputs. Experimental results demonstrate that AURORA enhances process evaluation accuracy, improves PRMs' accuracy for diverse policy distributions and long-CoT responses. The project will be open-sourced at https://auroraprm.github.io/. The Universal-PRM-7B is available at https://huggingface.co/infly/Universal-PRM-7B.

### Learning to Keep a Promise: Scaling Language Model Decoding Parallelism with Learned Asynchronous Decoding 
[[arxiv](https://arxiv.org/abs/2502.11517)] [[cool](https://papers.cool/arxiv/2502.11517)] [[pdf](https://arxiv.org/pdf/2502.11517)]
> **Authors**: Tian Jin,Ellie Y. Cheng,Zack Ankner,Nikunj Saunshi,Blake M. Elias,Amir Yazdanbakhsh,Jonathan Ragan-Kelley,Suvinay Subramanian,Michael Carbin
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 15 pages
- **标题**: None
- **领域**: 计算语言学,分布式、并行和集群计算,机器学习
- **Abstract**: Decoding with autoregressive large language models (LLMs) traditionally occurs sequentially, generating one token after another. An emerging line of work explored parallel decoding by identifying and simultaneously generating semantically independent chunks of LLM responses. However, these techniques rely on hand-crafted heuristics tied to syntactic structures like lists and paragraphs, making them rigid and imprecise. We present PASTA, a learning-based system that teaches LLMs to identify semantic independence and express parallel decoding opportunities in their own responses. At its core are PASTA-LANG and its interpreter: PASTA-LANG is an annotation language that enables LLMs to express semantic independence in their own responses; the language interpreter acts on these annotations to orchestrate parallel decoding on-the-fly at inference time. Through a two-stage finetuning process, we train LLMs to generate PASTA-LANG annotations that optimize both response quality and decoding speed. Evaluation on AlpacaEval, an instruction following benchmark, shows that our approach Pareto-dominates existing methods in terms of decoding speed and response quality; our results demonstrate geometric mean speedups ranging from 1.21x to 1.93x with corresponding quality changes of +2.2% to -7.1%, measured by length-controlled win rates against sequential decoding baseline.

### Chinese Spelling Correction: A Comprehensive Survey of Progress, Challenges, and Opportunities 
[[arxiv](https://arxiv.org/abs/2502.11508)] [[cool](https://papers.cool/arxiv/2502.11508)] [[pdf](https://arxiv.org/pdf/2502.11508)]
> **Authors**: Changchun Liu,Kai Zhang,Junzhe Jiang,Zixiao Kong,Qi Liu,Enhong Chen
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Chinese Spelling Correction (CSC) is a critical task in natural language processing, aimed at detecting and correcting spelling errors in Chinese text. This survey provides a comprehensive overview of CSC, tracing its evolution from pre-trained language models to large language models, and critically analyzing their respective strengths and weaknesses in this domain. Moreover, we further present a detailed examination of existing benchmark datasets, highlighting their inherent challenges and limitations. Finally, we propose promising future research directions, particularly focusing on leveraging the potential of LLMs and their reasoning capabilities for improved CSC performance. To the best of our knowledge, this is the first comprehensive survey dedicated to the field of CSC. We believe this work will serve as a valuable resource for researchers, fostering a deeper understanding of the field and inspiring future advancements.

### Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem? 
[[arxiv](https://arxiv.org/abs/2502.11501)] [[cool](https://papers.cool/arxiv/2502.11501)] [[pdf](https://arxiv.org/pdf/2502.11501)]
> **Authors**: Zichen Wen,Yifeng Gao,Weijia Li,Conghui He,Linfeng Zhang
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 12 pages, 3 figures
- **标题**: None
- **领域**: 计算语言学,计算机视觉和模式识别
- **Abstract**: Multimodal large language models (MLLMs) have shown remarkable performance for cross-modal understanding and generation, yet still suffer from severe inference costs. Recently, abundant works have been proposed to solve this problem with token pruning, which identifies the redundant tokens in MLLMs and then prunes them to reduce the computation and KV storage costs, leading to significant acceleration without training. While these methods claim efficiency gains, critical questions about their fundamental design and evaluation remain unanswered: Why do many existing approaches underperform even compared to naive random token selection? Are attention-based scoring sufficient for reliably identifying redundant tokens? Is language information really helpful during token pruning? What makes a good trade-off between token importance and duplication? Are current evaluation protocols comprehensive and unbiased? The ignorance of previous research on these problems hinders the long-term development of token pruning. In this paper, we answer these questions one by one, providing insights into the design of future token pruning methods.

### Balanced Multi-Factor In-Context Learning for Multilingual Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.11495)] [[cool](https://papers.cool/arxiv/2502.11495)] [[pdf](https://arxiv.org/pdf/2502.11495)]
> **Authors**: Masahiro Kaneko,Alham Fikri Aji,Timothy Baldwin
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Multilingual large language models (MLLMs) are able to leverage in-context learning (ICL) to achieve high performance by leveraging cross-lingual knowledge transfer without parameter updates. However, their effectiveness is highly sensitive to example selection, particularly in multilingual settings. Based on the findings of existing work, three key factors influence multilingual ICL: (1) semantic similarity, (2) linguistic alignment, and (3) language-specific performance. However, existing approaches address these factors independently, without explicitly disentangling their combined impact, leaving optimal example selection underexplored. To address this gap, we propose balanced multi-factor ICL (\textbf{BMF-ICL}), a method that quantifies and optimally balances these factors for improved example selection. Experiments on mCSQA and TYDI across four MLLMs demonstrate that BMF-ICL outperforms existing methods. Further analysis highlights the importance of incorporating all three factors and the importance of selecting examples from multiple languages.

### Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More 
[[arxiv](https://arxiv.org/abs/2502.11494)] [[cool](https://papers.cool/arxiv/2502.11494)] [[pdf](https://arxiv.org/pdf/2502.11494)]
> **Authors**: Zichen Wen,Yifeng Gao,Shaobo Wang,Junyuan Zhang,Qintong Zhang,Weijia Li,Conghui He,Linfeng Zhang
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 15 pages, 8 figures
- **标题**: None
- **领域**: 计算语言学,计算机视觉和模式识别
- **Abstract**: Vision tokens in multimodal large language models often dominate huge computational overhead due to their excessive length compared to linguistic modality. Abundant recent methods aim to solve this problem with token pruning, which first defines an importance criterion for tokens and then prunes the unimportant vision tokens during inference. However, in this paper, we show that the importance is not an ideal indicator to decide whether a token should be pruned. Surprisingly, it usually results in inferior performance than random token pruning and leading to incompatibility to efficient attention computation operators.Instead, we propose DART (Duplication-Aware Reduction of Tokens), which prunes tokens based on its duplication with other tokens, leading to significant and training-free acceleration. Concretely, DART selects a small subset of pivot tokens and then retains the tokens with low duplication to the pivots, ensuring minimal information loss during token pruning. Experiments demonstrate that DART can prune 88.9% vision tokens while maintaining comparable performance, leading to a 1.99$\times$ and 2.99$\times$ speed-up in total time and prefilling stage, respectively, with good compatibility to efficient attention operators. Our codes are available at https://github.com/ZichenWen1/DART.

### DAST: Context-Aware Compression in LLMs via Dynamic Allocation of Soft Tokens 
[[arxiv](https://arxiv.org/abs/2502.11493)] [[cool](https://papers.cool/arxiv/2502.11493)] [[pdf](https://arxiv.org/pdf/2502.11493)]
> **Authors**: Shaoshen Chen,Yangning Li,Zishan Xu,Yinghui Li,Xin Su,Zifei Shan,Hai-tao Zheng
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Large Language Models (LLMs) face computational inefficiencies and redundant processing when handling long context inputs, prompting a focus on compression techniques. While existing semantic vector-based compression methods achieve promising performance, these methods fail to account for the intrinsic information density variations between context chunks, instead allocating soft tokens uniformly across context chunks. This uniform distribution inevitably diminishes allocation to information-critical regions. To address this, we propose Dynamic Allocation of Soft Tokens (DAST), a simple yet effective method that leverages the LLM's intrinsic understanding of contextual relevance to guide compression. DAST combines perplexity-based local information with attention-driven global information to dynamically allocate soft tokens to the informative-rich chunks, enabling effective, context-aware compression. Experimental results across multiple benchmarks demonstrate that DAST surpasses state-of-the-art methods.

### Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering 
[[arxiv](https://arxiv.org/abs/2502.11491)] [[cool](https://papers.cool/arxiv/2502.11491)] [[pdf](https://arxiv.org/pdf/2502.11491)]
> **Authors**: Runxuan Liu,Bei Luo,Jiaqi Li,Baoxin Wang,Ming Liu,Dayong Wu,Shijin Wang,Bing Qin
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Large language models (LLMs) have shown remarkable capabilities in natural language processing. However, in knowledge graph question answering tasks (KGQA), there remains the issue of answering questions that require multi-hop reasoning. Existing methods rely on entity vector matching, but the purpose of the question is abstract and difficult to match with specific entities. As a result, it is difficult to establish reasoning paths to the purpose, which leads to information loss and redundancy. To address this issue, inspired by human reverse thinking, we propose Ontology-Guided Reverse Thinking (ORT), a novel framework that constructs reasoning paths from purposes back to conditions. ORT operates in three key phases: (1) using LLM to extract purpose labels and condition labels, (2) constructing label reasoning paths based on the KG ontology, and (3) using the label reasoning paths to guide knowledge retrieval. Experiments on the WebQSP and CWQ datasets show that ORT achieves state-of-the-art performance and significantly enhances the capability of LLMs for KGQA.

### FastMCTS: A Simple Sampling Strategy for Data Synthesis 
[[arxiv](https://arxiv.org/abs/2502.11476)] [[cool](https://papers.cool/arxiv/2502.11476)] [[pdf](https://arxiv.org/pdf/2502.11476)]
> **Authors**: Peiji Li,Kai Lv,Yunfan Shao,Yichuan Ma,Linyang Li,Xiaoqing Zheng,Xipeng Qiu,Qipeng Guo
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: work in progress
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Synthetic high-quality multi-step reasoning data can significantly enhance the performance of large language models on various tasks. However, most existing methods rely on rejection sampling, which generates trajectories independently and suffers from inefficiency and imbalanced sampling across problems of varying difficulty. In this work, we introduce FastMCTS, an innovative data synthesis strategy inspired by Monte Carlo Tree Search. FastMCTS provides a more efficient sampling method for multi-step reasoning data, offering step-level evaluation signals and promoting balanced sampling across problems of different difficulty levels. Experiments on both English and Chinese reasoning datasets demonstrate that FastMCTS generates over 30\% more correct reasoning paths compared to rejection sampling as the number of generated tokens scales up. Furthermore, under comparable synthetic data budgets, models trained on FastMCTS-generated data outperform those trained on rejection sampling data by 3.9\% across multiple benchmarks. As a lightweight sampling strategy, FastMCTS offers a practical and efficient alternative for synthesizing high-quality reasoning data. Our code will be released soon.

### GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion 
[[arxiv](https://arxiv.org/abs/2502.11471)] [[cool](https://papers.cool/arxiv/2502.11471)] [[pdf](https://arxiv.org/pdf/2502.11471)]
> **Authors**: Kangyang Luo,Yuzhuo Bai,Cheng Gao,Shuzheng Si,Yingli Shen,Zhu Liu,Zhitong Wang,Cunliang Kong,Wenhao Li,Yufei Huang,Ye Tian,Xuantang Xiong,Lei Han,Maosong Sun
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,信息检索
- **Abstract**: Knowledge Graph Completion (KGC), which aims to infer missing or incomplete facts, is a crucial task for KGs. However, integrating the vital structural information of KGs into Large Language Models (LLMs) and outputting predictions deterministically remains challenging. To address this, we propose a new method called GLTW, which encodes the structural information of KGs and merges it with LLMs to enhance KGC performance. Specifically, we introduce an improved Graph Transformer (iGT) that effectively encodes subgraphs with both local and global structural information and inherits the characteristics of language model, bypassing training from scratch. Also, we develop a subgraph-based multi-classification training objective, using all entities within KG as classification objects, to boost learning efficiency.Importantly, we combine iGT with an LLM that takes KG language prompts as input.Our extensive experiments on various KG datasets show that GLTW achieves significant performance gains compared to SOTA baselines.

### If Attention Serves as a Cognitive Model of Human Memory Retrieval, What is the Plausible Memory Representation? 
[[arxiv](https://arxiv.org/abs/2502.11469)] [[cool](https://papers.cool/arxiv/2502.11469)] [[pdf](https://arxiv.org/pdf/2502.11469)]
> **Authors**: Ryo Yoshida,Shinnosuke Isono,Kohei Kajikawa,Taiga Someya,Yushi Sugimito,Yohei Oseki
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 16 pages
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Recent work in computational psycholinguistics has revealed intriguing parallels between attention mechanisms and human memory retrieval, focusing primarily on Transformer architectures that operate on token-level representations. However, computational psycholinguistic research has also established that syntactic structures provide compelling explanations for human sentence processing that word-level factors alone cannot fully account for. In this study, we investigate whether the attention mechanism of Transformer Grammar (TG), which uniquely operates on syntactic structures as representational units, can serve as a cognitive model of human memory retrieval, using Normalized Attention Entropy (NAE) as a linking hypothesis between model behavior and human processing difficulty. Our experiments demonstrate that TG's attention achieves superior predictive power for self-paced reading times compared to vanilla Transformer's, with further analyses revealing independent contributions from both models. These findings suggest that human sentence processing involves dual memory representations -- one based on syntactic structures and another on token sequences -- with attention serving as the general retrieval algorithm, while highlighting the importance of incorporating syntactic structures as representational units.

### UnitCoder: Scalable Iterative Code Synthesis with Unit Test Guidance 
[[arxiv](https://arxiv.org/abs/2502.11460)] [[cool](https://papers.cool/arxiv/2502.11460)] [[pdf](https://arxiv.org/pdf/2502.11460)]
> **Authors**: Yichuan Ma,Yunfan Shao,Peiji Li,Demin Song,Qipeng Guo,Linyang Li,Xipeng Qiu,Kai Chen
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: work in progress
- **标题**: None
- **领域**: 计算语言学,软件工程
- **Abstract**: Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks, yet code generation remains a major challenge. Current approaches for obtaining high-quality code data primarily focus on (i) collecting large-scale pre-training data and (ii) synthesizing instruction data through prompt engineering with powerful models. While pre-training data faces quality consistency issues, instruction-based synthesis suffers from limited instruction diversity and inherent biases of LLMs. To address this gap, we introduce UnitCoder, a systematic pipeline leveraging model-generated unit tests to both guide and validate the code generation process. Combined with large-scale package-based retrieval from pre-training corpus, we generate a dataset of 500K+ verifiable programs containing diverse API calls. Evaluations on multiple Python benchmarks (BigCodeBench, HumanEval, MBPP) demonstrate that models fine-tuned on our synthetic data exhibit consistent performance improvements. Notably, Llama3.1-8B and InternLM2.5-7B improve from 31\% and 28\% to 40\% and 39\% success rates on BigCodeBench, respectively. Our work presents a scalable approach that leverages model-generated unit tests to guide the synthesis of high-quality code data from pre-training corpora, demonstrating the potential for producing diverse and high-quality post-training data at scale. All code and data will be released (https://github.com).

### Aligning Sentence Simplification with ESL Learner's Proficiency for Language Acquisition 
[[arxiv](https://arxiv.org/abs/2502.11457)] [[cool](https://papers.cool/arxiv/2502.11457)] [[pdf](https://arxiv.org/pdf/2502.11457)]
> **Authors**: Guanlin Li,Yuki Arase,Noel Crespi
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: NAACL2025 main
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Text simplification is crucial for improving accessibility and comprehension for English as a Second Language (ESL) learners. This study goes a step further and aims to facilitate ESL learners' language acquisition by simplification. Specifically, we propose simplifying complex sentences to appropriate levels for learners while also increasing vocabulary coverage of the target level in the simplifications. We achieve this without a parallel corpus by conducting reinforcement learning on a large language model. Our method employs token-level and sentence-level rewards, and iteratively trains the model on its self-generated outputs to guide the model to search for simplification hypotheses that satisfy the target attributes. Experiment results on CEFR-SP and TurkCorpus datasets show that the proposed method can effectively increase the frequency and diversity of vocabulary of the target level by more than $20\%$ compared to baseline models, while maintaining high simplification quality.

### UniCBE: An Uniformity-driven Comparing Based Evaluation Framework with Unified Multi-Objective Optimization 
[[arxiv](https://arxiv.org/abs/2502.11454)] [[cool](https://papers.cool/arxiv/2502.11454)] [[pdf](https://arxiv.org/pdf/2502.11454)]
> **Authors**: Peiwen Yuan,Shaoxiong Feng,Yiwei Li,Xinglin Wang,Yueqi Zhang,Jiayi Shi,Chuyi Tan,Boyuan Pan,Yao Hu,Kan Li
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: ICLR 2025 spotlight
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Human preference plays a significant role in measuring large language models and guiding them to align with human values. Unfortunately, current comparing-based evaluation (CBE) methods typically focus on a single optimization objective, failing to effectively utilize scarce yet valuable preference signals. To address this, we delve into key factors that can enhance the accuracy, convergence, and scalability of CBE: suppressing sampling bias, balancing descending process of uncertainty, and mitigating updating uncertainty. Following the derived guidelines, we propose UniCBE, a unified uniformity-driven CBE framework which simultaneously optimize these core objectives by constructing and integrating three decoupled sampling probability matrices, each designed to ensure uniformity in specific aspects. We further ablate the optimal tuple sampling and preference aggregation strategies to achieve efficient CBE. On the AlpacaEval benchmark, UniCBE saves over 17% of evaluation budgets while achieving a Pearson correlation with ground truth exceeding 0.995, demonstrating excellent accuracy and convergence. In scenarios where new models are continuously introduced, UniCBE can even save over 50% of evaluation costs, highlighting its improved scalability.

### From Personas to Talks: Revisiting the Impact of Personas on LLM-Synthesized Emotional Support Conversations 
[[arxiv](https://arxiv.org/abs/2502.11451)] [[cool](https://papers.cool/arxiv/2502.11451)] [[pdf](https://arxiv.org/pdf/2502.11451)]
> **Authors**: Shenghan Wu,Yang Deng,Yimo Zhu,Wynne Hsu,Mong Li Lee
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: The rapid advancement of Large Language Models (LLMs) has revolutionized the generation of emotional support conversations (ESC), offering scalable solutions with reduced costs and enhanced data privacy. This paper explores the role of personas in the creation of ESC by LLMs. Our research utilizes established psychological frameworks to measure and infuse persona traits into LLMs, which then generate dialogues in the emotional support scenario. We conduct extensive evaluations to understand the stability of persona traits in dialogues, examining shifts in traits post-generation and their impact on dialogue quality and strategy distribution. Experimental results reveal several notable findings: 1) LLMs can infer core persona traits, 2) subtle shifts in emotionality and extraversion occur, influencing the dialogue dynamics, and 3) the application of persona traits modifies the distribution of emotional support strategies, enhancing the relevance and empathetic quality of the responses. These findings highlight the potential of persona-driven LLMs in crafting more personalized, empathetic, and effective emotional support dialogues, which has significant implications for the future design of AI-driven emotional support systems.

### Does RAG Really Perform Bad For Long-Context Processing? 
[[arxiv](https://arxiv.org/abs/2502.11444)] [[cool](https://papers.cool/arxiv/2502.11444)] [[pdf](https://arxiv.org/pdf/2502.11444)]
> **Authors**: Kun Luo,Zheng Liu,Peitian Zhang,Hongjin Qian,Jun Zhao,Kang Liu
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: The efficient processing of long context poses a serious challenge for large language models (LLMs). Recently, retrieval-augmented generation (RAG) has emerged as a promising strategy for this problem, as it enables LLMs to make selective use of the long context for efficient computation. However, existing RAG approaches lag behind other long-context processing methods due to inherent limitations on inaccurate retrieval and fragmented contexts. To address these challenges, we introduce RetroLM, a novel RAG framework for long-context processing. Unlike traditional methods, RetroLM employs KV-level retrieval augmentation, where it partitions the LLM's KV cache into contiguous pages and retrieves the most crucial ones for efficient computation. This approach enhances robustness to retrieval inaccuracy, facilitates effective utilization of fragmented contexts, and saves the cost from repeated computation. Building on this framework, we further develop a specialized retriever for precise retrieval of critical pages and conduct unsupervised post-training to optimize the model's ability to leverage retrieved information. We conduct comprehensive evaluations with a variety of benchmarks, including LongBench, InfiniteBench, and RULER, where RetroLM significantly outperforms existing long-context LLMs and efficient long-context processing methods, particularly in tasks requiring intensive reasoning or extremely long-context comprehension.

## 密码学和安全(cs.CR:Cryptography and Security)

### DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning 
[[arxiv](https://arxiv.org/abs/2502.11521)] [[cool](https://papers.cool/arxiv/2502.11521)] [[pdf](https://arxiv.org/pdf/2502.11521)]
> **Authors**: Juantao Zhong,Daoyuan Wu,Ye Liu,Maoyi Xie,Yang Liu,Yi Li,Ning Liu
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 密码学和安全,人工智能
- **Abstract**: DeFi (Decentralized Finance) is one of the most important applications of today's cryptocurrencies and smart contracts. It manages hundreds of billions in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi price manipulation attacks. Despite state-of-the-art (SOTA) systems like DeFiRanger and DeFort, we found that they are less effective to non-standard price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi price manipulation attacks reported over the past three years. In this paper, we introduce the first LLM-based approach, DeFiScope, for detecting DeFi price manipulation attacks in both standard and custom price models. Our insight is that large language models (LLMs) have certain intelligence to abstract price calculation from code and infer the trend of token price changes based on the extracted price models. To further strengthen LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it to fine-tune a DeFi price-specific LLM. Together with the high-level DeFi operations recovered from low-level transaction data, DeFiScope detects various DeFi price manipulations according to systematically mined patterns. Experimental results show that DeFiScope achieves a high precision of 96% and a recall rate of 80%, significantly outperforming SOTA approaches. Moreover, we evaluate DeFiScope's cost-effectiveness and demonstrate its practicality by helping our industry partner confirm 147 real-world price manipulation attacks, including discovering 81 previously unknown historical incidents.

### Optimized detection of cyber-attacks on IoT networks via hybrid deep learning models 
[[arxiv](https://arxiv.org/abs/2502.11470)] [[cool](https://papers.cool/arxiv/2502.11470)] [[pdf](https://arxiv.org/pdf/2502.11470)]
> **Authors**: Ahmed Bensaoud,Jugal Kalita
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: ef:deeplearningmodels." Ad Hoc Networks 170 (2025): 103770
- **标题**: None
- **领域**: 密码学和安全,人工智能
- **Abstract**: The rapid expansion of Internet of Things (IoT) devices has increased the risk of cyber-attacks, making effective detection essential for securing IoT networks. This work introduces a novel approach combining Self-Organizing Maps (SOMs), Deep Belief Networks (DBNs), and Autoencoders to detect known and previously unseen attack patterns. A comprehensive evaluation using simulated and real-world traffic data is conducted, with models optimized via Particle Swarm Optimization (PSO). The system achieves an accuracy of up to 99.99% and Matthews Correlation Coefficient (MCC) values exceeding 99.50%. Experiments on NSL-KDD, UNSW-NB15, and CICIoT2023 confirm the model's strong performance across diverse attack types. These findings suggest that the proposed method enhances IoT security by identifying emerging threats and adapting to evolving attack strategies.

## 计算机视觉和模式识别(cs.CV:Computer Vision and Pattern Recognition)

### Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos 
[[arxiv](https://arxiv.org/abs/2502.11481)] [[cool](https://papers.cool/arxiv/2502.11481)] [[pdf](https://arxiv.org/pdf/2502.11481)]
> **Authors**: Xiangxiang Cui,Zhongyu Li,Xiayue Fan,Peng Huang,Ying Wang,Meng Yang,Shi Chang,Jihua Zhu
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别,人工智能
- **Abstract**: The intersection of medical imaging and artificial intelligence has become an important research direction in intelligent medical treatment, particularly in the analysis of medical images using deep learning for clinical diagnosis. Despite the advances, existing keyframe classification methods lack extraction of time series features, while ultrasonic video classification based on three-dimensional convolution requires uniform frame numbers across patients, resulting in poor feature extraction efficiency and model classification performance. This study proposes a novel video classification method based on CNN and LSTM, introducing NLP's long and short sentence processing scheme into video classification for the first time. The method reduces CNN-extracted image features to 1x512 dimension, followed by sorting and compressing feature vectors for LSTM training. Specifically, feature vectors are sorted by patient video frame numbers and populated with padding value 0 to form variable batches, with invalid padding values compressed before LSTM training to conserve computing resources. Experimental results demonstrate that our variable-frame CNNLSTM method outperforms other approaches across all metrics, showing improvements of 3-6% in F1 score and 1.5% in specificity compared to keyframe methods. The variable-frame CNNLSTM also achieves better accuracy and precision than equal-frame CNNLSTM. These findings validate the effectiveness of our approach in classifying variable-frame ultrasound videos and suggest potential applications in other medical imaging modalities.

### Learning to Sample Effective and Diverse Prompts for Text-to-Image Generation 
[[arxiv](https://arxiv.org/abs/2502.11477)] [[cool](https://papers.cool/arxiv/2502.11477)] [[pdf](https://arxiv.org/pdf/2502.11477)]
> **Authors**: Taeyoung Yun,Dinghuai Zhang,Jinkyoo Park,Ling Pan
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 18 pages, 14 figures, 6 tables
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Recent advances in text-to-image diffusion models have achieved impressive image generation capabilities. However, it remains challenging to control the generation process with desired properties (e.g., aesthetic quality, user intention), which can be expressed as black-box reward functions. In this paper, we focus on prompt adaptation, which refines the original prompt into model-preferred prompts to generate desired images. While prior work uses reinforcement learning (RL) to optimize prompts, we observe that applying RL often results in generating similar postfixes and deterministic behaviors. To this end, we introduce \textbf{P}rompt \textbf{A}daptation with \textbf{G}FlowNets (\textbf{PAG}), a novel approach that frames prompt adaptation as a probabilistic inference problem. Our key insight is that leveraging Generative Flow Networks (GFlowNets) allows us to shift from reward maximization to sampling from an unnormalized density function, enabling both high-quality and diverse prompt generation. However, we identify that a naive application of GFlowNets suffers from mode collapse and uncovers a previously overlooked phenomenon: the progressive loss of neural plasticity in the model, which is compounded by inefficient credit assignment in sequential prompt generation. To address this critical challenge, we develop a systematic approach in PAG with flow reactivation, reward-prioritized sampling, and reward decomposition for prompt adaptation. Extensive experiments validate that PAG successfully learns to sample effective and diverse prompts for text-to-image generation. We also show that PAG exhibits strong robustness across various reward functions and transferability to different text-to-image models.

## 机器学习(cs.LG:Machine Learning)

### : A Modular World Model over Streams of Tokens 
[[arxiv](https://arxiv.org/abs/2502.11537)] [[cool](https://papers.cool/arxiv/2502.11537)] [[pdf](https://arxiv.org/pdf/2502.11537)]
> **Authors**: Lior Cohen,Kaixin Wang,Bingyi Kang,Uri Gadot,Shie Mannor
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Token-based world models emerged as a promising modular framework, modeling dynamics over token streams while optimizing tokenization separately. While successful in visual environments with discrete actions (e.g., Atari games), their broader applicability remains uncertain. In this paper, we introduce $\text{M}^{\text{3}}$, a $\textbf{m}$odular $\textbf{w}$orld $\textbf{m}$odel that extends this framework, enabling flexible combinations of observation and action modalities through independent modality-specific components. $\text{M}^{\text{3}}$ integrates several improvements from existing literature to enhance agent performance. Through extensive empirical evaluation across diverse benchmarks, $\text{M}^{\text{3}}$ achieves state-of-the-art sample efficiency for planning-free world models. Notably, among these methods, it is the first to reach a human-level median score on Atari 100K, with superhuman performance on 13 games. Our code and model weights are publicly available at https://github.com/leor-c/M3.

### MaZO: Masked Zeroth-Order Optimization for Multi-Task Fine-Tuning of Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.11513)] [[cool](https://papers.cool/arxiv/2502.11513)] [[pdf](https://arxiv.org/pdf/2502.11513)]
> **Authors**: Zhen Zhang,Yifan Yang,Kai Zhen,Nathan Susanj,Athanasios Mouchtaris,Siegfried Kunzmann,Zheng Zhang
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 17 pages
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Large language models have demonstrated exceptional capabilities across diverse tasks, but their fine-tuning demands significant memory, posing challenges for resource-constrained environments. Zeroth-order (ZO) optimization provides a memory-efficient alternative by eliminating the need for backpropagation. However, ZO optimization suffers from high gradient variance, and prior research has largely focused on single-task learning, leaving its application to multi-task learning unexplored. Multi-task learning is crucial for leveraging shared knowledge across tasks to improve generalization, yet it introduces unique challenges under ZO settings, such as amplified gradient variance and collinearity. In this paper, we present MaZO, the first framework specifically designed for multi-task LLM fine-tuning under ZO optimization. MaZO tackles these challenges at the parameter level through two key innovations: a weight importance metric to identify critical parameters and a multi-task weight update mask to selectively update these parameters, reducing the dimensionality of the parameter space and mitigating task conflicts. Experiments demonstrate that MaZO achieves state-of-the-art performance, surpassing even multi-task learning methods designed for first-order optimization.

### DifCluE: Generating Counterfactual Explanations with Diffusion Autoencoders and modal clustering 
[[arxiv](https://arxiv.org/abs/2502.11509)] [[cool](https://papers.cool/arxiv/2502.11509)] [[pdf](https://arxiv.org/pdf/2502.11509)]
> **Authors**: Suparshva Jain,Amit Sangroya,Lovekesh Vig
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Generating multiple counterfactual explanations for different modes within a class presents a significant challenge, as these modes are distinct yet converge under the same classification. Diffusion probabilistic models (DPMs) have demonstrated a strong ability to capture the underlying modes of data distributions. In this paper, we harness the power of a Diffusion Autoencoder to generate multiple distinct counterfactual explanations. By clustering in the latent space, we uncover the directions corresponding to the different modes within a class, enabling the generation of diverse and meaningful counterfactuals. We introduce a novel methodology, DifCluE, which consistently identifies these modes and produces more reliable counterfactual explanations. Our experimental results demonstrate that DifCluE outperforms the current state-of-the-art in generating multiple counterfactual explanations, offering a significant advancement in model interpretability.

### Learning Surrogate Potential Mean Field Games via Gaussian Processes: A Data-Driven Approach to Ill-Posed Inverse Problems 
[[arxiv](https://arxiv.org/abs/2502.11506)] [[cool](https://papers.cool/arxiv/2502.11506)] [[pdf](https://arxiv.org/pdf/2502.11506)]
> **Authors**: Jingguo Zhang,Xianjin Yang,Chenchen Mou,Chao Zhou
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 36 pages
- **标题**: None
- **领域**: 机器学习,优化与控制,机器学习
- **Abstract**: Mean field games (MFGs) describe the collective behavior of large populations of interacting agents. In this work, we tackle ill-posed inverse problems in potential MFGs, aiming to recover the agents' population, momentum, and environmental setup from limited, noisy measurements and partial observations. These problems are ill-posed because multiple MFG configurations can explain the same data, or different parameters can yield nearly identical observations. Nonetheless, they remain crucial in practice for real-world scenarios where data are inherently sparse or noisy, or where the MFG structure is not fully determined. Our focus is on finding surrogate MFGs that accurately reproduce the observed data despite these challenges. We propose two Gaussian process (GP)-based frameworks: an inf-sup formulation and a bilevel approach. The choice between them depends on whether the unknown parameters introduce concavity in the objective. In the inf-sup framework, we use the linearity of GPs and their parameterization structure to maintain convex-concave properties, allowing us to apply standard convex optimization algorithms. In the bilevel framework, we employ a gradient-descent-based algorithm and introduce two methods for computing the outer gradient. The first method leverages an existing solver for the inner potential MFG and applies automatic differentiation, while the second adopts an adjoint-based strategy that computes the outer gradient independently of the inner solver. Our numerical experiments show that when sufficient prior information is available, the unknown parameters can be accurately recovered. Otherwise, if prior information is limited, the inverse problem is ill-posed, but our frameworks can still produce surrogate MFG models that closely match observed data.

### A GNN-based Spectral Filtering Mechanism for Imbalance Classification in Network Digital Twin 
[[arxiv](https://arxiv.org/abs/2502.11505)] [[cool](https://papers.cool/arxiv/2502.11505)] [[pdf](https://arxiv.org/pdf/2502.11505)]
> **Authors**: Abubakar Isah,Ibrahim Aliyu,Sulaiman Muhammad Rashid,Jaehyung Park,Minsoo Hahn,Jinsul Kim
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: arXiv admin note: substantial text overlap with arXiv:2406.06595
- **标题**: None
- **领域**: 机器学习,网络和互联网架构
- **Abstract**: Graph Neural Networks are gaining attention in Fifth-Generation (5G) core network digital twins, which are data-driven complex systems with numerous components. Analyzing these data can be challenging due to rare failure types, leading to imbalanced classification in multiclass settings. Digital twins of 5G networks increasingly employ graph classification as the main method for identifying failure types. However, the skewed distribution of failure occurrences is a major class imbalance issue that prevents effective graph data mining. Previous studies have not sufficiently tackled this complex problem. In this paper, we propose Class-Fourier Graph Neural Network (CF-GNN) introduces a class-oriented spectral filtering mechanism that ensures precise classification by estimating a unique spectral filter for each class. We employ eigenvalue and eigenvector spectral filtering to capture and adapt to variations in the minority classes, ensuring accurate class-specific feature discrimination, and adept at graph representation learning for complex local structures among neighbors in an end-to-end setting. Extensive experiments have demonstrated that the proposed CF-GNN could help with both the creation of new techniques for enhancing classifiers and the investigation of the characteristics of the multi-class imbalanced data in a network digital twin system.

### Accelerated Gradient-based Design Optimization Via Differentiable Physics-Informed Neural Operator: A Composites Autoclave Processing Case Study 
[[arxiv](https://arxiv.org/abs/2502.11504)] [[cool](https://papers.cool/arxiv/2502.11504)] [[pdf](https://arxiv.org/pdf/2502.11504)]
> **Authors**: Janak M. Patel,Milad Ramezankhani,Anirudh Deodhar,Dagnachew Birru
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 15 pages, 7 figures
- **标题**: None
- **领域**: 机器学习,人工智能,数值分析
- **Abstract**: Simulation and optimization are crucial for advancing the engineering design of complex systems and processes. Traditional optimization methods require substantial computational time and effort due to their reliance on resource-intensive simulations, such as finite element analysis, and the complexity of rigorous optimization algorithms. Data-agnostic AI-based surrogate models, such as Physics-Informed Neural Operators (PINOs), offer a promising alternative to these conventional simulations, providing drastically reduced inference time, unparalleled data efficiency, and zero-shot super-resolution capability. However, the predictive accuracy of these models is often constrained to small, low-dimensional design spaces or systems with relatively simple dynamics. To address this, we introduce a novel Physics-Informed DeepONet (PIDON) architecture, which extends the capabilities of conventional neural operators to effectively model the nonlinear behavior of complex engineering systems across high-dimensional design spaces and a wide range of dynamic design configurations. This new architecture outperforms existing SOTA models, enabling better predictions across broader design spaces. Leveraging PIDON's differentiability, we integrate a gradient-based optimization approach using the Adam optimizer to efficiently determine optimal design variables. This forms an end-to-end gradient-based optimization framework that accelerates the design process while enhancing scalability and efficiency. We demonstrate the effectiveness of this framework in the optimization of aerospace-grade composites curing processes achieving a 3x speedup in obtaining optimal design variables compared to gradient-free methods. Beyond composites processing, the proposed model has the potential to be used as a scalable and efficient optimization tool for broader applications in advanced engineering and digital twin systems.

### GPU-accelerated Multi-relational Parallel Graph Retrieval for Web-scale Recommendations 
[[arxiv](https://arxiv.org/abs/2502.11490)] [[cool](https://papers.cool/arxiv/2502.11490)] [[pdf](https://arxiv.org/pdf/2502.11490)]
> **Authors**: Zhuoning Guo,Guangxing Chen,Qian Gao,Xiaochao Liao,Jianjia Zheng,Lu Shen,Hao Liu
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,分布式、并行和集群计算,信息检索
- **Abstract**: Web recommendations provide personalized items from massive catalogs for users, which rely heavily on retrieval stages to trade off the effectiveness and efficiency of selecting a small relevant set from billion-scale candidates in online digital platforms. As one of the largest Chinese search engine and news feed providers, Baidu resorts to Deep Neural Network (DNN) and graph-based Approximate Nearest Neighbor Search (ANNS) algorithms for accurate relevance estimation and efficient search for relevant items. However, current retrieval at Baidu fails in comprehensive user-item relational understanding due to dissected interaction modeling, and performs inefficiently in large-scale graph-based ANNS because of suboptimal traversal navigation and the GPU computational bottleneck under high concurrency. To this end, we propose a GPU-accelerated Multi-relational Parallel Graph Retrieval (GMP-GR) framework to achieve effective yet efficient retrieval in web-scale recommendations. First, we propose a multi-relational user-item relevance metric learning method that unifies diverse user behaviors through multi-objective optimization and employs a self-covariant loss to enhance pathfinding performance. Second, we develop a hierarchical parallel graph-based ANNS to boost graph retrieval throughput, which conducts breadth-depth-balanced searches on a large-scale item graph and cost-effectively handles irregular neural computation via adaptive aggregation on GPUs. In addition, we integrate system optimization strategies in the deployment of GMP-GR in Baidu. Extensive experiments demonstrate the superiority of GMP-GR in retrieval accuracy and efficiency. Deployed across more than twenty applications at Baidu, GMP-GR serves hundreds of millions of users with a throughput exceeding one hundred million requests per second.

### Dictionary-Learning-Based Data Pruning for System Identification 
[[arxiv](https://arxiv.org/abs/2502.11484)] [[cool](https://papers.cool/arxiv/2502.11484)] [[pdf](https://arxiv.org/pdf/2502.11484)]
> **Authors**: Tingna Wang,Sikai Zhang,Limin Sun
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,系统与控制
- **Abstract**: System identification is normally involved in augmenting time series data by time shifting and nonlinearisation (via polynomial basis), which introduce redundancy both feature-wise and sample-wise. Many research works focus on reducing redundancy feature-wise, while less attention is paid to sample-wise redundancy. This paper proposes a novel data pruning method, called (mini-batch) FastCan, to reduce sample-wise redundancy based on dictionary learning. Time series data is represented by some representative samples, called atoms, via dictionary learning. The useful samples are selected based on their correlation with the atoms. The method is tested on one simulated dataset and two benchmark datasets. The R-squared between the coefficients of models trained on the full and the coefficients of models trained on pruned datasets is adopted to evaluate the performance of data pruning methods. It is found that the proposed method significantly outperforms the random pruning method.

### No-regret incentive-compatible online learning under exact truthfulness with non-myopic experts 
[[arxiv](https://arxiv.org/abs/2502.11483)] [[cool](https://papers.cool/arxiv/2502.11483)] [[pdf](https://arxiv.org/pdf/2502.11483)]
> **Authors**: Junpei Komiyama,Nishant A. Mehta,Ali Mortazavi
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 44 pages
- **标题**: None
- **领域**: 机器学习,计算机科学与博弈论,机器学习
- **Abstract**: We study an online forecasting setting in which, over $T$ rounds, $N$ strategic experts each report a forecast to a mechanism, the mechanism selects one forecast, and then the outcome is revealed. In any given round, each expert has a belief about the outcome, but the expert wishes to select its report so as to maximize the total number of times it is selected. The goal of the mechanism is to obtain low belief regret: the difference between its cumulative loss (based on its selected forecasts) and the cumulative loss of the best expert in hindsight (as measured by the experts' beliefs). We consider exactly truthful mechanisms for non-myopic experts, meaning that truthfully reporting its belief strictly maximizes the expert's subjective probability of being selected in any future round. Even in the full-information setting, it is an open problem to obtain the first no-regret exactly truthful mechanism in this setting. We develop the first no-regret mechanism for this setting via an online extension of the Independent-Event Lotteries Forecasting Competition Mechanism (I-ELF). By viewing this online I-ELF as a novel instance of Follow the Perturbed Leader (FPL) with noise based on random walks with loss-dependent perturbations, we obtain $\tilde{O}(\sqrt{T N})$ regret. Our results are fueled by new tail bounds for Poisson binomial random variables that we develop. We extend our results to the bandit setting, where we give an exactly truthful mechanism obtaining $\tilde{O}(T^{2/3} N^{1/3})$ regret; this is the first no-regret result even among approximately truthful mechanisms.

### DATA: Decomposed Attention-based Task Adaptation for Rehearsal-Free Continual Learning 
[[arxiv](https://arxiv.org/abs/2502.11482)] [[cool](https://papers.cool/arxiv/2502.11482)] [[pdf](https://arxiv.org/pdf/2502.11482)]
> **Authors**: Huanxuan Liao,Shizhu He,Yupu Hao,Jun Zhao,Kang Liu
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,计算语言学
- **Abstract**: Continual learning (CL) is essential for Large Language Models (LLMs) to adapt to evolving real-world demands, yet they are susceptible to catastrophic forgetting (CF). While traditional CF solutions rely on expensive data rehearsal, recent rehearsal-free methods employ model-based and regularization-based strategies to address this issue. However, these approaches often neglect the model's plasticity, which is crucial to achieving optimal performance on newly learned tasks. Consequently, a key challenge in CL is striking a balance between preserving plasticity and mitigating CF. To tackle this challenge, we propose the $\textbf{D}$ecomposed $\textbf{A}$ttention-based $\textbf{T}$ask $\textbf{A}$daptation (DATA), which explicitly decouples and learns both task-specific and task-shared knowledge using high-rank and low-rank task adapters (e.g., LoRAs). For new tasks, DATA dynamically adjusts the weights of adapters of different ranks based on their relevance and distinction from previous tasks, allowing the model to acquire new task-specific skills while effectively retaining previously learned knowledge. Specifically, we implement a decomposed component weighting strategy comprising learnable components that collectively generate attention-based weights, allowing the model to integrate and utilize diverse knowledge from each DATA. Extensive experiments on three widely used benchmarks demonstrate that our proposed method achieves state-of-the-art performance. Notably, our approach significantly enhances model plasticity and mitigates CF by extending learnable components and employing stochastic restoration during training iterations.

### Enhancing Offline Model-Based RL via Active Model Selection: A Bayesian Optimization Perspective 
[[arxiv](https://arxiv.org/abs/2502.11480)] [[cool](https://papers.cool/arxiv/2502.11480)] [[pdf](https://arxiv.org/pdf/2502.11480)]
> **Authors**: Yu-Wei Yang,Yun-Ming Chan,Wei Hung,Xi Liu,Ping-Chun Hsieh
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 18 pages, 6 figures
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: Offline model-based reinforcement learning (MBRL) serves as a competitive framework that can learn well-performing policies solely from pre-collected data with the help of learned dynamics models. To fully unleash the power of offline MBRL, model selection plays a pivotal role in determining the dynamics model utilized for downstream policy learning. However, offline MBRL conventionally relies on validation or off-policy evaluation, which are rather inaccurate due to the inherent distribution shift in offline RL. To tackle this, we propose BOMS, an active model selection framework that enhances model selection in offline MBRL with only a small online interaction budget, through the lens of Bayesian optimization (BO). Specifically, we recast model selection as BO and enable probabilistic inference in BOMS by proposing a novel model-induced kernel, which is theoretically grounded and computationally efficient. Through extensive experiments, we show that BOMS improves over the baseline methods with a small amount of online interaction comparable to only $1\%$-$2.5\%$ of offline training data on various RL tasks.

### Approximation of Permutation Invariant Polynomials by Transformers: Efficient Construction in Column-Size 
[[arxiv](https://arxiv.org/abs/2502.11467)] [[cool](https://papers.cool/arxiv/2502.11467)] [[pdf](https://arxiv.org/pdf/2502.11467)]
> **Authors**: Naoki Takeshita,Masaaki Imaizumi
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 29 pages
- **标题**: None
- **领域**: 机器学习,泛函分析
- **Abstract**: Transformers are a type of neural network that have demonstrated remarkable performance across various domains, particularly in natural language processing tasks. Motivated by this success, research on the theoretical understanding of transformers has garnered significant attention. A notable example is the mathematical analysis of their approximation power, which validates the empirical expressive capability of transformers. In this study, we investigate the ability of transformers to approximate column-symmetric polynomials, an extension of symmetric polynomials that take matrices as input. Consequently, we establish an explicit relationship between the size of the transformer network and its approximation capability, leveraging the parameter efficiency of transformers and their compatibility with symmetry by focusing on the algebraic properties of symmetric polynomials.

### GiFT: Gibbs Fine-Tuning for Code Generation 
[[arxiv](https://arxiv.org/abs/2502.11466)] [[cool](https://papers.cool/arxiv/2502.11466)] [[pdf](https://arxiv.org/pdf/2502.11466)]
> **Authors**: Haochen Li,Wanjin Feng,Xin Zhou,Zhiqi Shen
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,计算语言学,软件工程
- **Abstract**: Training Large Language Models (LLMs) with synthetic data is a prevalent practice in code generation. A key approach is self-training, where LLMs are iteratively trained on self-generated correct code snippets. In this case, the self-generated codes are drawn from a conditional distribution, conditioned on a specific seed description. However, the seed description is not the only valid representation that aligns with its intended meaning. With all valid descriptions and codes forming a joint space, codes drawn from the conditional distribution would lead to an underrepresentation of the full description-code space. As such, we propose Gibbs Fine-Tuning (GiFT), a novel self-training method inspired by Gibbs sampling. GiFT allows self-generated data to be drawn from the marginal distribution of the joint space, thereby mitigating the biases inherent in conditional sampling. We provide a theoretical analysis demonstrating the potential benefits of fine-tuning LLMs with code derived from the marginal distribution. Furthermore, we propose a perplexity-based code selection method to mitigate the imbalanced long-tail distribution of the self-generated codes. Empirical evaluation of two LLMs across four datasets demonstrates that GiFT achieves superior performance, particularly on more challenging benchmarks.

### Towards Efficient Pre-training: Exploring FP4 Precision in Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.11458)] [[cool](https://papers.cool/arxiv/2502.11458)] [[pdf](https://arxiv.org/pdf/2502.11458)]
> **Authors**: Jiecheng Zhou,Ding Tang,Rong Fu,Boni Hu,Haoran Xu,Yi Wang,Zhilin Pei,Zhongling Su,Liang Liu,Xingcheng Zhang,Weiming Zhang
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 8 pages, 2 figure
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: The burgeoning computational demands for training large language models (LLMs) necessitate efficient methods, including quantized training, which leverages low-bit arithmetic operations to reduce costs. While FP8 precision has shown potential, leveraging FP4 remains challenging due to inherent quantization errors and limited representation capability. Based on the Transformer architecture, we present an FP4 training scheme for LLMs, overcoming these obstacles through mixed-precision quantization strategies tailed for different modules and training stages. This allows us to apply the precision level suitable to distinct components within the model, ensuring that multi-head attention and linear layers are handled appropriately. Our pretraining recipe ensures stability in backpropagation by incorporating fine-grained quantization methods with a target precision training schedule. Experimental results demonstrate that our FP4 training scheme achieves accuracy comparable to BF16 and FP8, with smaller theoretical computational cost. With the advent of next-generation hardware supporting FP4, our method sets the foundation for efficient ultra-low precision training.

### Connector-S: A Survey of Connectors in Multi-modal Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.11453)] [[cool](https://papers.cool/arxiv/2502.11453)] [[pdf](https://arxiv.org/pdf/2502.11453)]
> **Authors**: Xun Zhu,Zheng Zhang,Xi Chen,Yiming Shi,Miao Li,Ji Wu
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: With the rapid advancements in multi-modal large language models (MLLMs), connectors play a pivotal role in bridging diverse modalities and enhancing model performance. However, the design and evolution of connectors have not been comprehensively analyzed, leaving gaps in understanding how these components function and hindering the development of more powerful connectors. In this survey, we systematically review the current progress of connectors in MLLMs and present a structured taxonomy that categorizes connectors into atomic operations (mapping, compression, mixture of experts) and holistic designs (multi-layer, multi-encoder, multi-modal scenarios), highlighting their technical contributions and advancements. Furthermore, we discuss several promising research frontiers and challenges, including high-resolution input, dynamic compression, guide information selection, combination strategy, and interpretability. This survey is intended to serve as a foundational reference and a clear roadmap for researchers, providing valuable insights into the design and optimization of next-generation connectors to enhance the performance and adaptability of MLLMs.

### Fishing For Cheap And Efficient Pruners At Initialization 
[[arxiv](https://arxiv.org/abs/2502.11450)] [[cool](https://papers.cool/arxiv/2502.11450)] [[pdf](https://arxiv.org/pdf/2502.11450)]
> **Authors**: Ivo Gollini Navarrete,Nicolas Mauricio Cuadrado,Jose Renato Restom,Martin Takáč,Samuel Horváth
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 8 pages of main content (excluding references), 2 figures, 2 tables, 1 algorithm, and 11 pages of appendix. Code available at https://github.com/Gollini/Fisher_Taylor_Sensitivity
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Pruning offers a promising solution to mitigate the associated costs and environmental impact of deploying large deep neural networks (DNNs). Traditional approaches rely on computationally expensive trained models or time-consuming iterative prune-retrain cycles, undermining their utility in resource-constrained settings. To address this issue, we build upon the established principles of saliency (LeCun et al., 1989) and connection sensitivity (Lee et al., 2018) to tackle the challenging problem of one-shot pruning neural networks (NNs) before training (PBT) at initialization. We introduce Fisher-Taylor Sensitivity (FTS), a computationally cheap and efficient pruning criterion based on the empirical Fisher Information Matrix (FIM) diagonal, offering a viable alternative for integrating first- and second-order information to identify a model's structurally important parameters. Although the FIM-Hessian equivalency only holds for convergent models that maximize the likelihood, recent studies (Karakida et al., 2019) suggest that, even at initialization, the FIM captures essential geometric information of parameters in overparameterized NNs, providing the basis for our method. Finally, we demonstrate empirically that layer collapse, a critical limitation of data-dependent pruning methodologies, is easily overcome by pruning within a single training epoch after initialization. We perform experiments on ResNet18 and VGG19 with CIFAR-10 and CIFAR-100, widely used benchmarks in pruning research. Our method achieves competitive performance against state-of-the-art techniques for one-shot PBT, even under extreme sparsity conditions. Our code is made available to the public.

### Does Editing Provide Evidence for Localization? 
[[arxiv](https://arxiv.org/abs/2502.11447)] [[cool](https://papers.cool/arxiv/2502.11447)] [[pdf](https://arxiv.org/pdf/2502.11447)]
> **Authors**: Zihao Wang,Victor Veitch
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: :68T50ACM Class:I.2.7; I.2.6; F.1.1
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: A basic aspiration for interpretability research in large language models is to "localize" semantically meaningful behaviors to particular components within the LLM. There are various heuristics for finding candidate locations within the LLM. Once a candidate localization is found, it can be assessed by editing the internal representations at the corresponding localization and checking whether this induces model behavior that is consistent with the semantic interpretation of the localization. The question we address here is: how strong is the evidence provided by such edits? To evaluate the localization claim, we want to assess the effect of the optimal intervention at a particular location. The key new technical tool is a way of adapting LLM alignment techniques to find such optimal localized edits. With this tool in hand, we give an example where the edit-based evidence for localization appears strong, but where localization clearly fails. Indeed, we find that optimal edits at random localizations can be as effective as aligning the full model. In aggregate, our results suggest that merely observing that localized edits induce targeted changes in behavior provides little to no evidence that these locations actually encode the target behavior.

## 多代理系统(cs.MA:Multiagent Systems)

### Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review 
[[arxiv](https://arxiv.org/abs/2502.11518)] [[cool](https://papers.cool/arxiv/2502.11518)] [[pdf](https://arxiv.org/pdf/2502.11518)]
> **Authors**: Di Wu,Xian Wei,Guang Chen,Hao Shen,Xiangfeng Wang,Wenhao Li,Bo Jin
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: 18 pages
- **标题**: None
- **领域**: 多代理系统,人工智能,机器学习
- **Abstract**: Embodied multi-agent systems (EMAS) have attracted growing attention for their potential to address complex, real-world challenges in areas such as logistics and robotics. Recent advances in foundation models pave the way for generative agents capable of richer communication and adaptive problem-solving. This survey provides a systematic examination of how EMAS can benefit from these generative capabilities. We propose a taxonomy that categorizes EMAS by system architectures and embodiment modalities, emphasizing how collaboration spans both physical and virtual contexts. Central building blocks, perception, planning, communication, and feedback, are then analyzed to illustrate how generative techniques bolster system robustness and flexibility. Through concrete examples, we demonstrate the transformative effects of integrating foundation models into embodied, multi-agent frameworks. Finally, we discuss challenges and future directions, underlining the significant promise of EMAS to reshape the landscape of AI-driven collaboration.

## 声音(cs.SD:Sound)

### TAPS: Throat and Acoustic Paired Speech Dataset for Deep Learning-Based Speech Enhancement 
[[arxiv](https://arxiv.org/abs/2502.11478)] [[cool](https://papers.cool/arxiv/2502.11478)] [[pdf](https://arxiv.org/pdf/2502.11478)]
> **Authors**: Yunsik Kim,Yonghun Song,Yoonyoung Chung
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 声音,机器学习,音频和语音处理
- **Abstract**: In high-noise environments such as factories, subways, and busy streets, capturing clear speech is challenging due to background noise. Throat microphones provide a solution with their noise-suppressing properties, reducing the noise while recording speech. However, a significant limitation remains: high-frequency information is attenuated as sound waves pass through skin and tissue, reducing speech clarity. Recent deep learning approaches have shown promise in enhancing throat microphone recordings, but further progress is constrained by the absence of standardized dataset. We introduce a throat and acoustic paired speech dataset (TAPS), a collection of paired utterances recorded from 60 native Korean speakers using throat and acoustic microphones. To demonstrate the TAPS's utility, we tested three baseline deep learning models and identified the mapping-based approach as superior in improving speech quality and restoring content. Additionally, we propose an optimal method to mitigate the signal mismatch between throat and acoustic microphones, ensuring model performance. These results highlight the potential of TAPS to serve as a standardized dataset and advance research in throat microphone-based speech enhancement.

## 社交和信息网络(cs.SI:Social and Information Networks)

### UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs 
[[arxiv](https://arxiv.org/abs/2502.11519)] [[cool](https://papers.cool/arxiv/2502.11519)] [[pdf](https://arxiv.org/pdf/2502.11519)]
> **Authors**: Hao Li,Hao Jiang,Yuke Zheng,Hao Sun,Wenying Gong
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: WWW2025
- **标题**: None
- **领域**: 社交和信息网络,人工智能
- **Abstract**: Polarization and fragmentation in social media amplify user biases, making it increasingly important to understand the evolution of opinions. Opinion dynamics provide interpretability for studying opinion evolution, yet incorporating these insights into predictive models remains challenging. This challenge arises due to the inherent complexity of the diversity of opinion fusion rules and the difficulty in capturing equilibrium states while avoiding over-smoothing. This paper constructs a unified opinion dynamics model to integrate different opinion fusion rules and generates corresponding synthetic datasets. To fully leverage the advantages of unified opinion dynamics, we introduces UniGO, a framework for modeling opinion evolution on graphs. Using a coarsen-refine mechanism, UniGO efficiently models opinion dynamics through a graph neural network, mitigating over-smoothing while preserving equilibrium phenomena. UniGO leverages pretraining on synthetic datasets, which enhances its ability to generalize to real-world scenarios, providing a viable paradigm for applications of opinion dynamics. Experimental results on both synthetic and real-world datasets demonstrate UniGO's effectiveness in capturing complex opinion formation processes and predicting future evolution. The pretrained model also shows strong generalization capability, validating the benefits of using synthetic data to boost real-world performance.

## 音频和语音处理(eess.AS:Audio and Speech Processing)

### LMFCA-Net: A Lightweight Model for Multi-Channel Speech Enhancement with Efficient Narrow-Band and Cross-Band Attention 
[[arxiv](https://arxiv.org/abs/2502.11462)] [[cool](https://papers.cool/arxiv/2502.11462)] [[pdf](https://arxiv.org/pdf/2502.11462)]
> **Authors**: Yaokai Zhang,Hanchen Pei,Wanqi Wang,Gongping Huang
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: Accepted at ICASSP 2025
- **标题**: None
- **领域**: 音频和语音处理,机器学习,声音
- **Abstract**: Deep learning based end-to-end multi-channel speech enhancement methods have achieved impressive performance by leveraging sub-band, cross-band, and spatial information. However, these methods often demand substantial computational resources, limiting their practicality on terminal devices. This paper presents a lightweight multi-channel speech enhancement network with decoupled fully connected attention (LMFCA-Net). The proposed LMFCA-Net introduces time-axis decoupled fully-connected attention (T-FCA) and frequency-axis decoupled fully-connected attention (F-FCA) mechanisms to effectively capture long-range narrow-band and cross-band information without recurrent units. Experimental results show that LMFCA-Net performs comparably to state-of-the-art methods while significantly reducing computational complexity and latency, making it a promising solution for practical applications.

## 机器学习(stat.ML:Machine Learning)

### All Models Are Miscalibrated, But Some Less So: Comparing Calibration with Conditional Mean Operators 
[[arxiv](https://arxiv.org/abs/2502.11465)] [[cool](https://papers.cool/arxiv/2502.11465)] [[pdf](https://arxiv.org/pdf/2502.11465)]
> **Authors**: Peter Moskvichev,Dino Sejdinovic
> **First submission**: 2025-02-17
> **First announcement**: 2025-02-18
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: When working in a high-risk setting, having well calibrated probabilistic predictive models is a crucial requirement. However, estimators for calibration error are not always able to correctly distinguish which model is better calibrated. We propose the \emph{conditional kernel calibration error} (CKCE) which is based on the Hilbert-Schmidt norm of the difference between conditional mean operators. By working directly with the definition of strong calibration as the distance between conditional distributions, which we represent by their embeddings in reproducing kernel Hilbert spaces, the CKCE is less sensitive to the marginal distribution of predictive models. This makes it more effective for relative comparisons than previously proposed calibration metrics. Our experiments, using both synthetic and real data, show that CKCE provides a more consistent ranking of models by their calibration error and is more robust against distribution shift.

## 其他论文

- [Anti-Degeneracy Scheme for Lidar SLAM based on Particle Filter in Geometry Feature-Less Environments](https://arxiv.org/abs/2502.11486)
  - **标题**: None
  - **Filtered Reason**: none of cs.RO in whitelist
- [BagChain: A Dual-functional Blockchain Leveraging Bagging-based Distributed Learning](https://arxiv.org/abs/2502.11464)
  - **标题**: None
  - **Filtered Reason**: none of cs.DC in whitelist
- [Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training](https://arxiv.org/abs/2502.11455)
  - **标题**: None
  - **Filtered Reason**: none of cs.CR in whitelist
