> 本文由 [https://github.com/huiyeruzhou/arxiv_crawler](https://github.com/huiyeruzhou/arxiv_crawler) 自动生成
>
> 领域白名单：cs.AI,cs.CL,cs.LG,cs.CV
> 关键词： LLM, GPT, AI, language+model, deep+learning, transformer, neural+network, machine+learning

# 论文全览：2025-02-20

共有44篇相关领域论文, 另有6篇其他

## 计算语言学(cs.CL:Computation and Language)

### Adapting Large Language Models for Time Series Modeling via a Novel Parameter-efficient Adaptation Method 
[[arxiv](https://arxiv.org/abs/2502.13725)] [[cool](https://papers.cool/arxiv/2502.13725)] [[pdf](https://arxiv.org/pdf/2502.13725)]
> **Authors**: Juyuan Zhang,Wei Zhu,Jiechao Gao
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Time series modeling holds significant importance in many real-world applications and has been extensively studied. While pre-trained foundation models have made impressive strides in the fields of natural language processing (NLP) and computer vision (CV), their development in time series domains has been constrained by data sparsity. A series of recent studies have demonstrated that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the current literature have yet striked a high-quality balance between (a) effectively aligning the time series and natural language modalities, and (b) keeping the inference efficiency. To address the above issues, we now propose the Time-LlaMA framework. Time-LlaMA first converts the time series input into token embeddings through a linear tokenization mechanism. Second, the time series token embeddings are aligned with the text prompts. Third, to further adapt the LLM backbone for time series modeling, we have developed a dynamic low-rank adaptation technique (D-LoRA). D-LoRA dynamically chooses the most suitable LoRA modules at each layer of the Transformer backbone for each time series input, enhancing the model's predictive capabilities. Our experimental results on an extensive collection of challenging real-world time series tasks confirm that our proposed method achieves the state-of-the-art (SOTA) performance.

### Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values 
[[arxiv](https://arxiv.org/abs/2502.13723)] [[cool](https://papers.cool/arxiv/2502.13723)] [[pdf](https://arxiv.org/pdf/2502.13723)]
> **Authors**: Hongbo Zhang,Han Cui,Guangsheng Bao,Linyi Yang,Jun Wang,Yue Zhang
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: preprint
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: We introduce Direct Value Optimization (DVO), an innovative reinforcement learning framework for enhancing large language models in complex reasoning tasks. Unlike traditional methods relying on preference labels, DVO utilizes value signals at individual reasoning steps, optimizing models via a mean squared error loss. The key benefit of DVO lies in its fine-grained supervision, circumventing the need for labor-intensive human annotations. Target values within the DVO are estimated using either Monte Carlo Tree Search or an outcome value model. Our empirical analysis on both mathematical and commonsense reasoning tasks shows that DVO consistently outperforms existing offline preference optimization techniques, even with fewer training steps. These findings underscore the importance of value signals in advancing reasoning capabilities and highlight DVO as a superior methodology under scenarios lacking explicit human preference information.

### Multi-Scale and Multi-Objective Optimization for Cross-Lingual Aspect-Based Sentiment Analysis 
[[arxiv](https://arxiv.org/abs/2502.13718)] [[cool](https://papers.cool/arxiv/2502.13718)] [[pdf](https://arxiv.org/pdf/2502.13718)]
> **Authors**: Chengyan Wu,Bolei Ma,Ningyuan Deng,Yanqing He,Yun Xue
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Aspect-based sentiment analysis (ABSA) is a sequence labeling task that has garnered growing research interest in multilingual contexts. However, recent studies lack more robust feature alignment and finer aspect-level alignment. In this paper, we propose a novel framework, Multi-Scale and Multi-Objective optimization (MSMO) for cross-lingual ABSA. During multi-scale alignment, we achieve cross-lingual sentence-level and aspect-level alignment, aligning features of aspect terms in different contextual environments. Specifically, we introduce code-switched bilingual sentences into the language discriminator and consistency training modules to enhance the model's robustness. During multi-objective optimization, we design two optimization objectives: supervised training and consistency training, aiming to enhance cross-lingual semantic alignment. To further improve model performance, we incorporate distilled knowledge of the target language into the model. Results show that MSMO significantly enhances cross-lingual ABSA by achieving state-of-the-art performance across multiple languages and models.

### Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora 
[[arxiv](https://arxiv.org/abs/2502.13691)] [[cool](https://papers.cool/arxiv/2502.13691)] [[pdf](https://arxiv.org/pdf/2502.13691)]
> **Authors**: Tristan Karch,Luca Engel,Philippe Schwaller,Frédéric Kaplan
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: As large language models (LLMs) converge towards similar capabilities, the key to advancing their performance lies in identifying and incorporating valuable new information sources. However, evaluating which text collections are worth the substantial investment required for digitization, preprocessing, and integration into LLM systems remains a significant challenge. We present a novel approach to this challenge: an automated pipeline that evaluates the potential information gain from text collections without requiring model training or fine-tuning. Our method generates multiple choice questions (MCQs) from texts and measures an LLM's performance both with and without access to the source material. The performance gap between these conditions serves as a proxy for the collection's information potential. We validate our approach using three strategically selected datasets: EPFL PhD manuscripts (likely containing novel specialized knowledge), Wikipedia articles (presumably part of training data), and a synthetic baseline dataset. Our results demonstrate that this method effectively identifies collections containing valuable novel information, providing a practical tool for prioritizing data acquisition and integration efforts.

### MoM: Linear Sequence Modeling with Mixture-of-Memories 
[[arxiv](https://arxiv.org/abs/2502.13685)] [[cool](https://papers.cool/arxiv/2502.13685)] [[pdf](https://arxiv.org/pdf/2502.13685)]
> **Authors**: Jusen Du,Weigao Sun,Disen Lan,Jiaxi Hu,Yu Cheng
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: Technical report, 14 pages
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: Linear sequence modeling methods, such as linear attention, state space modeling, and linear RNNs, offer significant efficiency improvements by reducing the complexity of training and inference. However, these methods typically compress the entire input sequence into a single fixed-size memory state, which leads to suboptimal performance on recall-intensive downstream tasks. Drawing inspiration from neuroscience, particularly the brain's ability to maintain robust long-term memory while mitigating "memory interference", we introduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes multiple independent memory states, with a router network directing input tokens to specific memory states. This approach greatly enhances the overall memory capacity while minimizing memory interference. As a result, MoM performs exceptionally well on recall-intensive tasks, surpassing existing linear sequence modeling techniques. Despite incorporating multiple memory states, the computation of each memory state remains linear in complexity, allowing MoM to retain the linear-complexity advantage during training, while constant-complexity during inference. Our experimental results show that MoM significantly outperforms current linear sequence models on downstream language tasks, particularly recall-intensive tasks, and even achieves performance comparable to Transformer models. The code is released at https://github.com/OpenSparseLLMs/MoM and is also released as a part of https://github.com/OpenSparseLLMs/Linear-MoE.

### SCOPE: A Self-supervised Framework for Improving Faithfulness in Conditional Text Generation 
[[arxiv](https://arxiv.org/abs/2502.13674)] [[cool](https://papers.cool/arxiv/2502.13674)] [[pdf](https://arxiv.org/pdf/2502.13674)]
> **Authors**: Song Duong,Florian Le Bronnec,Alexandre Allauzen,Vincent Guigue,Alberto Lumbreras,Laure Soulier,Patrick Gallinari
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 10 pages, ICLR 2025 conference
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Large Language Models (LLMs), when used for conditional text generation, often produce hallucinations, i.e., information that is unfaithful or not grounded in the input context. This issue arises in typical conditional text generation tasks, such as text summarization and data-to-text generation, where the goal is to produce fluent text based on contextual input. When fine-tuned on specific domains, LLMs struggle to provide faithful answers to a given context, often adding information or generating errors. One underlying cause of this issue is that LLMs rely on statistical patterns learned from their training data. This reliance can interfere with the model's ability to stay faithful to a provided context, leading to the generation of ungrounded information. We build upon this observation and introduce a novel self-supervised method for generating a training set of unfaithful samples. We then refine the model using a training process that encourages the generation of grounded outputs over unfaithful ones, drawing on preference-based training. Our approach leads to significantly more grounded text generation, outperforming existing self-supervised techniques in faithfulness, as evaluated through automatic metrics, LLM-based assessments, and human evaluations.

### Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.13656)] [[cool](https://papers.cool/arxiv/2502.13656)] [[pdf](https://arxiv.org/pdf/2502.13656)]
> **Authors**: Liyang He,Chenglong Liu,Rui Li,Zhenya Huang,Shulan Ruan,Jun Zhou,Enhong Chen
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Sentence embedding is essential for many NLP tasks, with contrastive learning methods achieving strong performance using annotated datasets like NLI. Yet, the reliance on manual labels limits scalability. Recent studies leverage large language models (LLMs) to generate sentence pairs, reducing annotation dependency. However, they overlook ranking information crucial for fine-grained semantic distinctions. To tackle this challenge, we propose a method for controlling the generation direction of LLMs in the latent space. Unlike unconstrained generation, the controlled approach ensures meaningful semantic divergence. Then, we refine exist sentence embedding model by integrating ranking information and semantic information. Experiments on multiple benchmarks demonstrate that our method achieves new SOTA performance with a modest cost in ranking sentence synthesis.

### C2T: A Classifier-Based Tree Construction Method in Speculative Decoding 
[[arxiv](https://arxiv.org/abs/2502.13652)] [[cool](https://papers.cool/arxiv/2502.13652)] [[pdf](https://arxiv.org/pdf/2502.13652)]
> **Authors**: Feiye Huo,Jianchao Tan,Kefeng Zhang,Xunliang Cai,Shengli Sun
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: The growing scale of Large Language Models (LLMs) has exacerbated inference latency and computational costs. Speculative decoding methods, which aim to mitigate these issues, often face inefficiencies in the construction of token trees and the verification of candidate tokens. Existing strategies, including chain mode, static tree, and dynamic tree approaches, have limitations in accurately preparing candidate token trees for verification. We propose a novel method named C2T that adopts a lightweight classifier to generate and prune token trees dynamically. Our classifier considers additional feature variables beyond the commonly used joint probability to predict the confidence score for each draft token to determine whether it is the candidate token for verification. This method outperforms state-of-the-art (SOTA) methods such as EAGLE-2 on multiple benchmarks, by reducing the total number of candidate tokens by 25% while maintaining or even improving the acceptance length.

### Reliability Across Parametric and External Knowledge: Understanding Knowledge Handling in LLMs 
[[arxiv](https://arxiv.org/abs/2502.13648)] [[cool](https://papers.cool/arxiv/2502.13648)] [[pdf](https://arxiv.org/pdf/2502.13648)]
> **Authors**: Youna Kim,Minjoon Choi,Sungmin Cho,Hyuhng Joon Kim,Sang-goo Lee,Taeuk Kim
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: under-review
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Large Language Models (LLMs) enhance their problem-solving capability by leveraging both parametric and external knowledge. Beyond leveraging external knowledge to improve response accuracy, they require key capabilities for reliable knowledge-handling: resolving conflicts between knowledge sources, avoiding distraction from uninformative external knowledge, and abstaining when sufficient knowledge is unavailable. Prior studies have examined these scenarios in isolation or with limited scope. To systematically evaluate these capabilities, we introduce a comprehensive framework for analyzing knowledge-handling based on two key dimensions: the presence of parametric knowledge and the informativeness of external knowledge. Through analysis, we identify biases in knowledge utilization and examine how the ability to handle one scenario impacts performance in others. Furthermore, we demonstrate that training on data constructed based on the knowledge-handling scenarios improves LLMs' reliability in integrating and utilizing knowledge.

### Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh 
[[arxiv](https://arxiv.org/abs/2502.13647)] [[cool](https://papers.cool/arxiv/2502.13647)] [[pdf](https://arxiv.org/pdf/2502.13647)]
> **Authors**: Nurkhan Laiyk,Daniil Orel,Rituraj Joshi,Maiya Goloburda,Yuxia Wang,Preslav Nakov,Fajri Koto
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Instruction tuning in low-resource languages remains underexplored due to limited text data, particularly in government and cultural domains. To address this, we introduce and open-source a large-scale (10,600 samples) instruction-following (IFT) dataset, covering key institutional and cultural knowledge relevant to Kazakhstan. Our dataset enhances LLMs' understanding of procedural, legal, and structural governance topics. We employ LLM-assisted data generation, comparing open-weight and closed-weight models for dataset construction, and select GPT-4o as the backbone. Each entity of our dataset undergoes full manual verification to ensure high quality. We also show that fine-tuning Qwen, Falcon, and Gemma on our dataset leads to consistent performance improvements in both multiple-choice and generative tasks, demonstrating the potential of LLM-assisted instruction tuning for low-resource languages.

### D.Va: Validate Your Demonstration First Before You Use It 
[[arxiv](https://arxiv.org/abs/2502.13646)] [[cool](https://papers.cool/arxiv/2502.13646)] [[pdf](https://arxiv.org/pdf/2502.13646)]
> **Authors**: Qi Zhang,Zhiqing Xiao,Ruixuan Xiao,Lirong Gao,Junbo Zhao
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 14 pages, 6 figures
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: In-context learning (ICL) has demonstrated significant potential in enhancing the capabilities of large language models (LLMs) during inference. It's well-established that ICL heavily relies on selecting effective demonstrations to generate outputs that better align with the expected results. As for demonstration selection, previous approaches have typically relied on intuitive metrics to evaluate the effectiveness of demonstrations, which often results in limited robustness and poor cross-model generalization capabilities. To tackle these challenges, we propose a novel method, \textbf{D}emonstration \textbf{VA}lidation (\textbf{D.Va}), which integrates a demonstration validation perspective into this field. By introducing the demonstration validation mechanism, our method effectively identifies demonstrations that are both effective and highly generalizable. \textbf{D.Va} surpasses all existing demonstration selection techniques across both natural language understanding (NLU) and natural language generation (NLG) tasks. Additionally, we demonstrate the robustness and generalizability of our approach across various language models with different retrieval models.

### Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks 
[[arxiv](https://arxiv.org/abs/2502.13645)] [[cool](https://papers.cool/arxiv/2502.13645)] [[pdf](https://arxiv.org/pdf/2502.13645)]
> **Authors**: Ori Shapira,Shlomo E. Chazan,Amir DN Cohen
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: With the increasing prevalence of recorded human speech, spoken language understanding (SLU) is essential for its efficient processing. In order to process the speech, it is commonly transcribed using automatic speech recognition technology. This speech-to-text transition introduces errors into the transcripts, which subsequently propagate to downstream NLP tasks, such as dialogue summarization. While it is known that transcript noise affects downstream tasks, a systematic approach to analyzing its effects across different noise severities and types has not been addressed. We propose a configurable framework for assessing task models in diverse noisy settings, and for examining the impact of transcript-cleaning techniques. The framework facilitates the investigation of task model behavior, which can in turn support the development of effective SLU solutions. We exemplify the utility of our framework on three SLU tasks and four task models, offering insights regarding the effect of transcript noise on tasks in general and models in particular. For instance, we find that task models can tolerate a certain level of noise, and are affected differently by the types of errors in the transcript.

### Qorgau: Evaluating LLM Safety in Kazakh-Russian Bilingual Contexts 
[[arxiv](https://arxiv.org/abs/2502.13640)] [[cool](https://papers.cool/arxiv/2502.13640)] [[pdf](https://arxiv.org/pdf/2502.13640)]
> **Authors**: Maiya Goloburda,Nurkhan Laiyk,Diana Turmakhan,Yuxia Wang,Mukhammed Togmanov,Jonibek Mansurov,Askhat Sametov,Nurdaulet Mukhituly,Minghan Wang,Daniil Orel,Zain Muhammad Mujahid,Fajri Koto,Timothy Baldwin,Preslav Nakov
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Large language models (LLMs) are known to have the potential to generate harmful content, posing risks to users. While significant progress has been made in developing taxonomies for LLM risks and safety evaluation prompts, most studies have focused on monolingual contexts, primarily in English. However, language- and region-specific risks in bilingual contexts are often overlooked, and core findings can diverge from those in monolingual settings. In this paper, we introduce Qorgau, a novel dataset specifically designed for safety evaluation in Kazakh and Russian, reflecting the unique bilingual context in Kazakhstan, where both Kazakh (a low-resource language) and Russian (a high-resource language) are spoken. Experiments with both multilingual and language-specific LLMs reveal notable differences in safety performance, emphasizing the need for tailored, region-specific datasets to ensure the responsible and safe deployment of LLMs in countries like Kazakhstan. Warning: this paper contains example data that may be offensive, harmful, or biased.

### Non-Euclidean Hierarchical Representational Learning using Hyperbolic Graph Neural Networks for Environmental Claim Detection 
[[arxiv](https://arxiv.org/abs/2502.13628)] [[cool](https://papers.cool/arxiv/2502.13628)] [[pdf](https://arxiv.org/pdf/2502.13628)]
> **Authors**: Darpan Aswal,Manjira Sinha
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Transformer-based models dominate NLP tasks like sentiment analysis, machine translation, and claim verification. However, their massive computational demands and lack of interpretability pose challenges for real-world applications requiring efficiency and transparency. In this work, we explore Graph Neural Networks (GNNs) and Hyperbolic Graph Neural Networks (HGNNs) as lightweight yet effective alternatives for Environmental Claim Detection, reframing it as a graph classification problem. We construct dependency parsing graphs to explicitly model syntactic structures, using simple word embeddings (word2vec) for node features with dependency relations encoded as edge features. Our results demonstrate that these graph-based models achieve comparable or superior performance to state-of-the-art transformers while using 30x fewer parameters. This efficiency highlights the potential of structured, interpretable, and computationally efficient graph-based approaches.

### REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models 
[[arxiv](https://arxiv.org/abs/2502.13622)] [[cool](https://papers.cool/arxiv/2502.13622)] [[pdf](https://arxiv.org/pdf/2502.13622)]
> **Authors**: DongGeon Lee,Hwanjo Yu
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Hallucinations in large language model (LLM) outputs severely limit their reliability in knowledge-intensive tasks such as question answering. To address this challenge, we introduce REFIND (Retrieval-augmented Factuality hallucINation Detection), a novel framework that detects hallucinated spans within LLM outputs by directly leveraging retrieved documents. As part of the REFIND, we propose the Context Sensitivity Ratio (CSR), a novel metric that quantifies the sensitivity of LLM outputs to retrieved evidence. This innovative approach enables REFIND to efficiently and accurately detect hallucinations, setting it apart from existing methods. In the evaluation, REFIND demonstrated robustness across nine languages, including low-resource settings, and significantly outperformed baseline models, achieving superior IoU scores in identifying hallucinated spans. This work highlights the effectiveness of quantifying context sensitivity for hallucination detection, thereby paving the way for more reliable and trustworthy LLM applications across diverse languages.

### Complex Ontology Matching with Large Language Model Embeddings 
[[arxiv](https://arxiv.org/abs/2502.13619)] [[cool](https://papers.cool/arxiv/2502.13619)] [[pdf](https://arxiv.org/pdf/2502.13619)]
> **Authors**: Guilherme Sousa,Rinaldo Lima,Cassia Trojahn
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能
- **Abstract**: Ontology, and more broadly, Knowledge Graph Matching is a challenging task in which expressiveness has not been fully addressed. Despite the increasing use of embeddings and language models for this task, approaches for generating expressive correspondences still do not take full advantage of these models, in particular, large language models (LLMs). This paper proposes to integrate LLMs into an approach for generating expressive correspondences based on alignment need and ABox-based relation discovery. The generation of correspondences is performed by matching similar surroundings of instance sub-graphs. The integration of LLMs results in different architectural modifications, including label similarity, sub-graph matching, and entity matching. The performance word embeddings, sentence embeddings, and LLM-based embeddings, was compared. The results demonstrate that integrating LLMs surpasses all other models, enhancing the baseline version of the approach with a 45\% increase in F-measure.

### BeamLoRA: Beam-Constraint Low-Rank Adaptation 
[[arxiv](https://arxiv.org/abs/2502.13604)] [[cool](https://papers.cool/arxiv/2502.13604)] [[pdf](https://arxiv.org/pdf/2502.13604)]
> **Authors**: Naibin Gu,Zhenyu Zhang,Xiyu Liu,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Due to the demand for efficient fine-tuning of large language models, Low-Rank Adaptation (LoRA) has been widely adopted as one of the most effective parameter-efficient fine-tuning methods. Nevertheless, while LoRA improves efficiency, there remains room for improvement in accuracy. Herein, we adopt a novel perspective to assess the characteristics of LoRA ranks. The results reveal that different ranks within the LoRA modules not only exhibit varying levels of importance but also evolve dynamically throughout the fine-tuning process, which may limit the performance of LoRA. Based on these findings, we propose BeamLoRA, which conceptualizes each LoRA module as a beam where each rank naturally corresponds to a potential sub-solution, and the fine-tuning process becomes a search for the optimal sub-solution combination. BeamLoRA dynamically eliminates underperforming sub-solutions while expanding the parameter space for promising ones, enhancing performance with a fixed rank. Extensive experiments across three base models and 12 datasets spanning math reasoning, code generation, and commonsense reasoning demonstrate that BeamLoRA consistently enhances the performance of LoRA, surpassing the other baseline methods.

### Efficient Safety Retrofitting Against Jailbreaking for LLMs 
[[arxiv](https://arxiv.org/abs/2502.13603)] [[cool](https://papers.cool/arxiv/2502.13603)] [[pdf](https://arxiv.org/pdf/2502.13603)]
> **Authors**: Dario Garcia-Gasulla,Adrian Tormos,Anna Arias-Duart,Daniel Hinjos,Oscar Molina-Sedano,Ashwin Kumar Gururajan,Maria Eugenia Cardello
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学,人工智能,机器学习
- **Abstract**: Direct Preference Optimization (DPO) is an efficient alignment technique that steers LLMs towards preferable outputs by training on preference data, bypassing the need for explicit reward models. Its simplicity enables easy adaptation to various domains and safety requirements. This paper examines DPO's effectiveness in model safety against jailbreaking attacks while minimizing data requirements and training costs. We introduce Egida, a dataset expanded from multiple sources, which includes 27 different safety topics and 18 different attack styles, complemented with synthetic and human labels. This data is used to boost the safety of state-of-the-art LLMs (Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack styles. In addition to safety evaluations, we assess their post-alignment performance degradation in general purpose tasks, and their tendency to over refusal. Following the proposed methodology, trained models reduce their Attack Success Rate by 10%-30%, using small training efforts (2,000 samples) with low computational cost (3\$ for 8B models, 20\$ for 72B models). Safety aligned models generalize to unseen topics and attack styles, with the most successful attack style reaching a success rate around 5%. Size and family are found to strongly influence model malleability towards safety, pointing at the importance of pre-training choices. To validate our findings, a large independent assessment of human preference agreement with Llama-Guard-3-8B is conducted by the authors and the associated dataset Egida-HSafe is released. Overall, this study illustrates how affordable and accessible it is to enhance LLM safety using DPO while outlining its current limitations. All datasets and models are released to enable reproducibility and further research.

### MMTEB: Massive Multilingual Text Embedding Benchmark 
[[arxiv](https://arxiv.org/abs/2502.13595)] [[cool](https://papers.cool/arxiv/2502.13595)] [[pdf](https://arxiv.org/pdf/2502.13595)]
> **Authors**: Kenneth Enevoldsen,Isaac Chung,Imene Kerboua,Márton Kardos,Ashwin Mathur,David Stap,Jay Gala,Wissam Siblini,Dominik Krzemiński,Genta Indra Winata,Saba Sturua,Saiteja Utpala,Mathieu Ciancone,Marion Schaeffer,Gabriel Sequeira,Diganta Misra,Shreeya Dhakal,Jonathan Rystrøm,Roman Solomatin,Ömer Çağatan,Akash Kundu,Martin Bernstorff,Shitao Xiao,Akshita Sukhlecha,Bhavish Pahwa, et al. (61 additional authors not shown)
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: Accepted for ICLR: https://openreview.net/forum?id=zl3pfz4VCV
- **标题**: None
- **领域**: 计算语言学,人工智能,信息检索
- **Abstract**: Text embeddings are typically evaluated on a limited set of tasks, which are constrained by language, domain, and task diversity. To address these limitations and provide a more comprehensive evaluation, we introduce the Massive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale, community-driven expansion of MTEB, covering over 500 quality-controlled evaluation tasks across 250+ languages. MMTEB includes a diverse set of challenging, novel tasks such as instruction following, long-document retrieval, and code retrieval, representing the largest multilingual collection of evaluation tasks for embedding models to date. Using this collection, we develop several highly multilingual benchmarks, which we use to evaluate a representative set of models. We find that while large language models (LLMs) with billions of parameters can achieve state-of-the-art performance on certain language subsets and task categories, the best-performing publicly available model is multilingual-e5-large-instruct with only 560 million parameters. To facilitate accessibility and reduce computational cost, we introduce a novel downsampling method based on inter-task correlation, ensuring a diverse selection while preserving relative model rankings. Furthermore, we optimize tasks such as retrieval by sampling hard negatives, creating smaller but effective splits. These optimizations allow us to introduce benchmarks that drastically reduce computational demands. For instance, our newly introduced zero-shot English benchmark maintains a ranking order similar to the full-scale version but at a fraction of the computational cost.

### Don't Stop the Multi-Party! On Generating Synthetic Multi-Party Conversations with Constraints 
[[arxiv](https://arxiv.org/abs/2502.13592)] [[cool](https://papers.cool/arxiv/2502.13592)] [[pdf](https://arxiv.org/pdf/2502.13592)]
> **Authors**: Nicolò Penzo,Marco Guerini,Bruno Lepri,Goran Glavaš,Sara Tonelli
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算语言学
- **Abstract**: Multi-Party Conversations (MPCs) are widely studied across disciplines, with social media as a primary data source due to their accessibility. However, these datasets raise privacy concerns and often reflect platform-specific properties. For example, interactions between speakers may be limited due to rigid platform structures (e.g., threads, tree-like discussions), which yield overly simplistic interaction patterns (e.g., as a consequence of ``reply-to'' links). This work explores the feasibility of generating diverse MPCs with instruction-tuned Large Language Models (LLMs) by providing deterministic constraints such as dialogue structure and participants' stance. We investigate two complementary strategies of leveraging LLMs in this context: (i.) LLMs as MPC generators, where we task the LLM to generate a whole MPC at once and (ii.) LLMs as MPC parties, where the LLM generates one turn of the conversation at a time, provided the conversation history. We next introduce an analytical framework to evaluate compliance with the constraints, content quality, and interaction complexity for both strategies. Finally, we assess the quality of obtained MPCs via human annotation and LLM-as-a-judge evaluations. We find stark differences among LLMs, with only some being able to generate high-quality MPCs. We also find that turn-by-turn generation yields better conformance to constraints and higher linguistic variability than generating MPCs in one pass. Nonetheless, our structural and qualitative evaluation indicates that both generation strategies can yield high-quality MPCs.

## 密码学和安全(cs.CR:Cryptography and Security)

### Secure Federated Data Distillation 
[[arxiv](https://arxiv.org/abs/2502.13728)] [[cool](https://papers.cool/arxiv/2502.13728)] [[pdf](https://arxiv.org/pdf/2502.13728)]
> **Authors**: Marco Arazzi,Mert Cihangiroglu,Serena Nicolazzo,Antonino Nocera
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 密码学和安全,人工智能
- **Abstract**: Dataset Distillation (DD) is a powerful technique for reducing large datasets into compact, representative synthetic datasets, accelerating Machine Learning training. However, traditional DD methods operate in a centralized manner, which poses significant privacy threats and reduces its applicability. To mitigate these risks, we propose a Secure Federated Data Distillation framework (SFDD) to decentralize the distillation process while preserving privacy.Unlike existing Federated Distillation techniques that focus on training global models with distilled knowledge, our approach aims to produce a distilled dataset without exposing local contributions. We leverage the gradient-matching-based distillation method, adapting it for a distributed setting where clients contribute to the distillation process without sharing raw data. The central aggregator iteratively refines a synthetic dataset by integrating client-side updates while ensuring data confidentiality. To make our approach resilient to inference attacks perpetrated by the server that could exploit gradient updates to reconstruct private data, we create an optimized Local Differential Privacy approach, called LDPO-RLD (Label Differential Privacy Obfuscation via Randomized Linear Dispersion). Furthermore, we assess the framework's resilience against malicious clients executing backdoor attacks and demonstrate robustness under the assumption of a sufficient number of participating clients. Our experimental results demonstrate the effectiveness of SFDD and that the proposed defense concretely mitigates the identified vulnerabilities, with minimal impact on the performance of the distilled dataset. By addressing the interplay between privacy and federation in dataset distillation, this work advances the field of privacy-preserving Machine Learning making our SFDD framework a viable solution for sensitive data-sharing applications.

## 计算机视觉和模式识别(cs.CV:Computer Vision and Pattern Recognition)

### Medical Image Classification with KAN-Integrated Transformers and Dilated Neighborhood Attention 
[[arxiv](https://arxiv.org/abs/2502.13693)] [[cool](https://papers.cool/arxiv/2502.13693)] [[pdf](https://arxiv.org/pdf/2502.13693)]
> **Authors**: Omid Nejati Manzari,Hojat Asgariandehkordi,Taha Koleilat,Yiming Xiao,Hassan Rivaz
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Convolutional networks, transformers, hybrid models, and Mamba-based architectures have demonstrated strong performance across various medical image classification tasks. However, these methods were primarily designed to classify clean images using labeled data. In contrast, real-world clinical data often involve image corruptions that are unique to multi-center studies and stem from variations in imaging equipment across manufacturers. In this paper, we introduce the Medical Vision Transformer (MedViTV2), a novel architecture incorporating Kolmogorov-Arnold Network (KAN) layers into the transformer architecture for the first time, aiming for generalized medical image classification. We have developed an efficient KAN block to reduce computational load while enhancing the accuracy of the original MedViT. Additionally, to counteract the fragility of our MedViT when scaled up, we propose an enhanced Dilated Neighborhood Attention (DiNA), an adaptation of the efficient fused dot-product attention kernel capable of capturing global context and expanding receptive fields to scale the model effectively and addressing feature collapse issues. Moreover, a hierarchical hybrid strategy is introduced to stack our Local Feature Perception and Global Feature Perception blocks in an efficient manner, which balances local and global feature perceptions to boost performance. Extensive experiments on 17 medical image classification datasets and 12 corrupted medical image datasets demonstrate that MedViTV2 achieved state-of-the-art results in 27 out of 29 experiments with reduced computational complexity. MedViTV2 is 44\% more computationally efficient than the previous version and significantly enhances accuracy, achieving improvements of 4.6\% on MedMNIST, 5.8\% on NonMNIST, and 13.4\% on the MedMNIST-C benchmark.

### Exploring Mutual Cross-Modal Attention for Context-Aware Human Affordance Generation 
[[arxiv](https://arxiv.org/abs/2502.13637)] [[cool](https://papers.cool/arxiv/2502.13637)] [[pdf](https://arxiv.org/pdf/2502.13637)]
> **Authors**: Prasun Roy,Saumik Bhattacharya,Subhankar Ghosh,Umapada Pal,Michael Blumenstein
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 11 pages
- **标题**: None
- **领域**: 计算机视觉和模式识别,多媒体
- **Abstract**: Human affordance learning investigates contextually relevant novel pose prediction such that the estimated pose represents a valid human action within the scene. While the task is fundamental to machine perception and automated interactive navigation agents, the exponentially large number of probable pose and action variations make the problem challenging and non-trivial. However, the existing datasets and methods for human affordance prediction in 2D scenes are significantly limited in the literature. In this paper, we propose a novel cross-attention mechanism to encode the scene context for affordance prediction by mutually attending spatial feature maps from two different modalities. The proposed method is disentangled among individual subtasks to efficiently reduce the problem complexity. First, we sample a probable location for a person within the scene using a variational autoencoder (VAE) conditioned on the global scene context encoding. Next, we predict a potential pose template from a set of existing human pose candidates using a classifier on the local context encoding around the predicted location. In the subsequent steps, we use two VAEs to sample the scale and deformation parameters for the predicted pose template by conditioning on the local context and template class. Our experiments show significant improvements over the previous baseline of human affordance injection into complex 2D scenes.

### CardiacMamba: A Multimodal RGB-RF Fusion Framework with State Space Models for Remote Physiological Measurement 
[[arxiv](https://arxiv.org/abs/2502.13624)] [[cool](https://papers.cool/arxiv/2502.13624)] [[pdf](https://arxiv.org/pdf/2502.13624)]
> **Authors**: Zheng Wu,Yiping Xie,Bo Zhao,Jiguang He,Fei Luo,Ning Deng,Zitong Yu
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 计算机视觉和模式识别
- **Abstract**: Heart rate (HR) estimation via remote photoplethysmography (rPPG) offers a non-invasive solution for health monitoring. However, traditional single-modality approaches (RGB or Radio Frequency (RF)) face challenges in balancing robustness and accuracy due to lighting variations, motion artifacts, and skin tone bias. In this paper, we propose CardiacMamba, a multimodal RGB-RF fusion framework that leverages the complementary strengths of both modalities. It introduces the Temporal Difference Mamba Module (TDMM) to capture dynamic changes in RF signals using timing differences between frames, enhancing the extraction of local and global features. Additionally, CardiacMamba employs a Bidirectional SSM for cross-modal alignment and a Channel-wise Fast Fourier Transform (CFFT) to effectively capture and refine the frequency domain characteristics of RGB and RF signals, ultimately improving heart rate estimation accuracy and periodicity detection. Extensive experiments on the EquiPleth dataset demonstrate state-of-the-art performance, achieving marked improvements in accuracy and robustness. CardiacMamba significantly mitigates skin tone bias, reducing performance disparities across demographic groups, and maintains resilience under missing-modality scenarios. By addressing critical challenges in fairness, adaptability, and precision, the framework advances rPPG technology toward reliable real-world deployment in healthcare. The codes are available at: https://github.com/WuZheng42/CardiacMamba.

## 数据结构和算法(cs.DS:Data Structures and Algorithms)

### A Query-Driven Approach to Space-Efficient Range Searching 
[[arxiv](https://arxiv.org/abs/2502.13653)] [[cool](https://papers.cool/arxiv/2502.13653)] [[pdf](https://arxiv.org/pdf/2502.13653)]
> **Authors**: Dimitris Fotakis,Andreas Kalavas,Ioannis Psarros
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 16 pages, 2 figures
- **标题**: None
- **领域**: 数据结构和算法,计算几何,机器学习
- **Abstract**: We initiate a study of a query-driven approach to designing partition trees for range-searching problems. Our model assumes that a data structure is to be built for an unknown query distribution that we can access through a sampling oracle, and must be selected such that it optimizes a meaningful performance parameter on expectation. Our first contribution is to show that a near-linear sample of queries allows the construction of a partition tree with a near-optimal expected number of nodes visited during querying. We enhance this approach by treating node processing as a classification problem, leveraging fast classifiers like shallow neural networks to obtain experimentally efficient query times. Our second contribution is to develop partition trees using sparse geometric separators. Our preprocessing algorithm, based on a sample of queries, builds a balanced tree with nodes associated with separators that minimize query stabs on expectation; this yields both fast processing of each node and a small number of visited nodes, significantly reducing query time.

## 信息检索(cs.IR:Information Retrieval)

### ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation 
[[arxiv](https://arxiv.org/abs/2502.13581)] [[cool](https://papers.cool/arxiv/2502.13581)] [[pdf](https://arxiv.org/pdf/2502.13581)]
> **Authors**: Yupeng Hou,Jianmo Ni,Zhankui He,Noveen Sachdeva,Wang-Cheng Kang,Ed H. Chi,Julian McAuley,Derek Zhiyuan Cheng
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 信息检索,机器学习
- **Abstract**: Generative recommendation (GR) is an emerging paradigm where user actions are tokenized into discrete token patterns and autoregressively generated as predictions. However, existing GR models tokenize each action independently, assigning the same fixed tokens to identical actions across all sequences without considering contextual relationships. This lack of context-awareness can lead to suboptimal performance, as the same action may hold different meanings depending on its surrounding context. To address this issue, we propose ActionPiece to explicitly incorporate context when tokenizing action sequences. In ActionPiece, each action is represented as a set of item features, which serve as the initial tokens. Given the action sequence corpora, we construct the vocabulary by merging feature patterns as new tokens, based on their co-occurrence frequency both within individual sets and across adjacent sets. Considering the unordered nature of feature sets, we further introduce set permutation regularization, which produces multiple segmentations of action sequences with the same semantics. Experiments on public datasets demonstrate that ActionPiece consistently outperforms existing action tokenization methods, improving NDCG@$10$ by $6.00\%$ to $12.82\%$.

## 机器学习(cs.LG:Machine Learning)

### Learning Novel Transformer Architecture for Time-series Forecasting 
[[arxiv](https://arxiv.org/abs/2502.13721)] [[cool](https://papers.cool/arxiv/2502.13721)] [[pdf](https://arxiv.org/pdf/2502.13721)]
> **Authors**: Juyuan Zhang,Wei Zhu,Jiechao Gao
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,计算语言学
- **Abstract**: Despite the success of Transformer-based models in the time-series prediction (TSP) tasks, the existing Transformer architecture still face limitations and the literature lacks comprehensive explorations into alternative architectures. To address these challenges, we propose AutoFormer-TS, a novel framework that leverages a comprehensive search space for Transformer architectures tailored to TSP tasks. Our framework introduces a differentiable neural architecture search (DNAS) method, AB-DARTS, which improves upon existing DNAS approaches by enhancing the identification of optimal operations within the architecture. AutoFormer-TS systematically explores alternative attention mechanisms, activation functions, and encoding operations, moving beyond the traditional Transformer design. Extensive experiments demonstrate that AutoFormer-TS consistently outperforms state-of-the-art baselines across various TSP benchmarks, achieving superior forecasting accuracy while maintaining reasonable training efficiency.

### Tight Generalization Bounds for Large-Margin Halfspaces 
[[arxiv](https://arxiv.org/abs/2502.13692)] [[cool](https://papers.cool/arxiv/2502.13692)] [[pdf](https://arxiv.org/pdf/2502.13692)]
> **Authors**: Kasper Green Larsen,Natascha Schalburg
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,统计理论
- **Abstract**: We prove the first generalization bound for large-margin halfspaces that is asymptotically tight in the tradeoff between the margin, the fraction of training points with the given margin, the failure probability and the number of training points.

### Generalization error bound for denoising score matching under relaxed manifold assumption 
[[arxiv](https://arxiv.org/abs/2502.13662)] [[cool](https://papers.cool/arxiv/2502.13662)] [[pdf](https://arxiv.org/pdf/2502.13662)]
> **Authors**: Konstantin Yakovlev,Nikita Puchkin
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 70 pages; refined rates of convergence in the bounded case
- **标题**: None
- **领域**: 机器学习,统计理论,机器学习
- **Abstract**: We examine theoretical properties of the denoising score matching estimate. We model the density of observations with a nonparametric Gaussian mixture. We significantly relax the standard manifold assumption allowing the samples step away from the manifold. At the same time, we are still able to leverage a nice distribution structure. We derive non-asymptotic bounds on the approximation and generalization errors of the denoising score matching estimate. The rates of convergence are determined by the intrinsic dimension. Furthermore, our bounds remain valid even if we allow the ambient dimension grow polynomially with the sample size.

### Towards Invariance to Node Identifiers in Graph Neural Networks 
[[arxiv](https://arxiv.org/abs/2502.13660)] [[cool](https://papers.cool/arxiv/2502.13660)] [[pdf](https://arxiv.org/pdf/2502.13660)]
> **Authors**: Maya Bechler-Speicher,Moshe Eliasof,Carola-Bibiane Schonlieb,Ran Gilad-Bachrach,Amir Globerson
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: arXiv admin note: text overlap with arXiv:2411.02271
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Message-Passing Graph Neural Networks (GNNs) are known to have limited expressive power, due to their message passing structure. One mechanism for circumventing this limitation is to add unique node identifiers (IDs), which break the symmetries that underlie the expressivity limitation. In this work, we highlight a key limitation of the ID framework, and propose an approach for addressing it. We begin by observing that the final output of the GNN should clearly not depend on the specific IDs used. We then show that in practice this does not hold, and thus the learned network does not possess this desired structural property. Such invariance to node IDs may be enforced in several ways, and we discuss their theoretical properties. We then propose a novel regularization method that effectively enforces ID invariance to the network. Extensive evaluations on both real-world and synthetic tasks demonstrate that our approach significantly improves ID invariance and, in turn, often boosts generalization performance.

### Integrating Inverse and Forward Modeling for Sparse Temporal Data from Sensor Networks 
[[arxiv](https://arxiv.org/abs/2502.13638)] [[cool](https://papers.cool/arxiv/2502.13638)] [[pdf](https://arxiv.org/pdf/2502.13638)]
> **Authors**: Julian Vexler,Björn Vieten,Martin Nelke,Stefan Kramer
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: We present CavePerception, a framework for the analysis of sparse data from sensor networks that incorporates elements of inverse modeling and forward modeling. By integrating machine learning with physical modeling in a hypotheses space, we aim to improve the interpretability of sparse, noisy, and potentially incomplete sensor data. The framework assumes data from a two-dimensional sensor network laid out in a graph structure that detects certain objects, with certain motion patterns. Examples of such sensors are magnetometers. Given knowledge about the objects and the way they act on the sensors, one can develop a data generator that produces data from simulated motions of the objects across the sensor field. The framework uses the simulated data to infer object behaviors across the sensor network. The approach is experimentally tested on real-world data, where magnetometers are used on an airport to detect and identify aircraft motions. Experiments demonstrate the value of integrating inverse and forward modeling, enabling intelligent systems to better understand and predict complex, sensor-driven events.

### Concept Layers: Enhancing Interpretability and Intervenability via LLM Conceptualization 
[[arxiv](https://arxiv.org/abs/2502.13632)] [[cool](https://papers.cool/arxiv/2502.13632)] [[pdf](https://arxiv.org/pdf/2502.13632)]
> **Authors**: Or Raphael Bidusa,Shaul Markovitch
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能,计算语言学
- **Abstract**: The opaque nature of Large Language Models (LLMs) has led to significant research efforts aimed at enhancing their interpretability, primarily through post-hoc methods. More recent in-hoc approaches, such as Concept Bottleneck Models (CBMs), offer both interpretability and intervenability by incorporating explicit concept representations. However, these methods suffer from key limitations, including reliance on labeled concept datasets and significant architectural modifications that challenges re-integration into existing system pipelines. In this work, we introduce a new methodology for incorporating interpretability and intervenability into an existing model by integrating Concept Layers (CLs) into its architecture. Our approach projects the model's internal vector representations into a conceptual, explainable vector space before reconstructing and feeding them back into the model. Furthermore, we eliminate the need for a human-selected concept set by algorithmically searching an ontology for a set of concepts that can be either task-specific or task-agnostic. We evaluate CLs across multiple tasks, demonstrating that they maintain the original model's performance and agreement while enabling meaningful interventions. Additionally, we present a proof of concept showcasing an intervenability interface, allowing users to adjust model behavior dynamically, such as mitigating biases during inference.

### Toward Robust Non-Transferable Learning: A Survey and Benchmark 
[[arxiv](https://arxiv.org/abs/2502.13593)] [[cool](https://papers.cool/arxiv/2502.13593)] [[pdf](https://arxiv.org/pdf/2502.13593)]
> **Authors**: Ziming Hong,Yongli Xiang,Tongliang Liu
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,密码学和安全,计算机视觉和模式识别
- **Abstract**: Over the past decades, researchers have primarily focused on improving the generalization abilities of models, with limited attention given to regulating such generalization. However, the ability of models to generalize to unintended data (e.g., harmful or unauthorized data) can be exploited by malicious adversaries in unforeseen ways, potentially resulting in violations of model ethics. Non-transferable learning (NTL), a task aimed at reshaping the generalization abilities of deep learning models, was proposed to address these challenges. While numerous methods have been proposed in this field, a comprehensive review of existing progress and a thorough analysis of current limitations remain lacking. In this paper, we bridge this gap by presenting the first comprehensive survey on NTL and introducing NTLBench, the first benchmark to evaluate NTL performance and robustness within a unified framework. Specifically, we first introduce the task settings, general framework, and criteria of NTL, followed by a summary of NTL approaches. Furthermore, we emphasize the often-overlooked issue of robustness against various attacks that can destroy the non-transferable mechanism established by NTL. Experiments conducted via NTLBench verify the limitations of existing NTL methods in robustness. Finally, we discuss the practical applications of NTL, along with its future directions and associated challenges.

### Multi-Target Radar Search and Track Using Sequence-Capable Deep Reinforcement Learning 
[[arxiv](https://arxiv.org/abs/2502.13584)] [[cool](https://papers.cool/arxiv/2502.13584)] [[pdf](https://arxiv.org/pdf/2502.13584)]
> **Authors**: Jan-Hendrik Ewers,David Cormack,Joe Gibbs,David Anderson
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: Accepted for RLDM 2025, submitted to IEEE SSP 2025
- **标题**: None
- **领域**: 机器学习,系统与控制
- **Abstract**: The research addresses sensor task management for radar systems, focusing on efficiently searching and tracking multiple targets using reinforcement learning. The approach develops a 3D simulation environment with an active electronically scanned array radar, using a multi-target tracking algorithm to improve observation data quality. Three neural network architectures were compared including an approach using fated recurrent units with multi-headed self-attention. Two pre-training techniques were applied: behavior cloning to approximate a random search strategy and an auto-encoder to pre-train the feature extractor. Experimental results revealed that search performance was relatively consistent across most methods. The real challenge emerged in simultaneously searching and tracking targets. The multi-headed self-attention architecture demonstrated the most promising results, highlighting the potential of sequence-capable architectures in handling dynamic tracking scenarios. The key contribution lies in demonstrating how reinforcement learning can optimize sensor management, potentially improving radar systems' ability to identify and track multiple targets in complex environments.

### Unraveling the Localized Latents: Learning Stratified Manifold Structures in LLM Embedding Space with Sparse Mixture-of-Experts 
[[arxiv](https://arxiv.org/abs/2502.13577)] [[cool](https://papers.cool/arxiv/2502.13577)] [[pdf](https://arxiv.org/pdf/2502.13577)]
> **Authors**: Xin Li,Anand Sarwate
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: However, real-world data often exhibit complex local structures that can be challenging for single-model approaches with a smooth global manifold in the embedding space to unravel. In this work, we conjecture that in the latent space of these large language models, the embeddings live in a local manifold structure with different dimensions depending on the perplexities and domains of the input data, commonly referred to as a Stratified Manifold structure, which in combination form a structured space known as a Stratified Space. To investigate the validity of this structural claim, we propose an analysis framework based on a Mixture-of-Experts (MoE) model where each expert is implemented with a simple dictionary learning algorithm at varying sparsity levels. By incorporating an attention-based soft-gating network, we verify that our model learns specialized sub-manifolds for an ensemble of input data sources, reflecting the semantic stratification in LLM embedding space. We further analyze the intrinsic dimensions of these stratified sub-manifolds and present extensive statistics on expert assignments, gating entropy, and inter-expert distances. Our experimental results demonstrate that our method not only validates the claim of a stratified manifold structure in the LLM embedding space, but also provides interpretable clusters that align with the intrinsic semantic variations of the input data.

### Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation 
[[arxiv](https://arxiv.org/abs/2502.13576)] [[cool](https://papers.cool/arxiv/2502.13576)] [[pdf](https://arxiv.org/pdf/2502.13576)]
> **Authors**: Peiwen Yuan,Yueqi Zhang,Shaoxiong Feng,Yiwei Li,Xinglin Wang,Jiayi Shi,Chuyi Tan,Boyuan Pan,Yao Hu,Kan Li
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,人工智能
- **Abstract**: Evaluating models on large benchmarks is very resource-intensive, especially during the period of rapid model evolution. Existing efficient evaluation methods estimate the performance of target models by testing them only on a small and static coreset of the benchmark, which is derived from the publicly available evaluation results of source models. These methods rely on the assumption that target models have high prediction consistency with source models. However, we demonstrate that it doesn't generalize well in practice. To alleviate the inconsistency issue, we present TailoredBench, a method that conducts customized evaluation tailored to each target model. Specifically, a Global-coreset is first constructed as a probe to identify the most consistent source models for each target model with an adaptive source model selection strategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to extend the Global-coreset to a tailored Native-coreset for each target model. According to the predictions on Native-coresets, we obtain the performance of target models on the whole benchmark with a calibrated estimation strategy. Comprehensive experiments on 5 benchmarks across over 300 models demonstrate that compared to best performing baselines, TailoredBench achieves an average reduction of 31.4% in MAE of accuracy estimates under the same inference budgets, showcasing strong effectiveness and generalizability.

### ETS: Efficient Tree Search for Inference-Time Scaling 
[[arxiv](https://arxiv.org/abs/2502.13575)] [[cool](https://papers.cool/arxiv/2502.13575)] [[pdf](https://arxiv.org/pdf/2502.13575)]
> **Authors**: Coleman Hooper,Sehoon Kim,Suhong Moon,Kerem Dilmen,Monishwaran Maheswaran,Nicholas Lee,Michael W. Mahoney,Sophia Shao,Kurt Keutzer,Amir Gholami
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 11 pages
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Test-time compute scaling has emerged as a new axis along which to improve model accuracy, where additional computation is used at inference time to allow the model to think longer for more challenging problems. One promising approach for test-time compute scaling is search against a process reward model, where a model generates multiple potential candidates at each step of the search, and these partial trajectories are then scored by a separate reward model in order to guide the search process. The diversity of trajectories in the tree search process affects the accuracy of the search, since increasing diversity promotes more exploration. However, this diversity comes at a cost, as divergent trajectories have less KV sharing, which means they consume more memory and slow down the search process. Previous search methods either do not perform sufficient exploration, or else explore diverse trajectories but have high latency. We address this challenge by proposing Efficient Tree Search (ETS), which promotes KV sharing by pruning redundant trajectories while maintaining necessary diverse trajectories. ETS incorporates a linear programming cost model to promote KV cache sharing by penalizing the number of nodes retained, while incorporating a semantic coverage term into the cost model to ensure that we retain trajectories which are semantically different. We demonstrate how ETS can achieve 1.8$\times$ reduction in average KV cache size during the search process, leading to 1.4$\times$ increased throughput relative to prior state-of-the-art methods, with minimal accuracy degradation and without requiring any custom kernel implementation. Code is available at: https://github.com/SqueezeAILab/ETS.

### Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective 
[[arxiv](https://arxiv.org/abs/2502.13573)] [[cool](https://papers.cool/arxiv/2502.13573)] [[pdf](https://arxiv.org/pdf/2502.13573)]
> **Authors**: Yuan Yao,Xiaopu Zhang,Yu Zhang,Jian Jin,Qiang Yang
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习
- **Abstract**: Semi-supervised heterogeneous domain adaptation (SHDA) addresses learning across domains with distinct feature representations and distributions, where source samples are labeled while most target samples are unlabeled, with only a small fraction labeled. Moreover, there is no one-to-one correspondence between source and target samples. Although various SHDA methods have been developed to tackle this problem, the nature of the knowledge transferred across heterogeneous domains remains unclear. This paper delves into this question from an empirical perspective. We conduct extensive experiments on about 330 SHDA tasks, employing two supervised learning methods and seven representative SHDA methods. Surprisingly, our observations indicate that both the category and feature information of source samples do not significantly impact the performance of the target domain. Additionally, noise drawn from simple distributions, when used as source samples, may contain transferable knowledge. Based on this insight, we perform a series of experiments to uncover the underlying principles of transferable knowledge in SHDA. Specifically, we design a unified Knowledge Transfer Framework (KTF) for SHDA. Based on the KTF, we find that the transferable knowledge in SHDA primarily stems from the transferability and discriminability of the source domain. Consequently, ensuring those properties in source samples, regardless of their origin (e.g., image, text, noise), can enhance the effectiveness of knowledge transfer in SHDA tasks. The codes and datasets are available at https://github.com/yyyaoyuan/SHDA.

## 软件工程(cs.SE:Software Engineering)

### An LLM-based Agent for Reliable Docker Environment Configuration 
[[arxiv](https://arxiv.org/abs/2502.13681)] [[cool](https://papers.cool/arxiv/2502.13681)] [[pdf](https://arxiv.org/pdf/2502.13681)]
> **Authors**: Ruida Hu,Chao Peng,Xinchen Wang,Cuiyun Gao
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 软件工程,人工智能,计算语言学,机器学习
- **Abstract**: Environment configuration is a critical yet time-consuming step in software development, especially when dealing with unfamiliar code repositories. While Large Language Models (LLMs) demonstrate the potential to accomplish software engineering tasks, existing methods for environment configuration often rely on manual efforts or fragile scripts, leading to inefficiencies and unreliable outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully automate environment configuration and generate executable Dockerfiles for arbitrary Python repositories. We address two major challenges: (1) enabling the LLM agent to configure environments within isolated Docker containers, and (2) ensuring the successful configuration process is recorded and accurately transferred to a Dockerfile without error. To achieve this, we propose atomic configuration synthesis, featuring a dual-environment architecture (internal and external environment) with a rollback mechanism to prevent environment "pollution" from failed commands, guaranteeing atomic execution (execute fully or not at all) and a Dockerfile generator to transfer successful configuration steps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark of 420 recent Python repositories with unit tests, where it achieves an 86.0% success rate, outperforming the best baseline by 63.9%.

## 社交和信息网络(cs.SI:Social and Information Networks)

### Diffusion Model Agnostic Social Influence Maximization in Hyperbolic Space 
[[arxiv](https://arxiv.org/abs/2502.13571)] [[cool](https://papers.cool/arxiv/2502.13571)] [[pdf](https://arxiv.org/pdf/2502.13571)]
> **Authors**: Hongliang Qiao
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 10 pages, 4 figures
- **标题**: None
- **领域**: 社交和信息网络,机器学习
- **Abstract**: The Influence Maximization (IM) problem aims to find a small set of influential users to maximize their influence spread in a social network. Traditional methods rely on fixed diffusion models with known parameters, limiting their generalization to real-world scenarios. In contrast, graph representation learning-based methods have gained wide attention for overcoming this limitation by learning user representations to capture influence characteristics. However, existing studies are built on Euclidean space, which fails to effectively capture the latent hierarchical features of social influence distribution. As a result, users' influence spread cannot be effectively measured through the learned representations. To alleviate these limitations, we propose HIM, a novel diffusion model agnostic method that leverages hyperbolic representation learning to estimate users' potential influence spread from social propagation data. HIM consists of two key components. First, a hyperbolic influence representation module encodes influence spread patterns from network structure and historical influence activations into expressive hyperbolic user representations. Hence, the influence magnitude of users can be reflected through the geometric properties of hyperbolic space, where highly influential users tend to cluster near the space origin. Second, a novel adaptive seed selection module is developed to flexibly and effectively select seed users using the positional information of learned user representations. Extensive experiments on five network datasets demonstrate the superior effectiveness and efficiency of our method for the IM problem with unknown diffusion model parameters, highlighting its potential for large-scale real-world social networks.

## 图像和视频处理(eess.IV:Image and Video Processing)

### RestoreGrad: Signal Restoration Using Conditional Denoising Diffusion Models with Jointly Learned Prior 
[[arxiv](https://arxiv.org/abs/2502.13574)] [[cool](https://papers.cool/arxiv/2502.13574)] [[pdf](https://arxiv.org/pdf/2502.13574)]
> **Authors**: Ching-Hua Lee,Chouchang Yang,Jaejin Cho,Yashas Malur Saidutta,Rakshith Sharma Srinivasa,Yilin Shen,Hongxia Jin
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 图像和视频处理,机器学习,音频和语音处理
- **Abstract**: Denoising diffusion probabilistic models (DDPMs) can be utilized for recovering a clean signal from its degraded observation(s) by conditioning the model on the degraded signal. The degraded signals are themselves contaminated versions of the clean signals; due to this correlation, they may encompass certain useful information about the target clean data distribution. However, existing adoption of the standard Gaussian as the prior distribution in turn discards such information, resulting in sub-optimal performance. In this paper, we propose to improve conditional DDPMs for signal restoration by leveraging a more informative prior that is jointly learned with the diffusion model. The proposed framework, called RestoreGrad, seamlessly integrates DDPMs into the variational autoencoder framework and exploits the correlation between the degraded and clean signals to encode a better diffusion prior. On speech and image restoration tasks, we show that RestoreGrad demonstrates faster convergence (5-10 times fewer training steps) to achieve better quality of restored signals over existing DDPM baselines, and improved robustness to using fewer sampling steps in inference time (2-2.5 times fewer), advocating the advantages of leveraging jointly learned prior for efficiency improvements in the diffusion process.

## 神经元和认知(q-bio.NC:Neurons and Cognition)

### LaVCa: LLM-assisted Visual Cortex Captioning 
[[arxiv](https://arxiv.org/abs/2502.13606)] [[cool](https://papers.cool/arxiv/2502.13606)] [[pdf](https://arxiv.org/pdf/2502.13606)]
> **Authors**: Takuya Matsuyama,Shinji Nishimoto,Yu Takagi
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: 33 pages
- **标题**: None
- **领域**: 神经元和认知,人工智能,计算语言学,计算机视觉和模式识别,机器学习
- **Abstract**: Understanding the property of neural populations (or voxels) in the human brain can advance our comprehension of human perceptual and cognitive processing capabilities and contribute to developing brain-inspired computer models. Recent encoding models using deep neural networks (DNNs) have successfully predicted voxel-wise activity. However, interpreting the properties that explain voxel responses remains challenging because of the black-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex Captioning (LaVCa), a data-driven approach that uses large language models (LLMs) to generate natural-language captions for images to which voxels are selective. By applying LaVCa for image-evoked brain activity, we demonstrate that LaVCa generates captions that describe voxel selectivity more accurately than the previously proposed method. Furthermore, the captions generated by LaVCa quantitatively capture more detailed properties than the existing method at both the inter-voxel and intra-voxel levels. Furthermore, a more detailed analysis of the voxel-specific properties generated by LaVCa reveals fine-grained functional differentiation within regions of interest (ROIs) in the visual cortex and voxels that simultaneously represent multiple distinct concepts. These findings offer profound insights into human visual representations by assigning detailed captions throughout the visual cortex while highlighting the potential of LLM-based methods in understanding brain representations. Please check out our webpage at https://sites.google.com/view/lavca-llm/

## 统计金融(q-fin.ST:Statistical Finance)

### Deep Learning for VWAP Execution in Crypto Markets: Beyond the Volume Curve 
[[arxiv](https://arxiv.org/abs/2502.13722)] [[cool](https://papers.cool/arxiv/2502.13722)] [[pdf](https://arxiv.org/pdf/2502.13722)]
> **Authors**: Remi Genet
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 统计金融,机器学习
- **Abstract**: Volume-Weighted Average Price (VWAP) is arguably the most prevalent benchmark for trade execution as it provides an unbiased standard for comparing performance across market participants. However, achieving VWAP is inherently challenging due to its dependence on two dynamic factors, volumes and prices. Traditional approaches typically focus on forecasting the market's volume curve, an assumption that may hold true under steady conditions but becomes suboptimal in more volatile environments or markets such as cryptocurrency where prediction error margins are higher. In this study, I propose a deep learning framework that directly optimizes the VWAP execution objective by bypassing the intermediate step of volume curve prediction. Leveraging automatic differentiation and custom loss functions, my method calibrates order allocation to minimize VWAP slippage, thereby fully addressing the complexities of the execution problem. My results demonstrate that this direct optimization approach consistently achieves lower VWAP slippage compared to conventional methods, even when utilizing a naive linear model presented in arXiv:2410.21448. They validate the observation that strategies optimized for VWAP performance tend to diverge from accurate volume curve predictions and thus underscore the advantage of directly modeling the execution objective. This research contributes a more efficient and robust framework for VWAP execution in volatile markets, illustrating the potential of deep learning in complex financial systems where direct objective optimization is crucial. Although my empirical analysis focuses on cryptocurrency markets, the underlying principles of the framework are readily applicable to other asset classes such as equities.

## 机器学习(stat.ML:Machine Learning)

### Graph Signal Inference by Learning Narrowband Spectral Kernels 
[[arxiv](https://arxiv.org/abs/2502.13686)] [[cool](https://papers.cool/arxiv/2502.13686)] [[pdf](https://arxiv.org/pdf/2502.13686)]
> **Authors**: Osman Furkan Kar,Gülce Turhan,Elif Vural
> **First submission**: 2025-02-19
> **First announcement**: 2025-02-20
> **comment**: No comments
- **标题**: None
- **领域**: 机器学习,机器学习
- **Abstract**: While a common assumption in graph signal analysis is the smoothness of the signals or the band-limitedness of their spectrum, in many instances the spectrum of real graph data may be concentrated at multiple regions of the spectrum, possibly including mid-to-high-frequency components. In this work, we propose a novel graph signal model where the signal spectrum is represented through the combination of narrowband kernels in the graph frequency domain. We then present an algorithm that jointly learns the model by optimizing the kernel parameters and the signal representation coefficients from a collection of graph signals. Our problem formulation has the flexibility of permitting the incorporation of signals possibly acquired on different graphs into the learning algorithm. We then theoretically study the signal reconstruction performance of the proposed method, by also elaborating on when joint learning on multiple graphs is preferable to learning an individual model on each graph. Experimental results on several graph data sets shows that the proposed method offers quite satisfactory signal interpolation accuracy in comparison with a variety of reference approaches in the literature.

## 其他论文

- [TALKPLAY: Multimodal Music Recommendation with Large Language Models](https://arxiv.org/abs/2502.13713)
  - **标题**: None
  - **Filtered Reason**: none of cs.SD,eess.AS,cs.IR in whitelist
- [Active Illumination for Visual Ego-Motion Estimation in the Dark](https://arxiv.org/abs/2502.13708)
  - **标题**: None
  - **Filtered Reason**: none of cs.RO in whitelist
- [User Association and Coordinated Beamforming in Cognitive Aerial-Terrestrial Networks: A Safe Reinforcement Learning Approach](https://arxiv.org/abs/2502.13663)
  - **标题**: None
  - **Filtered Reason**: none of cs.IT,eess.SP in whitelist
- [First Glimpse on Physical Layer Security in Internet of Vehicles: Transformed from Communication Interference to Sensing Interference](https://arxiv.org/abs/2502.13634)
  - **标题**: None
  - **Filtered Reason**: none of cs.IT in whitelist
- [AI-Empowered Catalyst Discovery: A Survey from Classical Machine Learning Approaches to Large Language Models](https://arxiv.org/abs/2502.13626)
  - **标题**: None
  - **Filtered Reason**: none of cs.CE in whitelist
- [Improving the Sparse Structure Learning of Spiking Neural Networks from the View of Compression Efficiency](https://arxiv.org/abs/2502.13572)
  - **标题**: None
  - **Filtered Reason**: none of cs.HC in whitelist
